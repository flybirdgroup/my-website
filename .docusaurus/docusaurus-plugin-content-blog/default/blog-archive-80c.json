{
  "blogPosts": [
    {
      "id": "welcome",
      "metadata": {
        "permalink": "/blog/welcome",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-26-welcome/index.md",
        "source": "@site/blog/2021-08-26-welcome/index.md",
        "title": "Welcome",
        "description": "Docusaurus blogging features are powered by the blog plugin.",
        "date": "2021-08-26T00:00:00.000Z",
        "formattedDate": "August 26, 2021",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 0.405,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "SÃ©bastien Lorber",
            "title": "Docusaurus maintainer",
            "url": "https://sebastienlorber.com",
            "imageURL": "https://github.com/slorber.png",
            "key": "slorber"
          },
          {
            "name": "Yangshun Tay",
            "title": "Front End Engineer @ Facebook",
            "url": "https://github.com/yangshun",
            "imageURL": "https://github.com/yangshun.png",
            "key": "yangshun"
          }
        ],
        "frontMatter": {
          "slug": "welcome",
          "title": "Welcome",
          "authors": [
            "slorber",
            "yangshun"
          ],
          "tags": [
            "facebook",
            "hello",
            "docusaurus"
          ]
        },
        "nextItem": {
          "title": "MDX Blog Post",
          "permalink": "/blog/mdx-blog-post"
        }
      },
      "content": "[Docusaurus blogging features](https://docusaurus.io/docs/blog) are powered by the [blog plugin](https://docusaurus.io/docs/api/plugins/@docusaurus/plugin-content-blog).\n\nSimply add Markdown files (or folders) to the `blog` directory.\n\nRegular blog authors can be added to `authors.yml`.\n\nThe blog post date can be extracted from filenames, such as:\n\n- `2019-05-30-welcome.md`\n- `2019-05-30-welcome/index.md`\n\nA blog post folder can be convenient to co-locate blog post images:\n\n![Docusaurus Plushie](./docusaurus-plushie-banner.jpeg)\n\nThe blog supports tags as well!\n\n**And if you don't want a blog**: just delete this directory, and use `blog: false` in your Docusaurus config."
    },
    {
      "id": "mdx-blog-post",
      "metadata": {
        "permalink": "/blog/mdx-blog-post",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2021-08-01-mdx-blog-post.mdx",
        "source": "@site/blog/2021-08-01-mdx-blog-post.mdx",
        "title": "MDX Blog Post",
        "description": "Blog posts support Docusaurus Markdown features, such as MDX.",
        "date": "2021-08-01T00:00:00.000Z",
        "formattedDate": "August 1, 2021",
        "tags": [
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 0.175,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "SÃ©bastien Lorber",
            "title": "Docusaurus maintainer",
            "url": "https://sebastienlorber.com",
            "imageURL": "https://github.com/slorber.png",
            "key": "slorber"
          }
        ],
        "frontMatter": {
          "slug": "mdx-blog-post",
          "title": "MDX Blog Post",
          "authors": [
            "slorber"
          ],
          "tags": [
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "Welcome",
          "permalink": "/blog/welcome"
        },
        "nextItem": {
          "title": "é€šè¿‡Composerä½¿ç”¨Airflowè¿è¡Œä¸€ä¸ªworkflow",
          "permalink": "/blog/2020/6/12/Airflow_Dataproc"
        }
      },
      "content": "Blog posts support [Docusaurus Markdown features](https://docusaurus.io/docs/markdown-features), such as [MDX](https://mdxjs.com/).\n\n:::tip\n\nUse the power of React to create interactive blog posts.\n\n```js\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n```\n\n<button onClick={() => alert('button clicked!')}>Click me!</button>\n\n:::"
    },
    {
      "id": "/2020/6/12/Airflow_Dataproc",
      "metadata": {
        "permalink": "/blog/2020/6/12/Airflow_Dataproc",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-6-12-Airflow_Dataproc.md",
        "source": "@site/blog/2020-6-12-Airflow_Dataproc.md",
        "title": "é€šè¿‡Composerä½¿ç”¨Airflowè¿è¡Œä¸€ä¸ªworkflow",
        "description": "åˆ›å»ºComposer by setting up Composer environment >> create a workflow py file >>  åˆ›å»ºDataproc >> Runs Hadoop job on Dataproc >> deletes Dataproc cluster",
        "date": "2020-06-12T00:00:00.000Z",
        "formattedDate": "June 12, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          }
        ],
        "readingTime": 6.2,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup"
          }
        ],
        "frontMatter": {
          "id": "Airflow1",
          "title": "é€šè¿‡Composerä½¿ç”¨Airflowè¿è¡Œä¸€ä¸ªworkflow",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "linux"
          ]
        },
        "prevItem": {
          "title": "MDX Blog Post",
          "permalink": "/blog/mdx-blog-post"
        },
        "nextItem": {
          "title": "äº‘ä¸Šå¿«é€Ÿæ­å»ºWordPressç½‘ç«™",
          "permalink": "/blog/2020/6/12/å¿«é€Ÿæ­å»ºwordpressç½‘ç«™"
        }
      },
      "content": "åˆ›å»ºComposer by setting up Composer environment >> create a workflow py file >>  åˆ›å»ºDataproc >> Runs Hadoop job on Dataproc >> deletes Dataproc cluster\n\n## step1 Create Enviroment and set up the Enviroment\n```\nName: highcpu\n\nLocation: us-central1\n\nZone: us-central1-a\n\nMachine type: n1-highcpu-4\n\nPython version 3\n```\n![png](../img/airflow/1-1.png)\n![png](../img/airflow/k-1.png)\n![png](../img/airflow/k-2.png)\n\n## step2 åˆ›å»ºGCS bucket\nè¦è®°ä½bucketåå­—, å› ä¸ºè¿™ä¸ªæ˜¯æ”¾DAG fileçš„\n\n\n## step3 äº†è§£æ ¸å¿ƒæ¦‚å¿µ\nAirflowæ˜¯ä¸€ä¸ªä»¥ç¼–ç¨‹æ–¹å¼ç¼–å†™ï¼Œå®‰æ’å’Œç›‘è§†å·¥ä½œæµçš„å¹³å°ã€‚\nä½¿ç”¨Airflowå°†å·¥ä½œæµç¼–å†™ä¸ºä»»åŠ¡çš„æœ‰å‘æ— ç¯å›¾ï¼ˆDAGï¼‰, å°±æ˜¯å•å‘çš„\n\nDAG: æœ‰å‘æ— ç¯å›¾æ˜¯æ‚¨è¦è¿è¡Œçš„æ‰€æœ‰ä»»åŠ¡çš„é›†åˆï¼Œä»¥åæ˜ å…¶å…³ç³»å’Œä¾èµ–æ€§çš„æ–¹å¼è¿›è¡Œç»„ç»‡ã€‚\n\nOperator: å°±æ˜¯å¯¹å•ä¸€ä»»åŠ¡çš„æè¿°\n\nTask: æ“ä½œå‘˜çš„å‚æ•°åŒ–å®ä¾‹ï¼›DAGä¸­çš„ä¸€ä¸ªèŠ‚ç‚¹\n\nTask Instance: ä»»åŠ¡çš„ç‰¹å®šè¿è¡Œï¼›å…¶ç‰¹å¾æ˜¯ï¼šDAGï¼Œä»»åŠ¡å’Œæ—¶é—´ç‚¹ã€‚å®ƒå…·æœ‰æŒ‡ç¤ºæ€§çŠ¶æ€ï¼šè¿è¡Œï¼ŒæˆåŠŸï¼Œå¤±è´¥ï¼Œè·³è¿‡\n\n[æ›´å¤šæ¦‚å¿µå¯ä»¥æŸ¥çœ‹é“¾æ¥](https://airflow.apache.org/docs/stable/concepts.html#)\n\n## step4: è®¾å®šä¸€ä¸ªworkflow å·¥ä½œæµ\n\n1. Composer workflowsæ˜¯ç”±DAGsç»„æˆçš„. DAGs å°±æ˜¯è¢«å®šä¹‰å¥½çš„æ ‡å‡†pythonæ–‡ä»¶, è¿™äº›æ–‡ä»¶éƒ½æ˜¯æ”¾åœ¨Airflowçš„DAG_FOLDERä¸­.\n2. Airflowä¼šåŠ¨æ€åœ°æ‰§è¡Œpythonæ–‡ä»¶çš„ä»£ç æ¥æ„å»ºDAGså¯¹è±¡\n3. æ‚¨å¯ä»¥æ ¹æ®éœ€è¦æ‹¥æœ‰ä»»æ„æ•°é‡çš„DAGï¼Œæ¯ä¸ªDAGæè¿°ä»»æ„æ•°é‡çš„ä»»åŠ¡ã€‚é€šå¸¸ï¼Œæ¯ä¸ªDAGåº”å¯¹åº”ä¸€ä¸ªé€»è¾‘å·¥ä½œæµç¨‹workflowã€‚\n\n```\n\"\"\"Example Airflow DAG that creates a Cloud Dataproc cluster, runs the Hadoop\nwordcount example, and deletes the cluster.\nThis DAG relies on three Airflow variables\nhttps://airflow.apache.org/concepts.html#variables\nè¿™é‡Œæ˜¯åœ¨airflow web interfaceçš„admin>>varibaleè®¾ç½®çš„\n* gcp_project - Google Cloud Project to use for the Cloud Dataproc cluster.\n* gce_zone - Google Compute Engine zone where Cloud Dataproc cluster should be\n  created.\n* gcs_bucket - Google Cloud Storage bucket to use for result of Hadoop job.\n  See https://cloud.google.com/storage/docs/creating-buckets for creating a\n  bucket.\n\"\"\"\n\nimport datetime\nimport os\n\nfrom airflow import models\nfrom airflow.contrib.operators import dataproc_operator\nfrom airflow.utils import trigger_rule\n\n# Output file for Cloud Dataproc job. è¾“å‡ºæ–‡ä»¶åœ°å€\n# è¾“å‡ºçš„åœ°å€æ˜¯é€šè¿‡gcs+æ–‡ä»¶åå­—(wordcount) + æ—¶é—´ + '/'\noutput_file = os.path.join(\n    models.Variable.get('gcs_bucket'), 'wordcount',\n    datetime.datetime.now().strftime('%Y%m%d-%H%M%S')) + os.sep\n# Path to Hadoop wordcount example available on every Dataproc cluster.\nWORDCOUNT_JAR = (\n    'file:///usr/lib/hadoop-mapreduce/hadoop-mapreduce-examples.jar'\n)\n# Arguments to pass to Cloud Dataproc job.\nwordcount_args = ['wordcount', 'gs://pub/shakespeare/rose.txt', output_file]\n\nyesterday = datetime.datetime.combine(\n    datetime.datetime.today() - datetime.timedelta(1),\n    datetime.datetime.min.time())\n\ndefault_dag_args = {\n    # Setting start date as yesterday starts the DAG immediately when it is\n    # detected in the Cloud Storage bucket.\n    'start_date': yesterday,\n    # To email on failure or retry set 'email' arg to your email and enable\n    # emailing here.\n    'email_on_failure': False,\n    'email_on_retry': False,\n    # If a task fails, retry it once after waiting at least 5 minutes\n    'retries': 1,\n    'retry_delay': datetime.timedelta(minutes=5),\n    'project_id': models.Variable.get('gcp_project')\n}\n\n# [START composer_hadoop_schedule]\nwith models.DAG(\n        'composer_hadoop_tutorial',\n        # Continue to run DAG once per day\n        schedule_interval=datetime.timedelta(days=1),\n        default_args=default_dag_args) as dag:\n    # [END composer_hadoop_schedule]\n\n    # Create a Cloud Dataproc cluster.\n    create_dataproc_cluster = dataproc_operator.DataprocClusterCreateOperator(\n        task_id='create_dataproc_cluster',\n        # Give the cluster a unique name by appending the date scheduled.\n        # See https://airflow.apache.org/code.html#default-variables\n        cluster_name='composer-hadoop-tutorial-cluster-{{ ds_nodash }}',\n        num_workers=2,\n        zone=models.Variable.get('gce_zone'),\n        master_machine_type='n1-standard-1',\n        worker_machine_type='n1-standard-1')\n\n    # Run the Hadoop wordcount example installed on the Cloud Dataproc cluster\n    # master node.\n    run_dataproc_hadoop = dataproc_operator.DataProcHadoopOperator(\n        task_id='run_dataproc_hadoop',\n        main_jar=WORDCOUNT_JAR,\n        cluster_name='composer-hadoop-tutorial-cluster-{{ ds_nodash }}',\n        arguments=wordcount_args)\n\n    # Delete Cloud Dataproc cluster.\n    delete_dataproc_cluster = dataproc_operator.DataprocClusterDeleteOperator(\n        task_id='delete_dataproc_cluster',\n        cluster_name='composer-hadoop-tutorial-cluster-{{ ds_nodash }}',\n        # Setting trigger_rule to ALL_DONE causes the cluster to be deleted\n        # even if the Dataproc job fails.\n        trigger_rule=trigger_rule.TriggerRule.ALL_DONE)\n\n    # [START composer_hadoop_steps]\n    # Define DAG dependencies.\n    create_dataproc_cluster >> run_dataproc_hadoop >> delete_dataproc_cluster\n    # [END composer_hadoop_steps]\n```\n\n## ä¸ºäº†åè°ƒè¿™ä¸‰ä¸ªå·¥ä½œæµç¨‹ä»»åŠ¡ï¼ŒDAGå¯¼å…¥äº†ä»¥ä¸‹è¿ç®—ç¬¦ï¼š\n\nDataprocClusterCreateOperatorï¼šåˆ›å»ºä¸€ä¸ªCloud Dataprocé›†ç¾¤ã€‚\nDataProcHadoopOperatorï¼šæäº¤Hadoop wordcountä½œä¸šå¹¶å°†ç»“æœå†™å…¥Cloud Storageå­˜å‚¨æ¡¶ã€‚\nDataprocClusterDeleteOperatorï¼šåˆ é™¤ç¾¤é›†ä»¥é¿å…äº§ç”ŸæŒç»­çš„Compute Engineè´¹ç”¨ã€‚\n\nä»»åŠ¡æŒ‰é¡ºåºè¿è¡Œï¼Œæ‚¨å¯ä»¥åœ¨æ–‡ä»¶çš„æ­¤éƒ¨åˆ†ä¸­çœ‹åˆ°\n```\n# Define DAG dependencies.\ncreate_dataproc_cluster >> run_dataproc_hadoop >> delete_dataproc_cluster\n```\n\nDAGçš„åç§°ä¸ºhadoop_tutorialï¼Œå¹¶ä¸”DAGæ¯å¤©è¿è¡Œä¸€æ¬¡ã€‚\n```\nwith models.DAG(\n        'composer_hadoop_tutorial',\n        # Continue to run DAG once per day\n        schedule_interval=datetime.timedelta(days=1),\n        default_args=default_dag_args) as dag:\n```\nç”±äºstart_dateä¼ é€’ç»™default_dag_argsçš„è®¾ç½®ä¸ºyesterdayï¼Œå› æ­¤Cloud Composerå®‰æ’å·¥ä½œæµåœ¨DAGä¸Šä¼ åç«‹å³å¼€å§‹ã€‚\n\n## step5 è®¾ç½®airflowå˜é‡\n\n1. å»airflow web interface \n\n![png](../img/airflow/1.png)\n\n2. åˆ›å»ºä»¥ä¸‹Aireflowå˜é‡gcp_projectï¼Œgcs_bucketä»¥åŠgce_zoneï¼š\n![png](../img/airflow/2.png)\n\n## step6 å°†DAGä¸Šè½½åˆ°äº‘å­˜å‚¨\nåœ¨Cloud Shellä¸­ï¼Œå°†hadoop_tutorial.pyå¤åˆ¶å¹¶ä¿å­˜åœ¨æœ¬åœ°è™šæ‹Ÿæœºä¸Š\n```\ngit clone https://github.com/GoogleCloudPlatform/python-docs-samples\n```\n\nè½¬åˆ°python-docs-samplesç›®å½•ï¼š\n```\ncd python-docs-samples/composer/workflows\n```\n\nç°åœ¨ï¼Œå°†hadoop_tutorial.pyæ–‡ä»¶çš„å‰¯æœ¬ä¸Šè½½åˆ°Cloud Storageå­˜å‚¨æ¡¶ï¼Œè¯¥å­˜å‚¨æ¡¶åœ¨åˆ›å»ºç¯å¢ƒæ—¶ä¼šè‡ªåŠ¨åˆ›å»ºã€‚æ‚¨å¯ä»¥é€šè¿‡è½¬åˆ°Composer > ç¯å¢ƒè¿›è¡Œæ£€æŸ¥ã€‚å•å‡»æ‚¨å…ˆå‰åˆ›å»ºçš„ç¯å¢ƒï¼Œè¿™å°†å¸¦æ‚¨è¿›å…¥æ‰€åˆ›å»ºç¯å¢ƒçš„æè¿°ã€‚æŸ¥æ‰¾DAGs folderï¼Œå¤åˆ¶è¦æ›¿æ¢çš„å€¼ï¼ŒDAGs_folder_pathå¹¶åœ¨ä»¥ä¸‹å‘½ä»¤ä¸­ä¸Šä¼ æ–‡ä»¶ï¼š\n```\ngsutil cp hadoop_tutorial.py DAGs_folder_path\n```\n![png](../img/airflow/3.png)\n\n\næ¢ç´¢DAGè¿è¡Œ\nå½“æ‚¨å°†DAGæ–‡ä»¶ä¸Šä¼ åˆ°dagsCloud Storageä¸­çš„æ–‡ä»¶å¤¹æ—¶ï¼ŒCloud Composerä¼šè§£æè¯¥æ–‡ä»¶ã€‚å¦‚æœæœªæ‰¾åˆ°é”™è¯¯ï¼Œåˆ™å·¥ä½œæµçš„åç§°å°†æ˜¾ç¤ºåœ¨DAGåˆ—è¡¨ä¸­ï¼Œå¹¶ä¸”è¯¥å·¥ä½œæµå·²æ’é˜Ÿç­‰å¾…ç«‹å³è¿è¡Œã€‚\n\nç¡®ä¿æ‚¨åœ¨Airflow Webç•Œé¢çš„DAGé€‰é¡¹å¡ä¸Šã€‚æ­¤è¿‡ç¨‹éœ€è¦å‡ åˆ†é’Ÿæ‰èƒ½å®Œæˆã€‚åˆ·æ–°æµè§ˆå™¨ä»¥ç¡®ä¿æ‚¨æ­£åœ¨æŸ¥çœ‹æœ€æ–°ä¿¡æ¯ã€‚\n![png](../img/airflow/4.png)\n![png](../img/airflow/5.png)\n![png](../img/airflow/6.png)\n\n## step7 é‡æ–°è¿è¡Œå·¥ä½œæµç¨‹\n1. å•å‡»create_dataproc_clusterå›¾å½¢ã€‚\n2. å•å‡»æ¸…é™¤ä»¥é‡ç½®ä¸‰ä¸ªä»»åŠ¡ã€‚\n3. ç„¶åå•å‡»ç¡®å®šè¿›è¡Œç¡®è®¤ã€‚è¯·æ³¨æ„ï¼Œcreate_dataproc_clusterå‘¨å›´çš„é¢œè‰²å·²æ›´æ”¹ï¼ŒçŠ¶æ€ä¸ºâ€œæ­£åœ¨è¿è¡Œâ€ã€‚\n![png](../img/airflow/7.png)\n\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°dataprocå…·ä½“çš„è¿è¡Œæƒ…å†µ\n![png](../img/airflow/d-1.png)\n![png](../img/airflow/d-2.png)\n![png](../img/airflow/d-3.png)\n\njobå®Œæˆå,GSCçš„æƒ…å†µ\n![png](../img/airflow/gs-1.png)\n![png](../img/airflow/gs-2.png)\n![png](../img/airflow/gs-3.png)"
    },
    {
      "id": "/2020/6/12/å¿«é€Ÿæ­å»ºwordpressç½‘ç«™",
      "metadata": {
        "permalink": "/blog/2020/6/12/å¿«é€Ÿæ­å»ºwordpressç½‘ç«™",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-6-12-å¿«é€Ÿæ­å»ºwordpressç½‘ç«™.md",
        "source": "@site/blog/2020-6-12-å¿«é€Ÿæ­å»ºwordpressç½‘ç«™.md",
        "title": "äº‘ä¸Šå¿«é€Ÿæ­å»ºWordPressç½‘ç«™",
        "description": "æˆ‘ä»¬å°†ä¼šåœ¨è¿™å°æœåŠ¡å™¨ä¸Šæ­å»ºå’Œéƒ¨ç½²LAMPç¯å¢ƒï¼Œç„¶åå®‰è£…WordPressç½‘ç«™ï¼Œæœ€åå‘å¤§å®¶å±•ç¤ºå¦‚ä½•åœ¨WordPressç½‘ç«™ä½¿ç”¨å¾®åšæŒ‚ä»¶å’Œç½‘ç«™ç»Ÿè®¡å¹³å°",
        "date": "2020-06-12T00:00:00.000Z",
        "formattedDate": "June 12, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          }
        ],
        "readingTime": 3.785,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup"
          }
        ],
        "frontMatter": {
          "id": "WordPress",
          "title": "äº‘ä¸Šå¿«é€Ÿæ­å»ºWordPressç½‘ç«™",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "linux"
          ]
        },
        "prevItem": {
          "title": "é€šè¿‡Composerä½¿ç”¨Airflowè¿è¡Œä¸€ä¸ªworkflow",
          "permalink": "/blog/2020/6/12/Airflow_Dataproc"
        },
        "nextItem": {
          "title": "ä½¿ç”¨GKE(Google Kubernetes Engine)éƒ¨ç½²å®¹å™¨åŒ–åº”ç”¨ è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(ä¸‰)",
          "permalink": "/blog/2020/5/1/Kubernetes"
        }
      },
      "content": "æˆ‘ä»¬å°†ä¼šåœ¨è¿™å°æœåŠ¡å™¨ä¸Šæ­å»ºå’Œéƒ¨ç½²LAMPç¯å¢ƒï¼Œç„¶åå®‰è£…WordPressç½‘ç«™ï¼Œæœ€åå‘å¤§å®¶å±•ç¤ºå¦‚ä½•åœ¨WordPressç½‘ç«™ä½¿ç”¨å¾®åšæŒ‚ä»¶å’Œç½‘ç«™ç»Ÿè®¡å¹³å°\n\n## step1 Login the vm instance\n\n![png](../img/aliyun/wordpress/1.png)\n\n## step2.1 æ­å»ºå¼€å‘ç¯å¢ƒ\n```\nyum -y install httpd\nyum -y install httpd-manual mod_ssl mod_perl mod_auth_mysql #å®‰è£… apache çš„æ‰©å±•æ–‡ä»¶ã€‚\nservice httpd start #å¯åŠ¨ apache http æœåŠ¡ã€‚\nchkconfig httpd on è®¾ç½®å¼€æœºè‡ªåŠ¨å¯åŠ¨ apache http æœåŠ¡ã€‚\n```\n\n## step2.2 æ ¡éªŒ\nå»å…¬ç½‘ipæŸ¥çœ‹\n\n## step2.3: ä¸‹è½½å’Œå®‰è£…MySQLæ•°æ®åº“\n\n```\nyum -y install mysql mysql-server\nservice mysqld start #å¯åŠ¨æœåŠ¡\nmysql_secure_installation #ä¿®æ”¹ MySQL æ•°æ®åº“ root ç”¨æˆ·çš„å¯†ç ï¼Œå¹¶æé«˜ MySQL æ•°æ®åº“çš„å®‰å…¨æ€§ã€‚\n```\n```\n# è¾“å…¥ä»¥ä¸‹å‘½ä»¤\nmysql -uroot -p123\n\nshow databases;\n\ncreate database wordpress;\n\nshow databases;\n\nexit\n\nchkconfig mysqld on #è®¾ç½®å¼€æœºè‡ªåŠ¨å¯åŠ¨MySQLæœåŠ¡\n```\n![png](../img/aliyun/wordpress/2.png)\n\n\n## step2.4: å®‰è£…PHPè¯­è¨€ç¯å¢ƒ\n```\nyum -y install php php-mysql\nyum -y install gd php-gd gd-devel php-xml php-common php-mbstring php-ldap php-pear php-xmlrpc php-imap #å®‰è£… php å¸¸ç”¨æ‰©å±•åŒ…\nservice httpd restart #é‡å¯æœåŠ¡,è¿™æ­¥å¾ˆé‡è¦,å¿…é¡»é‡å¯\n\necho \"<?php phpinfo(); ?>\" > /var/www/html/phpinfo.php #æ‰§è¡Œæ­¤å‘½ä»¤ï¼Œåˆ›å»ºä¸€ä¸ª php é¡µé¢ï¼Œæµ‹è¯• PHP ç¯å¢ƒ\n```\n\n## step2.5 åœ¨æµè§ˆå™¨æµ‹è¯•phpé¡µé¢\n```\nå¼¹æ€§ip/phpinfo.php\n```\n![png](../img/aliyun/wordpress/3.png)\n\n## step3 å®‰è£…éƒ¨ç½²wordpress\nä¸‹è½½ä¸­æ–‡ç‰ˆWordPresså®‰è£…åŒ…ï¼Œè¯·ç‚¹å‡»é“¾æ¥ https://cn.wordpress.org/ï¼Œè¿™ä¸ªæ˜¯WordPressä¸­æ–‡å®˜ç½‘ï¼Œå¯ä»¥æ‰¾åˆ°æœ€æ–°çš„ç‰ˆæœ¬å¹¶ä¸‹è½½å®‰è£…ï¼› ä¸‹è½½å®Œæˆå,è§£å‹\n```\ntar -xzf wordpress-4.7.4-zh_CN.tar.gz\nls\n```\n### å¤‡ä»½ WordPress é…ç½®æ–‡ä»¶ï¼Œå¹¶å°†åŸæœ‰çš„ç¤ºä¾‹é…ç½®æ–‡ä»¶æ ·æœ¬ä¿ç•™ã€‚\n```\ncd wordpress\ncp wp-config-sample.php wp-config.php\n```\n### è¿›å…¥ wp-config.php çš„ç¼–è¾‘é¡µé¢ï¼š\n```\nvim wp-config.php\n```\n### æŒ‰é”®ç›˜ i ï¼Œè¿›å…¥ç¼–è¾‘çŠ¶æ€ï¼Œä¿®æ”¹é…ç½®æ–‡ä»¶çš„æ•°æ®åº“ä¿¡æ¯ï¼šä¿®æ”¹ DB_NAME çš„å‚æ•°å€¼ database_name_here ä¸ºä¹‹å‰åˆ›å»ºçš„æ•°æ®åº“ wordpressï¼š\n```\ndefine('DB_NAME', 'wordpress');\n```\n\n### ä¿®æ”¹ DB_USER çš„å‚æ•°å€¼ username_here ä¸º root :\n```\ndefine('DB_USER', 'root');\n```\n\n### ä¿®æ”¹ DB_PASSWORD çš„å‚æ•°å€¼ password_here ä¸º 123 :\n\n### ä¿®æ”¹å®Œæ¯•åï¼Œç‚¹å‡» esc ï¼Œé€€å‡ºç¼–è¾‘çŠ¶æ€ï¼Œç„¶åè¾“å…¥ :wq ï¼Œä¿å­˜ä¿®æ”¹ä¿¡æ¯å¹¶é€€å‡ºé…ç½®æ–‡ä»¶\n\n### åœ¨ Apache çš„æ ¹ç›®å½• /var/www/html ä¸‹ï¼Œåˆ›å»ºä¸€ä¸ª wp-blog æ–‡ä»¶å¤¹ã€‚\n```\nmkdir /var/www/html/wp-blog\n```\n### ç„¶åï¼Œå°† wordpress è¿ç§»åˆ°è¿™ä¸ªæ–°å»ºæ–‡ä»¶å¤¹ä¸­ã€‚\n```\nmv * /var/www/html/wp-blog/\n```\n\n### å®Œæˆå¦‚ä¸Šé…ç½®åï¼Œè¿”å›æµè§ˆå™¨ï¼Œå¹¶è®¿é—® http://xxx.xxx.xx.x/wp-blog/wp-admin/install.php ï¼Œå…¶ä¸­ xxx.xxx.xx.x ä¸º ECS å®ä¾‹çš„ å¼¹æ€§IP ï¼Œå¡«å†™å¦‚ä¸‹ä¿¡æ¯ï¼Œå®Œæˆåï¼Œç‚¹å‡»é¡µé¢åº•éƒ¨çš„ å®‰è£…WordPress ï¼Œå¼€å§‹å®‰è£… WordPress ã€‚\n![png](../img/aliyun/wordpress/4.png)\n\nè·å¾—å¯†ç : MsLE1ppUhzV!95xOyq\n\n![png](../img/aliyun/wordpress/5.png)\n![png](../img/aliyun/wordpress/6.png)\n\n## step4 ä½¿ç”¨CNZZå¸®ä½ æˆä¸ºåˆæ ¼â€œç«™é•¿â€\n1. æœ¬å°èŠ‚ä»‹ç»ä¸»è¦ï¼šå€ŸåŠ© CNZZ  å¹³å°è§‚å¯Ÿ WordPress ç½‘ç«™ä¸€å¤©æœ‰å¤šå°‘ IP è®¿é—®ï¼Œé‚£äº› IP éƒ½æ˜¯ä»å“ªä¸ªé¡µé¢è¿›å…¥åˆ°è‡ªå·±ç½‘ç«™çš„ç­‰å†…å®¹ã€‚\n\n2. ç‚¹å‡»é“¾æ¥ https://web.umeng.com/main.php?c=user&a=login è¿›è¡Œæ³¨å†Œã€ç™»å½•ã€‚\n\nç™»å½•ç½‘å€(https://workbench.umeng.com/)\n\n3.  ç™»å½• CNZZ æ•°æ®ç»Ÿè®¡ä¸“å®¶ç½‘ç«™åï¼Œå¡«å†™ä»¥ä¸‹ä¿¡æ¯ï¼Œå®Œæˆåç‚¹å‡» ç¡®è®¤æ·»åŠ ç«™ç‚¹ ã€‚\nhttps://web.umeng.com/main.php?c=site&a=add\n\n![png](../img/aliyun/wordpress/7.png)\n![png](../img/aliyun/wordpress/8.png)\n![png](../img/aliyun/wordpress/9.png)\n\n4. åˆ‡æ¢å› WordPress ç½‘ç«™çš„ä¸»é¡µé¢ï¼Œç‚¹å‡» å¤–è§‚ ï¼Œå¹¶é€‰æ‹©å­èœå•ä¸‹çš„ å°å·¥å…·\n![png](../img/aliyun/wordpress/10.png) \n5. åµŒå…¥ä»£ç \n![png](../img/aliyun/wordpress/11.png) \n![png](../img/aliyun/wordpress/12.png) \n![png](../img/aliyun/wordpress/13.png) \n![png](../img/aliyun/wordpress/14.png)  \n\n6. åˆ é™¤ç»Ÿè®¡\n![png](../img/aliyun/wordpress/15.png)"
    },
    {
      "id": "/2020/5/1/Kubernetes",
      "metadata": {
        "permalink": "/blog/2020/5/1/Kubernetes",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-5-1-Kubernetes.md",
        "source": "@site/blog/2020-5-1-Kubernetes.md",
        "title": "ä½¿ç”¨GKE(Google Kubernetes Engine)éƒ¨ç½²å®¹å™¨åŒ–åº”ç”¨ è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(ä¸‰)",
        "description": "link to è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(äºŒ) å­˜å‚¨æ–‡ä»¶ç„¶åå…±äº«",
        "date": "2020-05-01T00:00:00.000Z",
        "formattedDate": "May 1, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          }
        ],
        "readingTime": 3.695,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup"
          }
        ],
        "frontMatter": {
          "id": "Kubernetes1",
          "title": "ä½¿ç”¨GKE(Google Kubernetes Engine)éƒ¨ç½²å®¹å™¨åŒ–åº”ç”¨ è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(ä¸‰)",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "linux"
          ]
        },
        "prevItem": {
          "title": "äº‘ä¸Šå¿«é€Ÿæ­å»ºWordPressç½‘ç«™",
          "permalink": "/blog/2020/6/12/å¿«é€Ÿæ­å»ºwordpressç½‘ç«™"
        },
        "nextItem": {
          "title": "linuxé«˜çº§ç”¨æ³•",
          "permalink": "/blog/2020/4/30/linuxå‘½ä»¤"
        }
      },
      "content": "link to [è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(äºŒ) å­˜å‚¨æ–‡ä»¶ç„¶åå…±äº«](GoogleCloudStorage)\n\nlink to [è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(å››) è®­ç»ƒTensorFlowæ¨¡å‹](TensorFlow)\n\nlink to [Container Registry å¿«é€Ÿå…¥é—¨å¿«é€Ÿå…¥é—¨](docker)\n\nlink to [dockerçŸ¥è¯†1](dockerhub)\n\nlink to [dockerçŸ¥è¯†2](dockerhub_2)\n\n## step 1 é€‰æ‹©é¡¹ç›®,å¯åŠ¨Kubernetes Engineé¡µé¢\n![png](../img/kubernetes/1_create_project.png)\n<!--truncate-->\n![png](../img/kubernetes/2_create_API.png)\n\n![png](../img/kubernetes/3_Kubernetes.png)\n\n![png](../img/kubernetes/4_activate_API.png)\n\n\n![png](../img/kubernetes/5_kubernetes.png)\n\n\n## step 2 é…ç½®gcloudå·¥å…·çš„é»˜è®¤è®¾ç½®\nå¦‚éœ€è®¾ç½®é»˜è®¤é¡¹ç›®ï¼Œè¯·åœ¨ Cloud Shell ä¸­è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n```python\ngcloud config set project project-id\n```\nå¦‚éœ€è®¾ç½®é»˜è®¤è®¡ç®—åœ°åŒºï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼š\n```python\ngcloud config set compute/zone compute-zone\n```\n![png](../img/kubernetes/2.png)\n\n## step3 åˆ›å»ºGKEé›†ç¾¤\nä¸€ä¸ªé›†ç¾¤åŒ…å«è‡³å°‘ä¸€å°ç¾¤ä¸»å®ä¾‹æœºå™¨å’Œå¤šå°å·¥ä½œå™¨æœºå™¨,è¿™äº›å·¥ä½œæœºå™¨ç§°ä¸º\"èŠ‚ç‚¹\".èŠ‚ç‚¹æ˜¯è¿è¡ŒKubernetesè¿›ç¨‹çš„Compute Engineè™šæ‹Ÿæœºå®ä¾‹,å¦‚ä¸‹å›¾\n![png](../img/kubernetes/10_cluster.png)\n\nå¦‚éœ€åˆ›å»ºé›†ç¾¤ï¼Œè¯·è¿è¡Œä»¥ä¸‹å‘½ä»¤, å…¶ä¸­ï¼Œcluster-name æ˜¯é›†ç¾¤é€‰æ‹©çš„åç§°ã€‚ï¼š\n```python\ngcloud container clusters create cluster-name\n```\n\n#### è·å–ç”¨äºè¯¥é›†ç¾¤çš„èº«ä»½éªŒè¯å‡­æ®\nåˆ›å»ºé›†ç¾¤å,éœ€è¦è·å–èº«ä»½éªŒè¯å‡­æ®ä»¥ä¾¿ä¸è¯¥é›†ç¾¤äº¤äº’,å‘½ä»¤ä¸º:\n```python\ngcloud container clusters get-credentials cluster-name\n```\næ­¤å‘½ä»¤å°† kubectl é…ç½®ä¸ºä½¿ç”¨æ‚¨åˆ›å»ºçš„é›†ç¾¤ã€‚\n\n### step4 åˆ›å»ºDeployment\n\nå¦‚æœéœ€è¦åœ¨é›†ç¾¤ä¸­è¿è¡Œåº”ç”¨,éœ€è¦è¿è¡Œä¸€ä¸‹å‘½ä»¤:\n```python\nkubectl create deployment abc-server --image=gcr.io/clean-mountain-272313/flybirdgroup/classifier:latest\n```\nè¿™ä¸ªKuberneteså‘½ä»¤kubectl create deployment ä¼šåˆ›å»ºåä¸º abc-server çš„ Deployment. è¿™ä¸ªDeploymentçš„Podåœ¨å…¶å®¹å™¨ä¸­è¿è¡Œhello-appæ˜ åƒ\n\nåœ¨æ­¤å‘½ä»¤ä¸­:\n--image æŒ‡å®šäº†è¦éƒ¨ç½²çš„å®¹å™¨é•œåƒ. è¿™ä¸ªå‘½ä»¤ä¼šä»Container Registry(ç§æœ‰å®¹å™¨æ˜ åƒæ³¨å†Œè¡¨)æ‹‰å–gcr.io/clean-mountain-272313/flybirdgroup/classifier:latest\n\nå¦‚ä½•åˆ›å»ºé•œåƒå’Œä¸Šä¼ åˆ°ç§æœ‰å®¹å™¨é•œåƒæ³¨å†Œè¡¨\n\nlink to [Container Registry å¿«é€Ÿå…¥é—¨å¿«é€Ÿå…¥é—¨](docker)\n\nlink to [dockerçŸ¥è¯†1](dockerhub)\n\nlink to [dockerçŸ¥è¯†2](dockerhub_2)\n\n### step 5 å…¬å¼€deployment\n\néƒ¨ç½²åº”ç”¨å,éœ€è¦å°†å…¶å…¬å¼€åˆ°äº’è”ç½‘,ä»¥ä¾¿ç”¨æˆ·è®¿é—®è¯¥åº”ç”¨.æˆ‘ä»¬å¯ä»¥é€šè¿‡åˆ›å»ºServiceæ¥å…¬å¼€åº”ç”¨,è¿™æ˜¯ä¸€ç§Kubernetesèµ„æº,å¯ä»¥å°†åº”ç”¨å…¬å¼€ç»™å¤–éƒ¨æµé‡.\n```python\nkubectl expose deployment abc-server --type LoadBalancer \\\n  --port 80 --target-port 8080 (è¿™é‡Œè¯·æ³¨æ„,å¦‚æœæ˜¯flaskåº”ç”¨,target-port é€‰æ‹©5000)\n```\n#### æ£€æŸ¥å’ŒæŸ¥çœ‹åº”ç”¨\n```python\nkubectl get pods (æŸ¥çœ‹æ­£åœ¨è¿è¡Œçš„pod)\n```\n![png](../img/kubernetes/3.png)\nå¦‚æœstatus æ˜¯ Running å’Œ Readyçš„çŠ¶æ€æ˜¯1/1, å°±å¯ä»¥è¿›è¡Œä¸‹ä¸€æ­¥\n\n#### ä½¿ç”¨ kubectl get service æ£€æŸ¥ abc-server Serviceï¼š\n```python\nkubectl get service abc-server \n```\né€šè¿‡è¿™ä¸ªå‘½ä»¤å¯ä»¥å¾—åˆ°external-ip,å¤åˆ¶serviceçš„å¤–éƒ¨ipåœ°å€,æ›¿æ¢external-ip\n```python\nhttp://external-ip/\n```\nè¿™æ ·å°±æƒ³GKE(google Kebernetes Engineéƒ¨ç½²äº†ä¸€ä¸ªå®¹å™¨åŒ–webåº”ç”¨)\n\n![png](../img/kubernetes/7.png)\n\n![png](../img/kubernetes/8.png)\n\n# æŸ¥çœ‹service\nå¯ä»¥æŸ¥çœ‹kubernetesçš„æ‰€æœ‰service\n```kubernetes\nkubectl get service # \n```\nè¿™äº›serviceéå¸¸é‡è¦,å› ä¸ºpodä¹‹é—´çš„ç›¸è¿å°±æ˜¯é€šè¿‡è¿™äº›serviceçš„\n\n# åˆ é™¤pod\n```\nkubectl delete pod jenkins2-8698b5449c-grbdm(podçš„åå­—)\nkubectl get pod \n```\næˆ‘ä»¬ä¼šå‘ç°podæ²¡æœ‰è¢«åˆ é™¤,è¿™æ—¶å€™æˆ‘ä»¬è¦è¾“å…¥ä¸€ä¸‹å‘½ä»¤\n```\nkubectl get deployment\nkubectl delete deployment åå­—name\nkubectl get pod\n```\nå°±å®Œå…¨åˆ é™¤äº†"
    },
    {
      "id": "/2020/4/30/linuxå‘½ä»¤",
      "metadata": {
        "permalink": "/blog/2020/4/30/linuxå‘½ä»¤",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-30-linuxå‘½ä»¤.md",
        "source": "@site/blog/2020-4-30-linuxå‘½ä»¤.md",
        "title": "linuxé«˜çº§ç”¨æ³•",
        "description": "linuxä¸€äº›å¥½ç©çš„å‘½ä»¤æ¯”å¦‚å¾ªç¯,é‡å®šå‘",
        "date": "2020-04-30T00:00:00.000Z",
        "formattedDate": "April 30, 2020",
        "tags": [
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          },
          {
            "label": "command line",
            "permalink": "/blog/tags/command-line"
          },
          {
            "label": "cat",
            "permalink": "/blog/tags/cat"
          },
          {
            "label": "<<EOF",
            "permalink": "/blog/tags/eof"
          },
          {
            "label": "loop",
            "permalink": "/blog/tags/loop"
          }
        ],
        "readingTime": 0.78,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "linux",
          "title": "linuxé«˜çº§ç”¨æ³•",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "linux",
            "command line",
            "cat",
            "<<EOF",
            "loop"
          ]
        },
        "prevItem": {
          "title": "ä½¿ç”¨GKE(Google Kubernetes Engine)éƒ¨ç½²å®¹å™¨åŒ–åº”ç”¨ è°·æ­Œäº‘å¿«é€Ÿå…¥é—¨(ä¸‰)",
          "permalink": "/blog/2020/5/1/Kubernetes"
        },
        "nextItem": {
          "title": "pythonè¯»å–bigquery",
          "permalink": "/blog/2020/4/30/pythonè¯»å–Biggquery"
        }
      },
      "content": "linuxä¸€äº›å¥½ç©çš„å‘½ä»¤æ¯”å¦‚å¾ªç¯,é‡å®šå‘\n\n# å¾ªç¯\n```linux\nfor i in {1..50}\ndo\necho i\ndone\n```\n<!--truncate-->\n# é‡å®šå‘ |, <<, >>, >, >>æ˜¯a,ç´¯ç§¯å†™å…¥, >æ˜¯w,è¦†ç›–å†™å…¥\nå°±æ˜¯å¦‚æœä¸€å¼€å§‹æ²¡æœ‰è¿™ä¸ªæ–‡ä»¶,æ‰§è¡Œ>>å’Œ>æ˜¯ä¸€æ ·çš„,ä½†æ˜¯å¦‚æœå†æ‰§è¡Œä¸€æ¬¡,æ‰§è¡Œ>å,æ–‡ä»¶å†…å®¹ä¸€æ ·,ä½†æ˜¯>>å°±æœ‰ä¸¤æ¬¡åŸæ¥çš„å†…å®¹,\n```linxus\ncat <<EOF > b.txt\nhaha\nlala\nmama\nbaba\ngege\njiejie\nEOF\n\ncat <<EOF >> b.txt\nhaha\nlala\nmama\nbaba\ngege\njiejie\nEOF\n```\næ‰€ä»¥æˆ‘ä»¬è¿™é‡Œå¯ä»¥ç”¨å¾ªç¯æ¥\n```\nfor i in {1..50}\ndo\ncat <<EOF > b.txt\nfield_$i,decimal,\"12,49\"\nEOF\ndone\n```\n\n```\nfor i in {1..50}\ndo\ncat <<EOF >> b.txt\nfield_$i,decimal,\"12,49\"\nEOF\ndone\n```"
    },
    {
      "id": "/2020/4/30/pythonè¯»å–Biggquery",
      "metadata": {
        "permalink": "/blog/2020/4/30/pythonè¯»å–Biggquery",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-30-pythonè¯»å–Biggquery.md",
        "source": "@site/blog/2020-4-30-pythonè¯»å–Biggquery.md",
        "title": "pythonè¯»å–bigquery",
        "description": "å®‰è£…å®¢æˆ·ç«¯",
        "date": "2020-04-30T00:00:00.000Z",
        "formattedDate": "April 30, 2020",
        "tags": [
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          },
          {
            "label": "command line",
            "permalink": "/blog/tags/command-line"
          },
          {
            "label": "cat",
            "permalink": "/blog/tags/cat"
          },
          {
            "label": "<<EOF",
            "permalink": "/blog/tags/eof"
          },
          {
            "label": "loop",
            "permalink": "/blog/tags/loop"
          }
        ],
        "readingTime": 0.47,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "bigquery1",
          "title": "pythonè¯»å–bigquery",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "linux",
            "command line",
            "cat",
            "<<EOF",
            "loop"
          ]
        },
        "prevItem": {
          "title": "linuxé«˜çº§ç”¨æ³•",
          "permalink": "/blog/2020/4/30/linuxå‘½ä»¤"
        },
        "nextItem": {
          "title": "è®¾ç«‹Jenkinsåœ¨GKEä¸Š",
          "permalink": "/blog/2020/4/30/åˆ›å»ºjenkinsåœ¨GKE"
        }
      },
      "content": "## å®‰è£…å®¢æˆ·ç«¯\n```\npip install --upgrade google-cloud-bigquery[bqstorage,pandas]\n```\n<!--truncate-->\n## å¯¼å…¥å·¥å…·åŒ…,åˆ›å»ºå®¢æˆ·ç«¯å¯¹è±¡\n```\nfrom google.cloud import bigquery\n\nclient = bigquery.Client()\n```\n## è¿è¡ŒæŸ¥è¯¢\n```\nquery_job = client.query(\"\"\"\n    SELECT\n      CONCAT(\n        'https://stackoverflow.com/questions/',\n        CAST(id as STRING)) as url,\n      view_count\n    FROM `bigquery-public-data.stackoverflow.posts_questions`\n    WHERE tags like '%google-bigquery%'\n    ORDER BY view_count DESC\n    LIMIT 10\"\"\")\n\nresults = query_job.result()  # Waits for job to complete.\n```\n\n## è½¬æˆdataframe\n```\ndf = results.to_dataframe()\n```\n\n## æ˜¾ç¤ºæŸ¥è¯¢ç»“æœ\n```\ndf.iloc[:,:5] #æ˜¾ç¤ºdataframe\n```"
    },
    {
      "id": "/2020/4/30/åˆ›å»ºjenkinsåœ¨GKE",
      "metadata": {
        "permalink": "/blog/2020/4/30/åˆ›å»ºjenkinsåœ¨GKE",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-30-åˆ›å»ºjenkinsåœ¨GKE.md",
        "source": "@site/blog/2020-4-30-åˆ›å»ºjenkinsåœ¨GKE.md",
        "title": "è®¾ç«‹Jenkinsåœ¨GKEä¸Š",
        "description": "è®¾ç½®zoneå’Œä¸‹è½½ä»£ç ",
        "date": "2020-04-30T00:00:00.000Z",
        "formattedDate": "April 30, 2020",
        "tags": [
          {
            "label": "Jenkins",
            "permalink": "/blog/tags/jenkins"
          },
          {
            "label": "GKE",
            "permalink": "/blog/tags/gke"
          }
        ],
        "readingTime": 1.91,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "jenkins",
          "title": "è®¾ç«‹Jenkinsåœ¨GKEä¸Š",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "Jenkins",
            "GKE"
          ]
        },
        "prevItem": {
          "title": "pythonè¯»å–bigquery",
          "permalink": "/blog/2020/4/30/pythonè¯»å–Biggquery"
        },
        "nextItem": {
          "title": "Bigqueryå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/29/bq_å¸¸ç”¨å‘½ä»¤"
        }
      },
      "content": "è®¾ç½®zoneå’Œä¸‹è½½ä»£ç \n```\ngcloud config set compute/zone us-east1-d\ngit clone https://github.com/GoogleCloudPlatform/continuous-deployment-on-kubernetes.git\ncd continuous-deployment-on-kubernetes\n```\n<!--truncate-->\nåˆ›å»ºGKEé›†ç¾¤\n```\ngcloud container clusters create jenkins-cd \\\n--num-nodes 2 \\\n--machine-type n1-standard-2 \\\n--scopes \"https://www.googleapis.com/auth/projecthosting,cloud-platform\"\n```\næŸ¥è¯¢clusteræ˜¯å¦è¿è¡Œ\n```\ngcloud container clusters list\n```\n\nè·å–å‡­è¯å»è¿æ¥ä½ çš„GKE\n```\ngcloud container clusters get-credentials jenkins-cd\n```\nç¡®è®¤æ˜¯å¦èƒ½è¿æ¥åˆ°é›†ç¾¤\n```\nkubectl clusters-info\n```\n\nå®‰è£…Helm\n```\nwget https://storage.googleapis.com/kubernetes-helm/helm-v2.9.1-linux-amd64.tar.gz\n```\nè§£å‹\n```\ntar zxfv helm-v2.9.1-linux-amd64.tar.gz\ncp linux-amd64/helm .\n```\n\næ·»åŠ è‡ªå·±ä½œä¸ºäº‘çš„ç®¡ç†è€…ğŸ™†ç»™jenkinsæƒé™åˆ°é›†ç¾¤\n```\nkubectl create clusterrolebinding cluster-admin-binding --clusterrole=cluster-admin --user=$(gcloud config get-value account)\n```\n\nç»™Tilleré›†ç¾¤ç®¡ç†è€…æƒé™\n```\nkubectl create serviceaccount tiller --namespace kube-system\nkubectl create clusterrolebinding tiller-admin-binding --\nclusterrole=cluster-admin --serviceaccount=kube-system:tiller\n```\n\nåˆå§‹åŒ–helm,è¿™æ ·å¯ä»¥ä¿è¯Helm(Tiller)æœåŠ¡ç«¯æ˜¯æ­£ç¡®å®‰è£…åˆ°é›†ç¾¤ä¸Š\n```\n./helm init --service-account=tiller\n./helm repo update\n```\n\nç¡®è®¤helmæ˜¯å¦å®‰è£…æˆåŠŸ,åº”è¯¥çœ‹åˆ°å‡ºç°åœ¨æœåŠ¡ç«¯å’Œå®¢æˆ·ç«¯æ˜¯v2.9.1\n```\n./helm version\n```\n\n\nç”¨Helm CLIå‘½ä»¤å»éƒ¨ç½²è®¾ç½®\n```\n./helm install -n cd stable/jenkins -f jenkins/values.yaml --version 0.16.6 --wait\n```\n\nç¡®è®¤jenkins podè¿è¡Œ\n```\nkubectil get pods\n```\n\nè¿è¡Œå‘½ä»¤å»è®¾ç½®jenkins UIç•Œé¢\n```\nexport POD_NAME=$(kubectl get pods -l \"component=cd-jenkins-master\" -o jsonpath=\"{.items[0].metadata.name}\")\nkubectl port-forward $POD_NAME 8080:8080 >> /dev/null &\n```\n\næµ‹è¯•Jenkins Serviceæ˜¯å¦åˆ›å»ºæ­£ç¡®\n```\nkubectl get svc\n```\n\nè¿æ¥åˆ°Jenkins-Jenkinsä¼šè‡ªåŠ¨åˆ›å»ºå¯†ç ,è·å–å®ƒ,è¿è¡Œä¸€ä¸‹å‘½ä»¤:\n```\nprintf $(kubectl get secret cd-jenkins -o jsonpath=\"{.data.jenkins-admin-password}\" | base64 --decode);echo\n```\n\næˆ‘è¿™è¾¹å‡ºç°çš„å¯†ç æ˜¯\n```\nJrK3zwoGFI\n```\nç„¶åå»gcloud shell çš„Web Previewä¸Šé€‰æ‹©Preview on Port 8080,\n![png](../img/Jenkins/1.png)\nç„¶åè¾“å…¥\n```\nusername: admin\npassword: JrK3zwoGFI\n```\n![png](../img/Jenkins/2.png)\n\n\n## åˆ é™¤å‘½ä»¤:\n```\nkubectl get deployment\nkubectl delete deployment åå­—name\nkubectl get pod \n\n#åˆ é™¤podå,åˆ é™¤clusters\n```\ngcloud containers clusters delete name\n```\n![png](../img/Jenkins/3.png)"
    },
    {
      "id": "/2020/4/29/bq_å¸¸ç”¨å‘½ä»¤",
      "metadata": {
        "permalink": "/blog/2020/4/29/bq_å¸¸ç”¨å‘½ä»¤",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-29-bq_å¸¸ç”¨å‘½ä»¤.md",
        "source": "@site/blog/2020-4-29-bq_å¸¸ç”¨å‘½ä»¤.md",
        "title": "Bigqueryå¸¸ç”¨å‘½ä»¤",
        "description": "æŸ¥çœ‹æ•°æ®é›†çš„schema ä½¿ç”¨bq show æ•°æ®é›†",
        "date": "2020-04-29T00:00:00.000Z",
        "formattedDate": "April 29, 2020",
        "tags": [
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "command line",
            "permalink": "/blog/tags/command-line"
          },
          {
            "label": "github",
            "permalink": "/blog/tags/github"
          }
        ],
        "readingTime": 2.435,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "bq_command_line",
          "title": "Bigqueryå¸¸ç”¨å‘½ä»¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "gcp",
            "command line",
            "github"
          ]
        },
        "prevItem": {
          "title": "è®¾ç«‹Jenkinsåœ¨GKEä¸Š",
          "permalink": "/blog/2020/4/30/åˆ›å»ºjenkinsåœ¨GKE"
        },
        "nextItem": {
          "title": "GCS è¯»å†™ by python",
          "permalink": "/blog/2020/4/29/_GCSè¯»å†™by python"
        }
      },
      "content": "## æŸ¥çœ‹æ•°æ®é›†çš„schema ä½¿ç”¨bq show æ•°æ®é›†\n\n<!--truncate-->\n\n# å¢ bq mk, bk load [å…·ä½“å¯ä»¥å‚è€ƒ](https://cloud.google.com/bigquery/docs/loading-data-local#cli_1)\n```bq\nbq mk babaynames åˆ›å»ºæ–°çš„æ•°æ®é›†,åœ¨è‡ªå·±é¡¹ç›®ä¸­å‘½å\n#### åˆ›å»ºè¡¨æ ¼ bq load datasetID tableID data_file Schema\nbq load æ•°æ®é›†ID.è¡¨æ ¼ID(å¦‚æœç©ºå°±è‡ªå·±åˆ›å»ºä¸€ä¸ª)  æ•°æ®æ–‡ä»¶(æ¯”å¦‚txt) schemaç±»å‹\nbq load datasetID.tableid your_file name:string,gender:string,count:integer(your schema)\nbq load --source_format=AVRO fakedatas.customer \"gs://zz_bucket/avro/cust.avro\" (avroæ–‡ä»¶)\n```\nè¿˜å¯ä»¥æ”¹ç”¨ --autodetect æ ‡å¿—ï¼Œè€Œæ— éœ€æä¾›æ¶æ„å®šä¹‰ã€‚\n\n# åˆ  bq rm -r\n## åˆ é™¤æ•°æ®é›† bq rm\nbq rm -r æ•°æ®é›†id\n```\nbq rm -r babynames\n```\n# æ˜¾ç¤º bq ls, bq show\n### æ£€æµ‹è¡¨æ ¼æ˜¯å¦åˆ›å»ºæˆåŠŸæˆ–è€…æ›´æ–°æˆåŠŸ\nåˆ›å»ºå,å¯ä»¥é€šè¿‡bq ls æ•°æ®é›†id æŸ¥çœ‹æ˜¯å¦åˆ›å»ºæˆåŠŸ\nä¹Ÿå¯ä»¥é€šè¿‡bq show æ•°æ®é›†id.tableid æŸ¥çœ‹schema\n```\nbq ls æ˜¾ç¤ºæ‰€æœ‰dataset\nbq ls babaynames æ˜¾ç¤ºdatasetidçš„æ‰€æœ‰table\nbq show datasetid æ˜¾ç¤ºdatasetçš„ACL(æƒé™) æ¯”å¦‚å¯ä»¥çœ‹åˆ° è°æ˜¯owners,writers,readers\nbq show babynames.names2010 æ˜¾ç¤ºtableçš„schemaç±»å‹,å¤šå°‘æ–‡æœ¬æ•°,å­—æ®µ\n```\n\n# æŸ¥ bq query --use_legacy_sql=false 'select * from dataset.table'\n```\n## è¿è¡Œsqlè¯­å¥å‘½ä»¤\næ€»ä½“æ ¼å¼å°±æ˜¯ bq query --use_legacy_sql=false 'select å­—æ®µ è€¦åˆå­—æ®µ(æ¯”å¦‚count(*)) from datasetid.tableid where æ¡ä»¶ order by å­—æ®µ (åšæ’åºASC,DESC) Limit æ•°å­—(é™åˆ¶æ¡æ•°)'\næ³¨æ„çš„åœ°æ–¹æ˜¯ \n### use_legacy_sql=false è¡¨ç¤ºä½¿ç”¨æ ‡å‡†sqlè¯­å¥\n### æ¡ä»¶çš„æ—¶å€™å¯ä»¥ä½¿ç”¨åŒå¼•å·åšåŒºåˆ†\"\"\n```sql\nbq query \"select name,count from babynames.names2010 where gender = 'F' Order by count desc limit 5\"\n\nbq query --use_legacy_sql=false 'SELECT word,SUM(word_count) AS count FROM `bigquery-public-data`.samples.shakespeare WHERE word LIKE \"%raisin%\" GROUP BY word'\n\nç¬¬äºŒä¸ªä¾‹å­æ˜¯é€‰æ‹©ä»bqå…¬å…±é›†ä¸­é€‰æ‹©samplesè¿™ä¸ªdataset,ç„¶åä»è¿™ä¸ªdatasetçš„shakespeareè¡¨ä¸­é€‰æ‹©wordå­—æ®µ, æ‰§è¡Œæ¡ä»¶æ˜¯ wordå­—æ®µå¿…é¡»ç­‰äº\"huzzah\"\nbq query --use_legacy_sql=false 'SELECT word FROM `bigquery-public-data`.samples.shakespeare WHERE word = \"huzzah\"'\n```\n\n## è¿è¡Œå¸®åŠ©å‘½ä»¤\n```\nbq help query\n```\n\n### ä¸‹è½½æ•°æ®åˆ°é¡¹ç›®ä¸­\nä½¿ç”¨wget æ•°æ®æºè¿æ¥(æ¯”å¦‚zip,txt,csvç­‰)\n```wget\nwget http://www.ssa.gov/OACT/babynames/names.zip\n```\n### è§£å‹ç¼©zipæ–‡ä»¶åˆ°é¡¹ç›®ä¸­\n```\nunzip names.zip\n```"
    },
    {
      "id": "/2020/4/29/_GCSè¯»å†™by python",
      "metadata": {
        "permalink": "/blog/2020/4/29/_GCSè¯»å†™by python",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-29_GCSè¯»å†™by python.md",
        "source": "@site/blog/2020-4-29_GCSè¯»å†™by python.md",
        "title": "GCS è¯»å†™ by python",
        "description": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è°·æ­Œçš„Pythonå®¢æˆ·ç«¯APIå°†æ–‡ä»¶ä¸Šä¼ åˆ°è°·æ­Œäº‘å­˜å‚¨ã€‚",
        "date": "2020-04-29T00:00:00.000Z",
        "formattedDate": "April 29, 2020",
        "tags": [
          {
            "label": "terraform",
            "permalink": "/blog/tags/terraform"
          },
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "compute engine",
            "permalink": "/blog/tags/compute-engine"
          },
          {
            "label": "vm",
            "permalink": "/blog/tags/vm"
          }
        ],
        "readingTime": 1.14,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "GCS1",
          "title": "GCS è¯»å†™ by python",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "terraform",
            "gcp",
            "compute engine",
            "vm"
          ]
        },
        "prevItem": {
          "title": "Bigqueryå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/29/bq_å¸¸ç”¨å‘½ä»¤"
        },
        "nextItem": {
          "title": "gsutilå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/29/_gsutilå¸¸ç”¨å‘½ä»¤"
        }
      },
      "content": "æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è°·æ­Œçš„Pythonå®¢æˆ·ç«¯APIå°†æ–‡ä»¶ä¸Šä¼ åˆ°è°·æ­Œäº‘å­˜å‚¨ã€‚\n\n\n# æ–¹æ³•ä¸€: \né¦–å…ˆï¼Œå¦‚ä¸‹å®‰è£…apiå®¢æˆ·ç«¯ã€‚\n\n>\n```\npip install --upgrade google-api-python-client \n```\nç„¶åï¼Œå¯ç”¨apièº«ä»½éªŒè¯ä»¥è·å–åº”ç”¨ç¨‹åºé»˜è®¤å‡­æ®ã€‚\n\n>\n```\ngcloud beta auth application-default login \n```\nä»¥ä¸‹æ˜¯ä½¿ç”¨åº”ç”¨ç¨‹åºé»˜è®¤å‡­æ®å°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°Googleäº‘å­˜å‚¨çš„ç¤ºä¾‹ä»£ç ã€‚\n\n```\nfrom googleapiclient import discovery\nfrom oauth2client.client import GoogleCredentials\n\ncredentials = GoogleCredentials.get_application_default()\nservice = discovery.build('storage', 'v1', credentials=credentials)\n\nfilename = './account_id_schema_new.csv'\n\nbucket = 'bq-pandas-bucket'\n\nbody = {'name': 'dest_file_name.csv'}\n\nreq = service.objects().insert(bucket=bucket, body=body, media_body=filename)\nesp = req.execute()\n```\n\n# æ–¹æ³•äºŒ--ä»…ä»…éœ€è¦å®‰è£…ä¸¤ä¸ªåŒ…\n```\npip install dask[dataframe] --upgrade --user\npip install gcsfs --user\n```\n\n## ä¾‹å­\n![png](../img/google/gcs/gcs1/1.png)\n\nåŸæ¥æ— è®ºç”¨pandavroæˆ–è€…pandaséƒ½æ˜¯è¯»å–ä¸äº†GCSçš„æ–‡ä»¶çš„\n\nä½†æ˜¯å®‰è£…åŒ…å,å°±å¯ä»¥è¯»å–GCSæ–‡ä»¶äº†\n![png](../img/google/gcs/gcs1/2.png)\n\nç„¶åå†™å…¥gcs,å°±æƒ³å¹³æ—¶é‚£æ ·,ç›´æ¥to_csvå°±å¯ä»¥äº†\n![png](../img/google/gcs/gcs1/3.png)\n\n```\nimport dask.bag as db\nb = db.read_avro('gs://zz_mm_bucket/account_id_schema_new.avro')\ndf = b.to_dataframe()\n```"
    },
    {
      "id": "/2020/4/29/_gsutilå¸¸ç”¨å‘½ä»¤",
      "metadata": {
        "permalink": "/blog/2020/4/29/_gsutilå¸¸ç”¨å‘½ä»¤",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-29_gsutilå¸¸ç”¨å‘½ä»¤.md",
        "source": "@site/blog/2020-4-29_gsutilå¸¸ç”¨å‘½ä»¤.md",
        "title": "gsutilå¸¸ç”¨å‘½ä»¤",
        "description": "gsutilå‘½ä»¤å¿«é€Ÿå…¥é—¨",
        "date": "2020-04-29T00:00:00.000Z",
        "formattedDate": "April 29, 2020",
        "tags": [
          {
            "label": "terraform",
            "permalink": "/blog/tags/terraform"
          },
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "compute engine",
            "permalink": "/blog/tags/compute-engine"
          },
          {
            "label": "vm",
            "permalink": "/blog/tags/vm"
          }
        ],
        "readingTime": 1.12,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "gsutil",
          "title": "gsutilå¸¸ç”¨å‘½ä»¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "terraform",
            "gcp",
            "compute engine",
            "vm"
          ]
        },
        "prevItem": {
          "title": "GCS è¯»å†™ by python",
          "permalink": "/blog/2020/4/29/_GCSè¯»å†™by python"
        },
        "nextItem": {
          "title": "ä½¿ç”¨terraformåŸºæœ¬è¯­æ³•å’Œåˆ›å»ºvm",
          "permalink": "/blog/2020/4/27/_terraform"
        }
      },
      "content": "[gsutilå‘½ä»¤å¿«é€Ÿå…¥é—¨](https://cloud.google.com/storage/docs/quickstart-gsutil)\n\n<!--truncate-->\n```\nmb \ngsutil mb -l us-east1 gs://my-awesome-bucket/ #åˆ›å»ºbucket\n\ncp å¤åˆ¶ä¸‹è½½\ngsutil cp Desktop/kitten.png gs://my-awesome-bucket å¤åˆ¶æ–‡ä»¶åˆ°bucket\ngsutil cp gs://my-awesome-bucket/kitten.png Desktop/kitten2.png ä»bucketä¸Šä¸‹è½½æ–‡ä»¶åˆ°æœ¬åœ°\ngsutil cp gs://my-awesome-bucket/kitten.png gs://my-awesome-bucket/just-a-folder/kitten3.png å¤åˆ¶bucketé‡Œçš„æ–‡ä»¶åˆ°bucketé‡Œé¢çš„æ–‡ä»¶å¤¹ä¸­\n```\n<!--truncate-->\n```\nls åˆ—ä¸¾\ngsutil ls gs://my-awesome-bucket åˆ—ä¸¾bucketå†…å®¹\ngsutil ls -l gs://my-awesome-bucket/kitten.png åˆ—ä¸¾bucketæ–‡ä»¶çš„è¯¦ç»†ä¿¡æ¯\n\nacl account credential limit æƒé™\ngsutil acl ch -u AllUsers:R gs://my-awesome-bucket/kitten.png\nä½¿ç”¨ gsutil acl ch å‘½ä»¤å‘æ‰€æœ‰ç”¨æˆ·æˆäºˆå­˜å‚¨åœ¨å­˜å‚¨åˆ†åŒºä¸­çš„å¯¹è±¡çš„è¯»å–æƒé™\ngsutil acl ch -d AllUsers gs://my-awesome-bucket/kitten.png\nä½¿ç”¨ gsutil acl ch å‘½ä»¤å‘æ‰€æœ‰ç”¨æˆ·ç§»é™¤å­˜å‚¨åœ¨å­˜å‚¨åˆ†åŒºä¸­çš„å¯¹è±¡çš„è¯»å–æƒé™\n\niam -å‘æŸäººæˆäºˆå’Œç§»é™¤æ‚¨çš„å­˜å‚¨åˆ†åŒºçš„è®¿é—®æƒé™\ngsutil iam ch user:jane@gmail.com:objectCreator,objectViewer gs://my-awesome-bucket\ngsutil iam ch -d user:jane@gmail.com:objectCreator,objectViewer gs://my-awesome-bucket\n\nrm æ¸…é™¤\ngsutil rm gs://my-awesome-bucket/kitten.png åˆ é™¤æ–‡ä»¶\n\ngsutil rm -r gs://my-awesome-bucket æ¸…é™¤bucket\n```"
    },
    {
      "id": "/2020/4/27/_terraform",
      "metadata": {
        "permalink": "/blog/2020/4/27/_terraform",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-27_terraform.md",
        "source": "@site/blog/2020-4-27_terraform.md",
        "title": "ä½¿ç”¨terraformåŸºæœ¬è¯­æ³•å’Œåˆ›å»ºvm",
        "description": "æˆ‘è§‰å¾—terraformçš„åŸºæœ¬è¯­æ³•å°±æ˜¯å­—å…¸å¯¹è±¡å¼è¯­æ³•.",
        "date": "2020-04-27T00:00:00.000Z",
        "formattedDate": "April 27, 2020",
        "tags": [
          {
            "label": "terraform",
            "permalink": "/blog/tags/terraform"
          },
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "compute engine",
            "permalink": "/blog/tags/compute-engine"
          },
          {
            "label": "vm",
            "permalink": "/blog/tags/vm"
          }
        ],
        "readingTime": 9.965,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "terraform1",
          "title": "ä½¿ç”¨terraformåŸºæœ¬è¯­æ³•å’Œåˆ›å»ºvm",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "terraform",
            "gcp",
            "compute engine",
            "vm"
          ]
        },
        "prevItem": {
          "title": "gsutilå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/29/_gsutilå¸¸ç”¨å‘½ä»¤"
        },
        "nextItem": {
          "title": "å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
          "permalink": "/blog/2020/4/26/å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“"
        }
      },
      "content": "æˆ‘è§‰å¾—terraformçš„åŸºæœ¬è¯­æ³•å°±æ˜¯å­—å…¸å¯¹è±¡å¼è¯­æ³•.\n\næ€»ä½“ç»“æ„å°±æ˜¯ \n1. instance.tf ç”¨æ¥åˆ›ä½œèµ„æºçš„æ–‡ä»¶,æ¯”å¦‚vm instance,storage bucket,bigqueryç­‰\n\n2. variables.tf å‚æ•°å˜é‡æ–‡ä»¶,ç”¨æ¥å†™é‚£äº›å˜é‡çš„,å˜é‡çš„æ ¼å¼ä¸º variable \"project\" {} å°±æ˜¯: variable + åå­— + {}\n\n3. terraform.tfvars ç”¨æ¥å†™å˜é‡å…·ä½“ç­‰äºä»€ä¹ˆçš„, æ¯”å¦‚ project = \"terraform-45110831\"\n\n4. output.tf åœ¨åˆ›å»ºå®ä¾‹å,æ‰“å°è¾“å‡ºæˆ‘ä»¬è§‰å¾—é‡è¦çš„å‚æ•°, å…·ä½“æ ¼å¼ output åå­— {value = \"${å˜é‡}\"} å¦‚output \"ip\" {value = \"${google_compute_address.vm_static_ip.address}\"} å£è¯€: 2ç¾å…ƒ1file4å¼•å·,ç®€ç§°\"214\"!!\n\n<!--truncate-->\n\n## å…¶ä¸­è¯¦ç»†çš„ç”¨æ³•æˆ‘ä»¬å¯ä»¥å»[å®˜ç½‘9æ­¥æ•™ç¨‹å­¦ä¹ ](https://learn.hashicorp.com/terraform/gcp/change),éå¸¸ç®€å•,ä½†æ˜¯å¾ˆå¤šå‘,ä½†æ˜¯èµ°å®Œå‘å,æ„Ÿè§‰å°±åŸºæœ¬ä¸Šæ‰‹äº†\n\n## å…¶ä¸­5ä¸ªç‚¹éœ€è¦æ³¨æ„çš„æ˜¯: \n\n1. å˜é‡çš„å†™æ³• \"${var.project}\"\n   \n2. å¦‚æœå˜é‡æ˜¯ä¸ªæ–‡ä»¶çš„è¯: \"${file(\"${var.jupyter_sh}\")}\"  ${file(\"${var.jupyter.sh}\")} ä¹Ÿå°±æ˜¯ \"${file(\"${å˜é‡}\")}\"\n   \n3. è¿˜æœ‰å°±æ˜¯å­—å…¸å±æ€§éƒ½æ˜¯ç”¨.æ¥å¼•ç”¨\n   \n4. tagçš„ä½¿ç”¨,å› ä¸ºtagå±æ€§çš„æ·»åŠ å¯¹äºvm instanceå°¤å…¶é‡è¦\n\n5. ä½¿ç”¨meta_startup_scriptè„šæœ¬,å¯ä»¥åœ¨åˆ›å»ºvm instanceåé€šè¿‡è„šæœ¬è¿è¡Œç¨‹åº,éå¸¸æœ‰ç”¨\n   \n## ä½¿ç”¨vs codeè¿æ¥è¿œç¨‹æœåŠ¡å™¨\n\nåœ¨vs code ç•Œé¢ æŒ‰fn+F1, \n```\nF1\nssh -i ~/.ssh/id_rsa flybird@34.73.166.222 (è¿æ¥è¿œç¨‹æœåŠ¡å™¨)\n```\nè¿æ¥æˆåŠŸå,æˆ‘ä»¬å°±å¯ä»¥åœ¨æœåŠ¡å™¨å‡†å¤‡åˆ›å»ºvm instanceäº†\n# ä½¿ç”¨terraformåˆ›å»ºVM\nä½¿ç”¨terraformå¯ä»¥å¾ˆå¿«çš„,å¯å¤åˆ¶æ€§çš„é…ç½®ä¸€ä¸ªvmæœºå™¨\n<!--truncate-->\n# 1 é¦–å…ˆæˆ‘ä»¬è¦å®‰è£…terraform,å®‰è£…çš„å…·ä½“æ•™ç¨‹è¯·çœ‹[terraformå®‰è£…](https://learn.hashicorp.com/terraform/gcp/install)\n\nå¤§è‡´æ­¥éª¤æ˜¯\n```\nä¸‹è½½ terraform_0.12.24_linux_amd64.zip\nunzip terraform_0.12.24_linux_amd64.zip\nsudo snap install terraform å®‰è£…terraform\nterraform ç¡®è®¤terraformæ˜¯å¦å®‰è£…æˆåŠŸ\n```\n\nterraformå®‰è£…å¥½å,æˆ‘ä»¬å»GCP>>APIs$Services>>Credentialsåˆ›å»ºservice account,ä¸‹è½½jsonæ–‡ä»¶,ä¿å­˜å¥½\nterraformåˆ›å»ºæ•™ç¨‹æˆ‘ä»¬å¯ä»¥å»[terraformå…¥é—¨æ•™ç¨‹](https://learn.hashicorp.com/terraform/gcp/change)çœ‹åˆ°\n\n## 2 æˆ‘ä»¬è¿™é‡Œä¼šåˆ›å»ºä¸€ä¸ªinstance.tfæ–‡ä»¶\n```\nprovider \"google\" {\n  credentials = \"terraform-45110831-450974fa2608.json\"\n  project = \"terraform-45110831\"\n  region  = \"us-central1\"\n  zone    = \"us-central1-a\"\n}\nresource \"google_compute_network\" \"vpc_network\" {\n  name = \"terraform-network\"\n}\nresource \"google_compute_instance\" \"default\" {\n  project      = \"terraform-45110831\"\n  name         = \"terraform\"\n  machine_type = \"n1-standard-1\"\n  zone         = \"us-central1-a\"\n\n  boot_disk {\n    initialize_params {\n      image = \"debian-cloud/debian-9\"\n    }\n  }\n\n  network_interface {\n    network = \"default\"\n    access_config {\n    }\n  }\n}\n```\n\nresource åé¢è·Ÿä¸¤ä¸ªå­—æ®µ,ç¬¬ä¸€ä¸ªæ˜¯resource typeå­—æ®µå’Œresource name, è¿™é‡Œçš„resource typeæ˜¯google_compute_instance, nameæ˜¯ terraform, google_compute_instance ä¼šè‡ªåŠ¨å‘Šè¯‰terraformè¿™ä¸ªæ˜¯è°·æ­Œçš„provider\n\n## 3 å†™å¥½é…ç½®å,æˆ‘ä»¬è¾“å…¥ä¸€ä¸‹å‘½ä»¤\n```\nterraform init\n```\nè¿™ä¸ªå‘½ä»¤æˆ–åˆå§‹åŒ–å¾ˆå¤šåç»­ä¼šè¢«ç”¨åˆ°çš„å‘½ä»¤çš„æœ¬åœ°è®¾ç½®å’Œæ•°æ®\ngoogle provider plugin ä¼šè¢«ä¸‹è½½å’Œå®‰è£…\n\n## 4 åˆå§‹åŒ–å,æˆ‘ä»¬å¯ä»¥æŸ¥çœ‹æ•´ä½“è®¡åˆ’,æŸ¥çœ‹è®¾ç½®æ˜¯å¦ç¬¦åˆæˆ‘ä»¬çš„è¦æ±‚,è¾“å…¥è¿™ä¸ªå‘½ä»¤çš„æ—¶å€™,GCPä¸ä¼šéƒ¨ç½²vm\n```\nterraform plan\n```\n\n## 5 è§‰å¾—æ²¡æœ‰é—®é¢˜,æˆ‘ä»¬å°±å¯ä»¥åº”ç”¨äº†\n```\nterraform apply\n```\nè¿™ä¸ªå‘½ä»¤å°±ä¼šæ‰§è¡Œä¹‹å‰plançš„ä¸œè¥¿\n```\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  + create\n\nTerraform will perform the following actions:\n\n  # google_compute_instance.default will be created\n  + resource \"google_compute_instance\" \"default\" {\n      + can_ip_forward       = false\n      + cpu_platform         = (known after apply)\n      + deletion_protection  = false\n      + guest_accelerator    = (known after apply)\n      + id                   = (known after apply)\n      + instance_id          = (known after apply)\n      + label_fingerprint    = (known after apply)\n      + machine_type         = \"n1-standard-1\"\n      + metadata_fingerprint = (known after apply)\n      + name                 = \"terraform\"\n      + project              = \"qwiklabs-gcp-42390cc9da8a4c4b\"\n      + self_link            = (known after apply)\n      + tags_fingerprint     = (known after apply)\n      + zone                 = \"us-central1-a\"\n\n      + boot_disk {\n          + auto_delete                = true\n          + device_name                = (known after apply)\n          + disk_encryption_key_sha256 = (known after apply)\n          + kms_key_self_link          = (known after apply)\n          + source                     = (known after apply)\n\n          + initialize_params {\n              + image  = \"debian-cloud/debian-9\"\n              + labels = (known after apply)\n              + size   = (known after apply)\n              + type   = (known after apply)\n            }\n        }\n\n      + network_interface {\n          + address            = (known after apply)\n          + name               = (known after apply)\n          + network            = \"default\"\n          + network_ip         = (known after apply)\n          + subnetwork         = (known after apply)\n          + subnetwork_project = (known after apply)\n\n          + access_config {\n              + assigned_nat_ip = (known after apply)\n              + nat_ip          = (known after apply)\n              + network_tier    = (known after apply)\n            }\n        }\n\n      + scheduling {\n          + automatic_restart   = (known after apply)\n          + on_host_maintenance = (known after apply)\n          + preemptible         = (known after apply)\n\n          + node_affinities {\n              + key      = (known after apply)\n              + operator = (known after apply)\n              + values   = (known after apply)\n            }\n        }\n    }\n\nPlan: 1 to add, 0 to change, 0 to destroy.\n\nDo you want to perform these actions?\n  Terraform will perform the actions described above.\n  Only 'yes' will be accepted to approve.\n\n  Enter a value:\n```\n\næˆ‘ä»¬çœ‹åˆ° +, è¿™æ„å‘³Terraformä¼šåˆ›å»ºè¿™ä¸ªèµ„æº,æˆ‘ä»¬èƒ½çœ‹åˆ°å¾ˆå¤šå±æ€§,å¦‚æœæœ‰çš„valueæ˜¯æ˜¾ç¤ºcomputed,è¿™æ„å‘³ç€è¿™valueä¼šç­‰åˆ°resourceåˆ›å»ºåæ‰çŸ¥é“\n\n## 6 æ˜¾ç¤ºvm çš„é…ç½®\n```\nterraform show\n```\n\n## 7.1 æˆ‘ä»¬å¯ä»¥ä½¿ç”¨terraformå»ä¿®æ”¹resources\næ¯”å¦‚æˆ‘ä»¬å¯ä»¥åœ¨ resource google_compute_instance ä¸Šæ·»åŠ tags\n### æ•²é»‘æ¿!!! å¦‚æœtagsä¸Šæ·»åŠ \"http-server\",\"https-server\"å,Firewallsé˜²ç«å¢™å°±allow http trafficå’Œ https trafficäº†\n\n```\nresource \"google_compute_instance\" \"default\" {\n  project      = \"terraform-45110831\"\n  name         = \"terraform\"\n  machine_type = \"n1-standard-1\"\n  zone         = \"us-central1-a\"\n  tags         = [\"web\", \"dev\",\"http-server\",\"https-server\"]\n```\nç„¶ååœ¨ç»ˆç«¯è¾“å…¥terraform init, terraform planå,å°±ä¼šå‡ºç°\n```\nTerraform will perform the following actions:\n\n  ~ google_compute_instance.default\n    tags.#:         \"0\" => \"2\"\n    tags.292811013: \"\" => \"dev\"\n    tags.365508689: \"\" => \"web\"\n```\nterraform apply å°±ä¼šå¯¹resourceè¿›è¡Œä¿®æ”¹\n\n## 7.2 ä¹Ÿæ”¯æŒç ´åæ€§ä¿®æ”¹,æ¯”å¦‚æ›´æ¢ç£ç›˜é•œåƒ,æ¯”å¦‚ä»Debian 9æ˜ åƒæ›´æ”¹ä¸ºä½¿ç”¨Googleçš„Container-Optimized OS\n```\nboot_disk {\n    initialize_params {\n      image = \"cos-cloud/cos-stable\"\n    }\n  }\n```\nterrform init> terrform plan >terrform applyå\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°internal IP å’Œ external ipæ”¹å˜äº†,ç„¶åæˆ‘ä»¬ç™»é™†è¿›vm instanceå,æˆ‘ä»¬ä¹‹å‰çš„æ‰€ä»¥èµ„æ–™éƒ½æ²¡æœ‰äº†\n<h1> æ‰€ä»¥å¦‚æœè¿›è¡Œdestructive changeå‰,ä¸€å®šè¦æ³¨æ„ </h1>\n\n\n## 8 terraform destroy\nè¾“å…¥å‘½ä»¤å:\n```\nAn execution plan has been generated and is shown below.\nResource actions are indicated with the following symbols:\n  - destroy\n\nTerraform will perform the following actions:\n\n  - google_compute_instance.default\n\n  - google_compute_network.vpc_network\n```\nterraform destroyå‘½ä»¤é”€æ¯èµ„æº,è¯¥å‘½ä»¤ç±»å‹äºterraform apply,terraformç¡®å®šå¿…é¡»é”€æ¯ç‰©ä»¶çš„é¡ºåº,å¦‚æœè¿˜æœ‰èµ„æº,GCPå°†ä¸å…è®¸åˆ é™¤VPCç½‘ç»œ,å› æ­¤Terraformä¼šç­‰åˆ°å®ä¾‹è¢«é”€æ¯åå†é”€æ¯ç½‘ç»œ,terraformæ‰§è¡Œæ“ä½œçš„æ—¶å€™,terraformå°†å»ºä¸€ä¸ªä¾èµ–å…³ç³»å›¾å·²ç¡®å®šé”€æ¯é¡ºåº.åœ¨å…·æœ‰å¤šä¸ªèµ„æºçš„æ›´å¤æ‚çš„æƒ…å†µä¸‹,Terraformå°†åœ¨å®‰å…¨çš„æƒ…å†µä¸‹å¹¶è¡Œæ‰§è¡Œæ“ä½œ.\n\n\n## GCPä¹Ÿå¯ä»¥åˆ é™¤\næˆ‘ä»¬å¯ä»¥å»GCP shellä¸­è¾“å…¥ä¸€ä¸‹å‘½ä»¤\n```\ngcloud compute instances delete instanceåå­—\n```\n\næˆ‘ä»¬è¿˜å¯ä»¥ä½¿resourceä¸resourceä¹‹é—´ç›¸äº’ä¾èµ–,ä½¿ç”¨depends_on = [\"\"]\næ¯”å¦‚æˆ‘å¯ä»¥ç°åœ¨åˆ›å»ºä¸€ä¸ªstorage bucket, æˆ‘ä»¬å¯ä»¥è®¾ç½®åœ¨åˆ›å»ºstorage bucketå‰ä¸€å®šè¦åˆ›å»º vmå…ˆ\n\nresource \"google\n```\nresource \"google_compute_instance\" \"default\" {\n  project      = \"terraform-45110831\"\n  name         = \"terraform\"\n  machine_type = \"n1-standard-1\"\n  zone         = \"us-central1-a\"\n  tags         = [\"web\", \"dev\"]\n}\n\nresource \"google_storage_bucket\" \"example_bucket\" {\n  depends_on = [\"google_compute_instance.default\"]\n  ...\n}\n```\n\n## 9 å¯ä»¥åœ¨æœ¬ç»ˆç«¯è¾“å…¥å‘½ä»¤[Provisioners](https://www.terraform.io/docs/provisioners/index.html)\n```\nresource \"google_compute_instance\" \"vm_instance\" {\n  name         = \"terraform-instance\"\n  machine_type = \"f1-micro\"\n  tags         = [\"web\", \"dev\"]\n\n  provisioner \"local-exec\" {\n    command = \"echo ${google_compute_instance.vm_instance.name}:  ${google_compute_instance.vm_instance.network_interface.0.access_config.0.nat_ip} >> ip_address.txt\"\n  }\n```\n## æ¯ä¸ªvmå®ä¾‹å¯ä»¥å…·æœ‰å¤šä¸ªç½‘ç»œæ¥å£,å› æ­¤æˆ‘ä»¬çš„network interface.0å°±æ˜¯å¼•ç”¨ç¬¬ä¸€ä¸ª,æ¯ä¸ªç½‘ç»œæ¥å£ä¹Ÿå…·æœ‰å¤šä¸ªaccess_configå¿«,æˆ‘ä»¬é€‰æ‹©acess_config.0æŒ‡å®šå¼•ç”¨ç¬¬ä¸€ä¸ª\n# terraformçš„æ ¸å¿ƒåœ¨äºå˜é‡,æˆ‘ä¸ªäººæ„Ÿè§‰å°±åƒæ˜¯javascriptçš„å­—å…¸å¯¹è±¡,æ‰€ä»¥å±æ€§éƒ½ç”¨.æ¥å¼•ç”¨, å¦å¤–å˜é‡çš„è¡¨ç¤ºæ–¹æ³•ä¸ºç¾å…ƒç¬¦å·$ + {å˜é‡} å°±æ˜¯ ${google_compute_instance.vm_instance}\n## ä½†æ˜¯ä½ å‘ç°ip_address.txtåœ¨terraform applyåæ²¡æœ‰åˆ›å»ºæˆåŠŸ\nå› ä¸ºé¢„é…å™¨provisioneråªæ˜¯åœ¨åˆ›å»ºèµ„æºæ—¶è¿è¡Œ,ä½†æ˜¯æ·»åŠ provisionerä¸ä¼šå¼ºåˆ¶é”€æ¯å’Œé‡æ–°åˆ›å»ºè¯¥èµ„æº,æ‰€ä»¥æˆ‘ä»¬è¦ç”¨terraform taintå‘Šè¯‰terraform,éœ€è¦é‡æ–°åˆ›å»ºå®ä¾‹\n```\nterraform taint google_compute_instance.vm_instance\nterraform apply\ncat ip_address.txt\n```\næˆ‘ä»¬å¯ä»¥çœ‹åˆ°txtæ–‡ä»¶å†…å®¹äº†\n\n\n## 10.1 åˆ›å»ºvm instanceæˆåŠŸå,æˆ‘ä»¬éœ€è¦æ·»åŠ sshkey,ç„¶åæˆ‘ä»¬å¯ä»¥è¿æ¥external ip,é€šè¿‡ä»¥ä¸‹å‘½ä»¤:\n```linux\nssh-keygen äº§ç”Ÿid-rsa.pub, å¤åˆ¶å…¶å†…å®¹,åœ¨vmçš„meta dataä¸Šç²˜è´´å¥½\nssh username@external_ip\n```\n## 10.2 å¦‚æœå‡ºç°permisson dennied,å¯ä»¥ç›´æ¥åœ¨vmæœºä¸ŠæŠŠssh keyåˆ æ‰,ç„¶ååœ¨æœ¬åœ°é‡æ–°åˆ›å»ºssh key,ç„¶åå¤åˆ¶ç²˜è´´åˆ° meta dataä¸Š\n\n## 11 èµ·å§‹è„šæœ¬metadata_startup_script\næˆ‘ä»¬åœ¨åˆ›å»ºresouce google_compute_instance çš„æ—¶å€™,æˆ‘ä»¬å¯ä»¥æ·»åŠ ä¸€ä¸ªmetadata_startup_scriptå±æ€§,è¿™ä¸ªæ˜¯ç”¨æ¥è¿è¡Œåœ¨åˆ›å»ºçš„vmè™šæ‹Ÿæœºä¸Šçš„,æ¯”å¦‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è¿™ä¸ªè„šæœ¬åˆ›å»º[jupyterå’Œpythonçš„å·¥å…·(è¯·çœ‹æ¡ˆä¾‹)](jupyterhub_GCP)ç­‰,è„šæœ¬æ˜¯åœ¨rootç›®å½•è¿è¡Œ,\n\n### å¦‚æœæˆ‘ä»¬æƒ³åœ¨homeç›®å½•è¿è¡Œ,è¯·cd home/ç”¨æˆ·å\n```linux\nmetadata_startup_script = \"${file(\"${var.jupyter_sh}\")}\" \n```"
    },
    {
      "id": "/2020/4/26/å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
      "metadata": {
        "permalink": "/blog/2020/4/26/å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-26å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“.md",
        "source": "@site/blog/2020-4-26å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“.md",
        "title": "å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
        "description": "portæ˜¯serviceæœåŠ¡çš„ç«¯å£",
        "date": "2020-04-26T00:00:00.000Z",
        "formattedDate": "April 26, 2020",
        "tags": [
          {
            "label": "nginx",
            "permalink": "/blog/tags/nginx"
          },
          {
            "label": "port",
            "permalink": "/blog/tags/port"
          },
          {
            "label": "target",
            "permalink": "/blog/tags/target"
          },
          {
            "label": "load-balance",
            "permalink": "/blog/tags/load-balance"
          }
        ],
        "readingTime": 3.155,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "nginx",
          "title": "å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "nginx",
            "port",
            "target",
            "load-balance"
          ]
        },
        "prevItem": {
          "title": "ä½¿ç”¨terraformåŸºæœ¬è¯­æ³•å’Œåˆ›å»ºvm",
          "permalink": "/blog/2020/4/27/_terraform"
        },
        "nextItem": {
          "title": "è¯»å–avroæ–‡ä»¶çš„schema",
          "permalink": "/blog/2020/4/21/pythonè¯»å–avroçš„schema"
        }
      },
      "content": "##  portæ˜¯serviceæœåŠ¡çš„ç«¯å£\n## targetportæ˜¯podä¹Ÿå°±æ˜¯å®¹å™¨çš„ç«¯å£\n## nodeportæ˜¯å®¹å™¨æ‰€åœ¨å®¿ä¸»æœºçš„ç«¯å£(é€šè¿‡serviceæš´éœ²ç»™å®¿ä¸»æœº,è€Œportå»æ²¡æœ‰)\n<!--truncate-->\nportçš„ä¸»è¦ä½œç”¨æ˜¯clustersé›†ç¾¤é‡Œé¢çš„ä¸€ä¸ªpodè®¿é—®å…¶ä»–podçš„æ—¶å€™,éœ€è¦ç«¯å£port,æ¯”å¦‚é›†ç¾¤é‡Œé¢nginxéœ€è¦è®¿é—®mysql,é‚£ä¹ˆä¹…éœ€è¦mysqlçš„target port,\n```mysql\napiVersion: v1\n kind: Service\n metadata:\n  name: mysql-service\n spec:\n  ports:\n  - port: 33306\n    targetPort: 3306\n  selector:\n   name: mysql-pod\n```\næ¯”å¦‚nginxé€šè¿‡è®¿é—®serviceçš„33306ç«¯å£,serviceæ ¹æ®selectorä¸­çš„name,å°†è¯·æ±‚è½¬å‘åˆ°mysql-podè¿™ä¸ªpodçš„3306ç«¯å£\né€šè¿‡POSTåˆ›å»º service\n```\n{\n    \"kind\": \"Service\",\n    \"apiVersion\": \"v1\",\n    \"metadata\": {\n        \"name\": \"my-service\"\n    },\n    \"spec\": {\n        \"selector\": {\n            \"app\": \"MyApp\"\n        },\n        \"ports\": [\n            {\n                \"name\": \"http\",\n                \"protocol\": \"TCP\",\n                \"port\": 80,\n                \"targetPort\": 9376\n            },\n            {\n                \"name\": \"https\",\n                \"protocol\": \"TCP\",\n                \"port\": 443,\n                \"targetPort\": 9377\n            }\n        ]\n    }\n}\n```\nå¯¹äºæ¯ä¸ªè¿è¡Œçš„pod,kuberneteå°†å…¶æ·»åŠ ç»™ç°æœ‰çš„serviceçš„å…¨å±€å˜é‡, æ¯”å¦‚å«åš\"redis-master\"çš„service,å¯¹å¤–æ˜ å°„6379ç«¯å£,\nserviceè¦æƒ³è¢«podä½¿ç”¨,å¿…é¡»å…ˆæ¯”podå»ºç«‹\næ‰€ä»¥æ€»ä½“æµç¨‹å°±podä¹‹é—´éƒ½æ˜¯é€šè¿‡serviceæ¥ç›¸äº’è®¿é—®,æ‰€ä»¥å…ˆserviceçš„port,ç„¶åserviceé€šè¿‡selectoræ‰¾åˆ°name,å†æŠŠè¯·æ±‚å‘é€åˆ°nameå¯¹åº”çš„target port\n\n# [NginxåŸºç¡€çŸ¥è¯†](https://www.cnblogs.com/mq0036/p/9794540.html)\n\n## nginxèƒ½åšçš„äº‹æƒ…:\n1 [æ­£å‘,æ–¹å‘ä»£ç†](https://www.jianshu.com/p/ae76c223c6ef)\n2 è´Ÿè½½å‡è¡¡\n3 httpæœåŠ¡å™¨-åŠ¨é™åˆ†ç¦»\n\n![png](../img/kubernetes/nginx/nginx.png)\n\n### æ­£å‘ä»£ç†æ˜¯nginx proxyç»™clientä»£ç†,ç„¶åå¯¹æ¥Server,è·å–å†…å®¹\n### æ–¹å‘ä»£ç†æ˜¯proxyç»™Serveråšä»£ç†,clientsè®¿é—®proxyè·å–å†…å®¹\n\n### nginxçš„è´Ÿè½½å‡è¡¡æœ‰ä¸€ä¸‹å‡ ä¸ªç­–ç•¥:\n1 RR- æŒ‰ç…§è¯·æ±‚æ—¶é—´é¡ºåºåˆ†é…åˆ°ä¸åŒçš„åç«¯æœåŠ¡å™¨,åç«¯æœåŠ¡å™¨æŒ‚æ‰,å°±è‡ªåŠ¨å‰”é™¤\n2 æƒé‡- ç»™ä¸åŒæœåŠ¡å™¨èµ‹äºˆæƒé‡,æƒé‡å¤§çš„,å°±æ‰¿å½“æ›´å¤šè®¿é—®\n3 ip_hash- å› ä¸ºå®¢æˆ·ç™»å½•ä¿¡æ¯ä¿å­˜åœ¨sessionä¸­,å¦‚æœè·³è½¬åˆ°å¦å¤–ä¸€å°æœåŠ¡å™¨çš„æ—¶å€™,éœ€è¦é‡æ–°ç™»å½•,æ‰€ä»¥ip_hashçš„æ–¹æ³•è®©ä¸€ä¸ªå®¢æˆ·åªè®¿é—®ä¸€å°æœåŠ¡å™¨\n4 fair(ç¬¬ä¸‰æ–¹)- æŒ‰åç«¯æœåŠ¡å™¨çš„å“åº”æ—¶é—´æ¥åˆ†é…è¯·æ±‚,å“åº”è¶ŠçŸ­,å°±è¶Šå…ˆåˆ†é…\n5 url_hash- å°±æ˜¯è®¾å®šæ–¹å‘urlè¿æ¥æ˜¯è®¿é—®é‚£å°æœåŠ¡å™¨,åç«¯æœåŠ¡å™¨ä¸ºç¼“å­˜æ—¶æ¯”è¾ƒæœ‰æ•ˆ\n\n### åŠ¨é™åˆ†ç¦»\nnginxæœ¬èº«å°±æ˜¯ä¸€å°æœåŠ¡å™¨,æ‰€ä»¥å¯ä»¥ä¿å­˜ä¸€äº›é™æ€èµ„æº,ä¹Ÿå°±æ˜¯æˆ‘ä»¬å¯ä»¥æŠŠåŠ¨æ€ç½‘ç«™é‡Œçš„åŠ¨æ€ç½‘é¡µæŒ‰ç…§ä¸€å®šè§„åˆ™æŠŠä¸å˜çš„èµ„æºå’Œç»å¸¸å˜çš„èµ„æºåŒºåˆ†å¼€æ¥,åŠ¨é™"
    },
    {
      "id": "/2020/4/21/pythonè¯»å–avroçš„schema",
      "metadata": {
        "permalink": "/blog/2020/4/21/pythonè¯»å–avroçš„schema",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-21-pythonè¯»å–avroçš„schema.md",
        "source": "@site/blog/2020-4-21-pythonè¯»å–avroçš„schema.md",
        "title": "è¯»å–avroæ–‡ä»¶çš„schema",
        "description": "é¦–å…ˆå®‰è£…åŒ…",
        "date": "2020-04-21T00:00:00.000Z",
        "formattedDate": "April 21, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "avro",
            "permalink": "/blog/tags/avro"
          },
          {
            "label": "bigquery",
            "permalink": "/blog/tags/bigquery"
          }
        ],
        "readingTime": 0.35,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "avro",
          "title": "è¯»å–avroæ–‡ä»¶çš„schema",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "avro",
            "bigquery"
          ]
        },
        "prevItem": {
          "title": "å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“",
          "permalink": "/blog/2020/4/26/å…³äºnginxå’ŒportçŸ¥è¯†æ€»ç»“"
        },
        "nextItem": {
          "title": "æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
          "permalink": "/blog/2020/4/21/æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery"
        }
      },
      "content": "é¦–å…ˆå®‰è£…åŒ…\n```\npip install avro-python3\n```\nç„¶ååœ¨pyæ–‡ä»¶å€’å…¥åŒ…\n```\nfrom avro.datafile import DataFileReader, DataFileWriter\nimport avro.io\nreader = avro.datafile.DataFileReader(open('./account_id_schema_new.avro',\"rb\"),avro.io.DatumReader())\nschema = reader.meta\nprint(schema)\n```\n<!--truncate-->\næ˜¾ç¤ºçš„æ•ˆæœå¦‚ä¸‹:\n```\n{'avro.schema': b'{\"fields\": [{\"type\": [\"null\", \"string\"], \"name\": \"ACNO\"}, {\"type\": [\"null\", \"double\"], \"name\": \"FIELD_1\"}, {\"type\": [\"null\", \"double\"], \"name\": \"FIELD_2\"}, {\"type\": [\"null\", \"double\"], \"name\": \"FIELD_3\"}], \"type\": \"record\", \"name\": \"Root\"}',\n 'avro.codec': b'null'}\n ```"
    },
    {
      "id": "/2020/4/21/æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
      "metadata": {
        "permalink": "/blog/2020/4/21/æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-21-æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery.md",
        "source": "@site/blog/2020-4-21-æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery.md",
        "title": "æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
        "description": "å»åˆ°æ§åˆ¶å°,ç¡®è®¤storageå’Œbigquery APIå·²å¯ç”¨",
        "date": "2020-04-21T00:00:00.000Z",
        "formattedDate": "April 21, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "avro",
            "permalink": "/blog/tags/avro"
          },
          {
            "label": "bigquery",
            "permalink": "/blog/tags/bigquery"
          }
        ],
        "readingTime": 0.915,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "avro",
          "title": "æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "avro",
            "bigquery"
          ]
        },
        "prevItem": {
          "title": "è¯»å–avroæ–‡ä»¶çš„schema",
          "permalink": "/blog/2020/4/21/pythonè¯»å–avroçš„schema"
        },
        "nextItem": {
          "title": "ç”¨yamlé…ç½®æ–‡ä»¶ä¼ å‚æ•°ç»™pyspark,ç„¶åå†dataprocè¿è¡Œ",
          "permalink": "/blog/2020/4/18/dataproc+spark+yaml"
        }
      },
      "content": "å»åˆ°æ§åˆ¶å°,ç¡®è®¤storageå’Œbigquery APIå·²å¯ç”¨\næ‰“å¼€gcs\nè®¾ç½®project id\n```\ngcloud config set project project_id\n```\n<!--truncate-->\n\nåœ¨storageä¸Šåˆ›å»ºbucket\n```\ngsutil mb gs://bucket_name\ngsutil ls #æŸ¥çœ‹åˆ›å»ºæ˜¯å¦æˆåŠŸ\n```\n```\nä¸Šä¼ æ–‡ä»¶å¤¹æˆ–è€…æ–‡ä»¶åˆ°storage bucket, å¦‚æœstorage bucketæ²¡æœ‰è¿™ä¸ªæ–‡ä»¶å,å°±ä¼šåˆ›å»ºä¸€ä¸ª\n```\n```\ngsutil cp -r faker_demo/data gs://z_bucket/sub_file\ngsutil ls gs://z_bucket/sub_file/* å‚çœ‹æ‰€æœ‰æ–‡ä»¶\ngsutil rm gs://z_bucket/sub_file/.DS_Store #åˆ é™¤æ–‡ä»¶\n```\nå»big query åˆ›å»ºdataset\n```\nbq mk fake_data\nbq ls #æŸ¥çœ‹å‘½ä»¤\n```\nåˆ›å»ºbiq query è¡¨æ ¼ csv, æˆ–è€…avro,æ³¨æ„--source_format è¦å¤§å†™AVRO,CSV, å¦‚æœcsvç±»å‹çš„schemaå¯ä»¥ç”¨--autodetect,\n```\nbq load --source_format=AVRO fake_data.account_id_schema \"gs://z_bucket/sub_file/avro_output/accountID.avro\"\n\nbq load --source_format=CSV fake_data.account_id_schema  \"gs://z_bucket/sub_file/input/account_id_schema.csv\" \n\nbq load --autodetect --source_format=CSV fake_data.account_id_schema \"gs://z_bucket/sub_file/output/accountID.csv\"\n```\næŸ¥çœ‹å­—æ®µ\n\n```\nbq show fake_data.account_id_schema\n```\n\næŸ¥è¯¢\n\n```\nbq query \"select * from fake_data.account_id_schema limit 5\"\n```"
    },
    {
      "id": "/2020/4/18/dataproc+spark+yaml",
      "metadata": {
        "permalink": "/blog/2020/4/18/dataproc+spark+yaml",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-18-dataproc+spark+yaml.md",
        "source": "@site/blog/2020-4-18-dataproc+spark+yaml.md",
        "title": "ç”¨yamlé…ç½®æ–‡ä»¶ä¼ å‚æ•°ç»™pyspark,ç„¶åå†dataprocè¿è¡Œ",
        "description": "é¦–å…ˆæˆ‘ä»¬è¦å­¦Yamlè¯­æ³•:",
        "date": "2020-04-18T00:00:00.000Z",
        "formattedDate": "April 18, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 2.73,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc6",
          "title": "ç”¨yamlé…ç½®æ–‡ä»¶ä¼ å‚æ•°ç»™pyspark,ç„¶åå†dataprocè¿è¡Œ",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery",
          "permalink": "/blog/2020/4/21/æŠŠavroæ–‡ä»¶æ”¾åˆ°bigquery"
        },
        "nextItem": {
          "title": "yamlè¯­æ³•å­¦ä¹ ",
          "permalink": "/blog/2020/4/18/yamlè¯­æ³•å­¦ä¹ "
        }
      },
      "content": "é¦–å…ˆæˆ‘ä»¬è¦å­¦Yamlè¯­æ³•:\nå…·ä½“yamlè¯­æ³•å¯ä»¥å‚è€ƒ[yamlè¯­æ³•è¯¦æƒ…](yaml1)\n\næ•´ä½“æ€è·¯\n## å‡†å¤‡yamlæ–‡ä»¶å’Œpyspark\n1. å¯¼å…¥å·¥å…·åŒ…\n```\n#!/usr/bin/env python\nfrom pyspark.sql import SparkSession\nimport sys,yaml,datetime\nimport os\nimport pathlib\nimport google.cloud.storage as gcs\n```\n2. æˆ‘ä»¬å†™äº†ä¸€ä¸ªYamlæ–‡ä»¶ä½œä¸ºconfigæ–‡ä»¶\n3. æˆ‘ä»¬åœ¨æˆ‘ä»¬çš„pysparkæ–‡ä»¶è¯»å–yamlæ–‡ä»¶,è¿™é‡Œè¦æ³¨æ„çš„æ˜¯,å› ä¸ºæœ¬åœ°å’ŒGCSä¼šæœ‰ä¸åŒ,æœ¬åœ°æ˜¯å¯ä»¥ç›´æ¥è¯»å–çš„,ä½†æ˜¯å¦‚æœyamlæ–‡ä»¶åœ¨GCS,yamlæ–‡ä»¶å°±æ˜¯object,æ˜¯ä¸å¯æ”¹å†™çš„,æ‰€ä»¥æˆ‘ä»¬ä¸èƒ½ç›´æ¥open(yamlæ–‡ä»¶,\"r\")\n4. æˆ‘ä»¬éœ€è¦åœ¨pysparkæ–‡ä»¶ä¸Šåˆ›å»ºgcså®¢æˆ·ç«¯,ç„¶ååˆ›å»ºè®¾ç½®ä¸€ä¸ªæœ¬åœ°æ–‡ä»¶è·¯å¾„,ç„¶åé€šè¿‡å®¢æˆ·ç«¯è¯»å–yamlæ–‡ä»¶å†…å®¹å¹¶ä¸”ä¸‹è½½åˆ°æœ¬åœ°,ç„¶åå†é€šè¿‡æœ¬åœ°ä½¿ç”¨with openæ–¹æ³•è¯»å–yamlæ–‡ä»¶å†…å®¹\n```\nclient = gcs.Client()\n\n#set target file to write to\ntarget = pathlib.Path(\"local_file.yaml\")\n\nconfig_file = sys.argv[1] +\"config.yaml\"\n\n#set file to download\nFULL_FILE_PATH = config_file\n\n#open filestream with write permissions\nwith target.open(mode=\"wb\") as downloaded_file:\n\n        #download and write file locally\n        client.download_blob_to_file(FULL_FILE_PATH, downloaded_file)\n\nconfig_file=\"local_file.yaml\"\n```\n\nè¯»å–å,æˆ‘ä»¬å°±å¯ä»¥æ“ä½œä¸€ä¸‹ä»£ç \n```\nfor job in config[\"jobs\"]:\n    print(\"Creating source views...\")\n    for source in job[\"sources\"]:\n        print(source)\n        if source.get(\"table\") is not None:\n            print(\"Creating view %s from table %s...\" % (source[\"view\"], source[\"table\"]))\n            df = spark.table(source[\"table\"])\n            df.show(5)\n            print('table now')\n        else:\n            print(\"Creating view %s from object %s...\" % (source[\"view\"], source[\"object\"]))\n            df = spark.read.format(source['object'][source['object'].rfind('.')+1:]).option(\"header\",\"true\").load(source['object'])\n            df.show(5)\n        if source.get(\"columns\") is not None:\n            # columns listed, select given columns\n            df = df.select(source[\"columns\"])\n            df.show(5)\n        if source.get('Fillna') is not None:\n            print(source['Fillna'][\"fields\"])\n            print('hah',type(source['Fillna']))\n            df = df.fillna({source['Fillna'][\"fields\"]:source['Fillna'][\"num\"]})\n            df.show(5)\n        if source.get(\"filters\") is not None:\n            df.filter(source[\"filters\"])\n        if source.get(\"union\") is not None:\n            df_union = spark.sql(\"select * from %s\"%(source['union']))\n            df.union(df_union)\n            df.show(1)\n        if source.get(\"join\") is not None:\n            cur = df.select(source['Key'])\n            pre = spark.sql(\"select * from %s\"%(source['right']))\n            df = cur.join(pre,[source['Key']],source['how'])\n            df.show(5)\n        df.createOrReplaceTempView(source[\"view\"])\n    print(\"Performing SQL Transformations...\")\n    if job.get(\"transforms\") is not None:\n        for transform in job[\"transforms\"]:\n            spark.sql(transform[\"sql\"])\n            print(df.count())\n    if job.get(\"targets\") is not None:\n        print(\"Writing out final object to %s...\" % (job[\"targets\"][\"target_location\"]))\n        start = datetime.datetime.now()\n        final_df = spark.table(job[\"targets\"][\"final_object\"])\n        final_df.write.mode(job[\"targets\"][\"mode\"]).format(job[\"targets\"][\"format\"]).save(job[\"targets\"][\"target_location\"])\n        finish = datetime.datetime.now()\n        print(\"Finished writing out target object...\")\n```\n## è¿™ç«¯ä»£ç çš„é€»è¾‘å°±æ˜¯å¾ªç¯configé‡Œé¢çš„jobs,jobsé‡Œé¢åŒ…æ‹¬è¯»å–æ–‡ä»¶æˆ–è€…table,fillna,union,transoformç­‰etlä½œä¸š\n\n## å‡†å¤‡å¯åŠ¨dataprocä»£ç \n```\nCLUSTER_NAME=newnew\ngcloud beta dataproc clusters create ${CLUSTER_NAME} \\\n    --region=global \\\n    --zone=us-central1-b \\\n    --worker-machine-type n1-standard-1 \\\n    --num-workers 2 \\\n    --image-version 1.4-debian \\\n    --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \\\n    --metadata 'PIP_PACKAGES=google-cloud-storage PyYAML pathlib avro-python3 dask[dataframe] gcsfs fastavro' \\\n    --enable-component-gateway \\\n    --worker-boot-disk-size=40 \\\n    --optional-components=ANACONDA \\\n    --enable-component-gateway\nBUCKET_NAME=zz_michael\ngcloud config set dataproc/region global\ngcloud dataproc jobs submit pyspark dyyaml.py --cluster newnew \\\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n--jars=https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.11/2.4.4/spark-avro_2.11-2.4.4.jar \\\n-- gs://${BUCKET_NAME}/yaml/ \n```\n\n## jobå®Œæˆåéœ€è¦åˆ é™¤dataproc clusters\n```\nCLUSTER_NAME=newnew\ngcloud dataproc clusters delete $CLUSTER_NAME\n```"
    },
    {
      "id": "/2020/4/18/yamlè¯­æ³•å­¦ä¹ ",
      "metadata": {
        "permalink": "/blog/2020/4/18/yamlè¯­æ³•å­¦ä¹ ",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-18-yamlè¯­æ³•å­¦ä¹ .md",
        "source": "@site/blog/2020-4-18-yamlè¯­æ³•å­¦ä¹ .md",
        "title": "yamlè¯­æ³•å­¦ä¹ ",
        "description": "é¦–å…ˆæˆ‘ä»¬è¦å­¦Yamlè¯­æ³•:",
        "date": "2020-04-18T00:00:00.000Z",
        "formattedDate": "April 18, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 3.445,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "yaml1",
          "title": "yamlè¯­æ³•å­¦ä¹ ",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "ç”¨yamlé…ç½®æ–‡ä»¶ä¼ å‚æ•°ç»™pyspark,ç„¶åå†dataprocè¿è¡Œ",
          "permalink": "/blog/2020/4/18/dataproc+spark+yaml"
        },
        "nextItem": {
          "title": "dataproc--dataproc+GCS+Bigquery+Pyspark",
          "permalink": "/blog/2020/4/17/dataproc+GCS+Bigquery+pyspark"
        }
      },
      "content": "é¦–å…ˆæˆ‘ä»¬è¦å­¦Yamlè¯­æ³•:\nå…·ä½“yamlè¯­æ³•å¯ä»¥å‚è€ƒ[yamlè¯­æ³•è¯¦æƒ…]([yaml1](https://learn-the-web.algonquindesign.ca/topics/yaml/))\n\n# yamlè¯­æ³•çš„æ ¸å¿ƒæˆ‘è§‰å¾—ä¹Ÿæ˜¯å­—å…¸è¯­è¨€\n\n## ç¼©å‡ç©ºæ ¼:\nYAMLå¯¹æ­¤éå¸¸ä¸¥æ ¼:ä»…ç¼©è¿›2ä¸ªç©ºæ ¼\n\n## ç»“æ„åŒ–æ•°æ®-è¨€å¤–ä¹‹æ„å°±æ˜¯å­—å…¸å¯¹è±¡\nä¸¤ä¸ªä¸»è¦ç»“æ„:\n1. ```å¯¹è±¡ ç±»ä¼¼javascriptçš„å¯¹è±¡ æˆ–è€…html <dl>```\n2. ```æ•°ç»„ ç±»ä¼¼javascriptçš„æ•°ç»„ ç±»ä¼¼html<ul>```\n\n## è¯»å–yamlæ–‡ä»¶\n```\nconfig_file  = './test.yaml'\nwith open(config_file, 'r') as stream:\n    config = yaml.load(stream.read(),Loader=yaml.FullLoader)\n```\n\n### å¯¹è±¡\nYAMLä¸­çš„å¯¹è±¡ä»¥å•è¯/æœ¯è¯­å¼€å¤´,åè·Ÿå†’å·å’Œç©ºæ ¼\n\nå¯¹è±¡åŒ…å«å¯¹è±¡\n```\ndimensions:\n  width: 3 metres\n  height: 8 metres\n  length: 12 metres\n  weight: 4 tonnes\n```\næˆ‘ä»¬å¯ä»¥dimension['width']è·å–wdithæ•°å€¼\n```\nfor key,values in config['dimensions']:\n    print(key,values)\n```\n\n### æ•°ç»„\n```\nlikes_to_eat:\n  - Other dinosaurs\n  - Meat\n  - More meat\n  - Not plants\n```\n```\nfor key,values in enumerate(config['likes_to_eat']):\n    print(key,values)\n```\n\n### æ•°æ®åŒ…å«å¯¹è±¡\n```\nPerson:\n    - name: T. rex\n      period: Late Cretaceous Period\n    - name: Stegosaurus\n      period: Late Jurassic Period\n    - name: Velociraptor\n      period: Cretaceous Period\n```\n\"-\"å¯ä»¥çœ‹å‡ºåˆ—è¡¨[],ç„¶åå¦‚æœé‡Œé¢æœ‰å¯¹è±¡,å°±æ˜¯åˆ—è¡¨åµŒå¥—å¯¹è±¡çš„æ„æ€\n\n## ä»¥ä¸Šå°±æ˜¯yamlæœ€åŸºæœ¬çš„ç”¨æ³•\n\n### æ–‡å­—åŒºå—\nå¦‚æœæ‚¨çš„YAMLä¸­æœ‰è¶…å¤§æ–‡æœ¬å—ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ç«–çº¿ï¼ˆ|ï¼‰æˆ–å¤§äºç¬¦å·ï¼ˆ>ï¼‰çš„æ–¹å¼å°†æ–‡æœ¬åˆ†å¼€ï¼Œå¹¶å…è®¸æ›´å¤šæ ¼å¼ã€‚\nå¤§äºå·ä½¿æ‚¨å¯ä»¥åœ¨å¤šè¡Œä¸Šç¼–å†™æ–‡æœ¬ï¼Œå› ä¸ºå½“æ‚¨è§£æYAMLæ—¶ï¼Œè¿™äº›è¡Œå°†æŠ˜å ä¸ºä¸€è¡Œã€‚\n```\ndesc: >\n  Tyrannosaurus (/tÉ¨ËŒrÃ¦nÉ™ËˆsÉ”rÉ™s/ or /taÉªËŒrÃ¦nÉ™ËˆsÉ”rÉ™s/ (\"tyrant lizard\", from the Ancient Greek tyrannos (Ï„ÏÏÎ±Î½Î½Î¿Ï‚), \"tyrant\", and sauros (ÏƒÎ±á¿¦ÏÎ¿Ï‚), \"lizard\"[1])) is a genus of coelurosaurian theropod dinosaur.\n  The species Tyrannosaurus rex (rex meaning \"king\" in Latin), commonly abbreviated to T. rex, is one of the most well-represented of the large theropods.\n```\n\n## éªŒè¯\næˆ‘ä»¬å¯ä»¥å»yamlè¯­æ³•éªŒè¯ç½‘ç«™éªŒè¯(http://www.yamllint.com/)\n\næˆ‘çš„ä¸€ä¸ªå®ä¾‹:\n```\njobs: \n  - \n    name: \"read_file and conbine as one dataframe5\"\n    sources: \n      - \n        Fillna: \n          fields: NUM_OF_MTHS_PD_30\n          num: 0\n        JobDescription: \"read Curr_RD file\"\n        object: \"gs://zz_michael/yaml/Curr_RD.avro\"\n        view: Curr_RD\n      - \n        Fillna: \n          fields: NUM_OF_MTHS_PD_30\n          num: 0\n        JobDescription: \"read Prev_RD file\"\n        object: \"gs://zz_michael/yaml/Prev_RD.avro\"\n        view: Prev_RD\n      - \n        JobDescription: \"left join\"\n        Key: ARNG_ID\n        how: left_outer\n        join: left_outer\n        left: Curr_RD\n        right: Prev_RD\n        table: Curr_RD\n        view: df5\n  - \n    name: \"filter Df5 df\"\n    sources: \n      - \n        JobDescription: \"filter df5\"\n        filters: \"NUM_OF_MTHS_PD_30 >=1\"\n        table: df5\n        view: df6\n    transforms: \n      - \n        sql: \"CREATE OR REPLACE TEMPORARY VIEW df7 as select * from df5 where NUM_OF_MTHS_PD_30 is null or NUM_OF_MTHS_PD_30 <1\"\n  - \n    name: fillna\n    sources: \n      - \n        Fillna: \n          fields: NUM_OF_MTHS_PD_30\n          num: 0\n        JobDescription: fillna\n        table: df7\n        view: df8\n  - \n    name: union\n    sources: \n      - \n        JobDescription: union\n        table: df6\n        union: df8\n        view: df9\n  - \n    name: write to avro file\n    sources: \n      - \n        JobDescription: \"left join\"\n        Key: ARNG_ID\n        how: left_outer\n        join: left_outer\n        left: Curr_RD\n        right: df9\n        table: Curr_RD\n        view: df10\n    targets: \n      final_object: df10\n      format: csv\n      mode: overwrite\n      target_location: \"gs://zz_michael/yaml/output\"\n    transforms: \n      - \n        sql: \"CREATE OR REPLACE TEMPORARY VIEW df10 as select * from df10\"\nname: haha\n```\n## è§£æä¸Šé¢YAMLæ–‡ä»¶\n1. æˆ‘ä»¬å¯ä»¥çœ‹åˆ°Jobsæ˜¯å¯¹è±¡ jobs(object)\n2. ä»'-'å¯ä»¥çœ‹å‡º,Jobså¯¹è±¡åµŒå¥—åˆ—è¡¨ ç±»ä¼¼ [i for i in config[\"jobs\"]],æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œå¯ä»¥éå†jobs\n3. åˆ—è¡¨é‡Œé¢åµŒå¥—å¯¹è±¡: [{\"name\":\"\",\"sources\":\"\"},{\"name\":\"\",\"sources\":\"\",\"transforms\":\"\"},{\"name\":\"\",\"sources\":\"\"},{\"name\":\"\",\"sources\":\"\"},{\"name\":\"\",\"sources\":\"\",\"transforms\":\"\",'targets':\"\"}]\n4. æˆ‘ä»¬çœ‹åˆ°sourceä¹Ÿæ˜¯æœ‰åµŒå¥—çš„,ä¹Ÿæ˜¯åµŒå¥—å¯¹è±¡[{},{}]\n5. Fillnaå¯¹è±¡é‡Œé¢ä¹Ÿæ˜¯æœ‰åµŒå¥—å¯¹è±¡"
    },
    {
      "id": "/2020/4/17/dataproc+GCS+Bigquery+pyspark",
      "metadata": {
        "permalink": "/blog/2020/4/17/dataproc+GCS+Bigquery+pyspark",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataproc+GCS+Bigquery+pyspark.md",
        "source": "@site/blog/2020-4-17-dataproc+GCS+Bigquery+pyspark.md",
        "title": "dataproc--dataproc+GCS+Bigquery+Pyspark",
        "description": "æµç¨‹å¾ˆç®€å•",
        "date": "2020-04-17T00:00:00.000Z",
        "formattedDate": "April 17, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 1.585,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc4",
          "title": "dataproc--dataproc+GCS+Bigquery+Pyspark",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "yamlè¯­æ³•å­¦ä¹ ",
          "permalink": "/blog/2020/4/18/yamlè¯­æ³•å­¦ä¹ "
        },
        "nextItem": {
          "title": "dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avroæ–‡ä»¶",
          "permalink": "/blog/2020/4/17/dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro"
        }
      },
      "content": "## æµç¨‹å¾ˆç®€å•\né¦–å…ˆæˆ‘ä»¬ä»GCSé‚£é‡Œè¯»å–avroæ•°æ®,ç„¶åæˆ‘ä»¬è¯»å–avroæ•°æ®å˜æˆdask.Dataframe,ç„¶åå¯¹dask.Dataframeæ“ä½œ,å†è½¬æˆpandas Dataframe,ç„¶åå˜æˆSpark Dataframe,æœ€åé€šè¿‡Spark ä¸ bigquery çš„connectorå¯¹æ¥èµ·æ¥,å†™å…¥big query\n\n## å®‰è£…åˆšæ‰çš„æ€è·¯å†™python.py\n```\nimport dask.bag as db # å¯¼å…¥å·¥å…·åŒ…\ndef run():\n    b = db.read_avro('gs://zz_mm_bucket/account_id_schema_new.avro') #ä»GCSè¯»å–avroæ–‡ä»¶\n    df = b.to_dataframe() # è½¬æˆDataframe\n    df_values = df.compute().values.tolist() #è½¬æˆpandasçš„dataframe\n    df_columns = list(df.columns)\n\n    import pandas as pd\n    from pyspark.sql import SparkSession #sparkåˆå§‹åŒ–\n    spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n    bucket = \"haha_mm_bucket\" #è®¾ç½®bucket\n    spark.conf.set('temporaryGcsBucket', bucket) #ç»™sparkåˆå§‹åŒ–è®¾ç½®bucketé›¶æ—¶å­˜æ”¾æ•°æ®çš„gcs\n\n    spark_df = spark.createDataFrame(df_values, df_columns) æŠŠdataframeè½¬æˆsparkçš„dataframe\n    spark_df.show(10) #å¯¹sparkçš„dataframeè¿›è¡Œæ“ä½œ\n    spark_df.write.format('bigquery').option('table','query-11:newdata.newdata').save() # å†™å…¥bigquery\n\nif __name__ == '__main__':\n    run()\n```\n###  å»åˆ°ç»ˆç«¯è¾“å…¥å‘½ä»¤,æäº¤spark job\n```\ngcloud dataproc jobs submit pyspark wordcount.py \\\n    --cluster cluster-name \\\n    --region cluster-region (example: \"us-central1\") \\\n    --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n```\nä¸»è¦æ ¼å¼: gcloud dataproc jobs submit pyspark python.py(pythonæ–‡ä»¶) \\\n        --cluster cluster-name \\\n        --region cluster-region(æ¯”å¦‚:us-central1,ä¸€å®šè¦å¯¹åº”dataprocé›†ç¾¤çš„region)\n        --jars ä¸biguqeryè¿æ¥çš„åŒ…\næ³¨æ„è¿™é‡Œçš„jars:\nIf you are using Dataproc image 1.5, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\nIf you are using Dataproc image 1.4 or below, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n\n\n```\ngcloud config set dataproc/region us-central1\nBUCKET_NAME=haha_mm_bucket\ninput=new.avro\ngcloud dataproc jobs submit pyspark wordcount3.py \\\n--cluster cluster-662b \\\n-- gs://${BUCKET_NAME}/${input} \\\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n--packages com.databricks:spark-avro_2.11:4.0.0\n```"
    },
    {
      "id": "/2020/4/17/dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro",
      "metadata": {
        "permalink": "/blog/2020/4/17/dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro.md",
        "source": "@site/blog/2020-4-17-dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro.md",
        "title": "dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avroæ–‡ä»¶",
        "description": "1. spark åˆå§‹åŒ–,å› ä¸ºè¦è¯»å–æˆdataframeæˆ–è€…sqlå½¢å¼,å¯¼å…¥SparkSession",
        "date": "2020-04-17T00:00:00.000Z",
        "formattedDate": "April 17, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 2.74,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc5",
          "title": "dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avroæ–‡ä»¶",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "dataproc--dataproc+GCS+Bigquery+Pyspark",
          "permalink": "/blog/2020/4/17/dataproc+GCS+Bigquery+pyspark"
        },
        "nextItem": {
          "title": "dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œspark job",
          "permalink": "/blog/2020/4/17/dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob"
        }
      },
      "content": "### 1. spark åˆå§‹åŒ–,å› ä¸ºè¦è¯»å–æˆdataframeæˆ–è€…sqlå½¢å¼,å¯¼å…¥SparkSession\n```\nfrom pyspark.sql import SparkSession\nimport sys\n```\n### 2. åˆ›å»ºsparkå¯¹è±¡\n```\nspark = SparkSession \\\n  .builder \\\n  .master('yarn') \\\n  .appName('gcs-sparkdataframe-sql-avro') \\\n  .getOrCreate()\n```\n### å‚æ•°åˆ¤æ–­å’Œå‚æ•°è®¾ç½®\n```\nif len(sys.argv) != 4:\n  raise Exception(\"Exactly 3 arguments are required: <inputUri> <table1><table2>\")\n\ninputUri=sys.argv[1]\ntable1=sys.argv[2]\ntable2=sys.argv[3]\n```\n### 4 è¯»å–avroæ–‡ä»¶\n```\ndf = spark.read.format('avro').load(inputUri)\n```\n### 5 æ³¨å†Œè§†å›¾,å®è¡ŒæŸ¥è¯¢è¯­å¥\n```\ndf1 = spark.sql(\"select ACNO,%s from bigtable\" % (\",\".join(df.columns[1:round(len(df.columns) / 2)])))\ndf2 = spark.sql(\"select ACNO,%s from bigtable\" % (\",\".join(df.columns[round(len(df.columns) / 2):])))\ndf1.show(10)\ndf2.show(10)\n```\n\n### 6 å¤„ç†å¥½çš„dataframeå¯¹è±¡å†™æˆavroæ–‡ä»¶ (æ³¨æ„,ç”¨sqlå¤„ç†è¿‡åçš„è¿˜æ˜¯dataframeå¯¹è±¡)\n```\ndf1.write.format('avro').save(table1,'avro')\n\ndf2.write.format('avro').save(table2,'avro')\n```\n\n### 7 å»åˆ°ç»ˆç«¯è¾“å…¥å‘½ä»¤,åˆ›å»ºdataprocé›†ç¾¤,ç„¶åæäº¤spark job\n```\nCLUSTER_NAME=newnew\ngcloud beta dataproc clusters create ${CLUSTER_NAME} \\\n    --region=global \\\n    --zone=us-central1-b \\\n    --worker-machine-type n1-standard-1 \\\n    --num-workers 2 \\\n    --image-version 1.4-debian \\\n    --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \\\n    --metadata 'PIP_PACKAGES=google-cloud-storage avro-python3 dask[dataframe] gcsfs fastavro' \\\n    --enable-component-gateway \\\n    --worker-boot-disk-size=40 \\\n    --optional-components=ANACONDA \\\n    --enable-component-gateway\nBUCKET_NAME=zz_mm_bucket\ngcloud config set dataproc/region global\ngcloud dataproc jobs submit pyspark avrosqlargs.py --cluster newnew \\\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n--jars=https://repo1.maven.org/maven2/org/apache/spark/spark-avro_2.11/2.4.4/spark-avro_2.11-2.4.4.jar \\\n-- gs://${BUCKET_NAME}/input/gs://zz_mm_bucket/input/ gs://${BUCKET_NAME}/output/table1 gs://${BUCKET_NAME}/output/table2\n```\n## è¿™é‡Œæ³¨æ„çš„æ˜¯gcloud dataproc jobs sumbitçš„å‚æ•°æ ¼å¼æ˜¯ pyspark.pyæ–‡ä»¶, files\næ‰€ä»¥ä¾‹å­ä¸­æˆ‘ä»¬çš„å‚æ•°æ€»å…±æœ‰4ä¸ª\n1 avrosqlargs.py\n\n2 gs://${BUCKET_NAME}/input/gs://zz_mm_bucket/input/\n\n3 gs://${BUCKET_NAME}/output/table1 \n\n4 gs://${BUCKET_NAME}/output/table2\n\njarså’Œclusteréƒ½ä¸ç®—ä¸ºå‚æ•°\n\nè¿˜æœ‰å°±æ˜¯filesçš„æ˜¯æ–‡ä»¶å¤¹å½¢å¼è€Œä¸èƒ½æ˜¯æ–‡ä»¶å½¢å¼,æ‰€ä»¥è¯»å…¥æ–‡ä»¶å¤¹å,å¯ä»¥æ ¹æ®éœ€è¦è¯»å–ä½ éœ€è¦çš„æ–‡ä»¶,æ¯”å¦‚sys.argv+'æ–‡ä»¶å'\n\næ‰€ä»¥æ•´ä½“å¯ä»¥æ”¹æˆ:\n```\n#!/usr/bin/python\n\"\"\"BigQuery I/O PySpark example.\"\"\"\nfrom pyspark.sql import SparkSession\nimport sys\n\n\n\nspark = SparkSession \\\n  .builder \\\n  .master('yarn') \\\n  .appName('gcs-sparkdataframe-sql-avro') \\\n  .getOrCreate()\n\n# get spark datafrom from avro file in GCS\n\nif len(sys.argv) != 4:\n  raise Exception(\"Exactly 3 arguments are required: <inputUri> <table1><table2>\")\n\ninputUri=sys.argv[1]\ntable1=sys.argv[2]\ntable2=sys.argv[3]\n\nfile = inputUri+'account_id_schema_new.avro'\ndf = spark.read.format('avro').load(file)\n\n\n#create temp table\ndf.createOrReplaceTempView('bigtable')\n\n# split temp table into 2 spark dataframes\ndf1 = spark.sql(\"select ACNO,%s from bigtable\" % (\",\".join(df.columns[1:round(len(df.columns) / 2)])))\ndf2 = spark.sql(\"select ACNO,%s from bigtable\" % (\",\".join(df.columns[round(len(df.columns) / 2):])))\ndf1.show(10)\ndf2.show(10)\n\n# Saving the dataframes into avro files and dump avro files into GCS\n\ndf1.write.mode(\"overwrite\").format('avro').save(table1,'avro')\n\ndf2.write.mode(\"overwrite\").format('avro').save(table2,'avro')\n```\n\n## å…³äºç”Ÿæˆæ–‡ä»¶,å› ä¸ºsparkæ˜¯åŸºäºhadoopçš„,æ‰€ä»¥æ–‡ä»¶ä¹Ÿä¼šåˆ†å¸ƒå¼å­˜å‚¨,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥çœ‹åˆ°\n```\ndf = spark.read.format('avro').load(sys.argv[3])\n```\n## ä¸€èˆ¬æ˜¯åˆ†åŒºæ˜¯ä¼šæ ¹æ®ä½ çš„ç”µè„‘çš„cpuæ ¸æ•°è‡ªåŠ¨åˆ†é…,æˆ‘çš„ç”µè„‘æ˜¯core i5,ä¹Ÿå°±æ˜¯å››æ ¸çš„,æ‰€ä»¥é»˜è®¤æ˜¯4\næˆ‘ä»¬å¯ä»¥é‡åˆ†åŒº:\n```\ndf.repartition(10) # å°±æ˜¯åˆ†10åŒº\ndf.rdd.getNumPartitions() #æŸ¥çœ‹åˆ†åŒºæ•°\ndf.coalesce(1)\n```"
    },
    {
      "id": "/2020/4/17/dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob",
      "metadata": {
        "permalink": "/blog/2020/4/17/dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob.md",
        "source": "@site/blog/2020-4-17-dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob.md",
        "title": "dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œspark job",
        "description": "æˆ‘ä»¬è¿ç”¨æ•°æ®åˆ†æçš„æ—¶å€™,é€šå¸¸éƒ½æ˜¯è„æ•°æ®,æˆ‘ä»¬éœ€è¦æ¸…æ´—æ‰èƒ½è¢«ä½¿ç”¨.",
        "date": "2020-04-17T00:00:00.000Z",
        "formattedDate": "April 17, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 2.51,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc2",
          "title": "dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œspark job",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avroæ–‡ä»¶",
          "permalink": "/blog/2020/4/17/dataprocå‚æ•°åŒ–è·‘sparkå’Œè¯»å†™avro"
        },
        "nextItem": {
          "title": "dataproc--è·‘pyspark(ä»big queryè·å–æ•°æ®)",
          "permalink": "/blog/2020/4/17/dataprocè·‘pyspark"
        }
      },
      "content": "æˆ‘ä»¬è¿ç”¨æ•°æ®åˆ†æçš„æ—¶å€™,é€šå¸¸éƒ½æ˜¯è„æ•°æ®,æˆ‘ä»¬éœ€è¦æ¸…æ´—æ‰èƒ½è¢«ä½¿ç”¨.\næˆ‘ä»¬å¯ä»¥åŠ è½½Big queryçš„æ•°æ®æ”¾åˆ°Dataprocä¸­,é€šè¿‡sparké›†ç¾¤æ¥etlæœ‰ç”¨çš„æ•°æ®,ç„¶åæŠŠä¸€äº›processed dataæ¯”å¦‚zipped csv fileæ”¾åˆ°google gloud storageä¸Š\n![png](../img/dataproc/dataproc2/1.png)\n\n# å‡†å¤‡é˜¶æ®µ\n## å»åˆ°æ§åˆ¶å°,ç¡®è®¤cloud dataproc APIå·²å¯ç”¨\n<!--truncate-->\n![png](../img/dataproc/dataproc1/1.png)\n![png](../img/dataproc/dataproc1/2.png)\n![png](../img/dataproc/dataproc1/3.png)\n\n# æˆ‘ä»¬ä¼šä½¿ç”¨å‘½ä»¤å»dataprocåˆ›å»ºé›†ç¾¤\n\n## é¦–å…ˆæˆ‘ä»¬åˆ›å»ºä¸€ä¸ªyamlæ–‡ä»¶,å¯¹é›†ç¾¤åšè‡ªåŠ¨ä¼¸ç¼©çš„å®šä¹‰\n[å…³äºsparkè‡ªåŠ¨ä¼¸ç¼©åŸç†](https://cloud.google.com/dataproc/docs/concepts/configuring-clusters/autoscaling#autoscaling_and_spark_structured_streaming)\n```\nworkerConfig:\n  minInstances: 2\n  maxInstances: 100\n  weight: 1\nsecondaryWorkerConfig:\n  minInstances: 0\n  maxInstances: 100\n  weight: 1\nbasicAlgorithm:\n  cooldownPeriod: 4m\n  yarnConfig:\n    scaleUpFactor: 1\n    scaleDownFactor: 1.0\n    scaleUpMinWorkerFraction: 0.0\n    scaleDownMinWorkerFraction: 0.0\n    gracefulDecommissionTimeout: 1h\n```\n\nç„¶åæˆ‘ä»¬å¯ä»¥å…ˆåˆ›å»ºè‡ªåŠ¨ä¼¸ç¼©æ”¿ç­–\n```\ngcloud beta dataproc autoscaling-policies import policy-name --source policy-file.yaml\n```\n[å…·ä½“çš„commandå‘½ä»¤](https://cloud.google.com/sdk/gcloud/reference/beta/dataproc/autoscaling-policies)\n\n## åˆ›å»ºé›†ç¾¤\n```\nCLUSTER_NAME=newnew\ngcloud beta dataproc clusters create ${CLUSTER_NAME} \\\n    --region=global \\\n    --zone=us-central1-b \\\n    --worker-machine-type n1-standard-1 \\\n    --num-workers 2 \\\n    --image-version 1.4-debian \\\n    --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \\\n    --metadata 'PIP_PACKAGES=google-cloud-storage avro-python3 dask[dataframe] gcsfs fastavro' \\\n    --enable-component-gateway \\\n    --worker-boot-disk-size=40 \\\n    --optional-components=JUPYTER,ANACONDA \\\n    --enable-component-gateway \\\n    --autoscaling-policy=global\n```\n\n## åˆ›å»ºæˆåŠŸå,Dataprocmenuä¸ŠæŸ¥çœ‹,åŒæ—¶æˆ‘ä»¬éœ€è¦åˆ›å»ºä¸€ä¸ªGCS,è¿™æ ·æˆ‘ä»¬å¤„ç†å¥½çš„æ•°æ®å°±å¯ä»¥å­˜åœ¨åœ¨GCSä¸Šäº†\n```\nBUCKET_NAME=<bucket_name>\ngsutil mb gs://${BUCKET_NAME}\n```\n\n## æˆ‘ä»¬å¯ä»¥å»bigqueryçš„public dataæ‰¾æ•°æ®,æŸ¥çœ‹è¡¨çš„æ•°æ®ç»“æ„\n![png](../img/dataproc/dataproc2/2.png)\n\n## è¿è¡Œ pyspark job\n```\ncd\ngit clone https://github.com/GoogleCloudPlatform/cloud-dataproc\n```\n```\ncd ~/cloud-dataproc/codelabs/spark-bigquery\ngcloud dataproc jobs submit pyspark --cluster ${CLUSTER_NAME} \\\n    --jars gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar \\\n    --driver-log-levels root=FATAL \\\n    counts_by_subreddit.py\n```\næˆ‘ä»¬éœ€è¦æä¾›é›†ç¾¤åå­—,æä¾›jarsçš„å‚æ•°,è¿™ä¸ªjaråŒ…èƒ½å¤Ÿå…è®¸æˆ‘ä»¬é€šè¿‡saprk-bigquery-connectorè¿æ¥åˆ°æˆ‘ä»¬çš„job,\ndriver-log-levels root=FATALèƒ½å¤ŸæŠ‘åˆ¶æ—¥å¿—è¾“å‡ºé™¤äº†é”™è¯¯ä¿¡æ¯,å› ä¸ºspark logs.\n![png](../img/dataproc/dataproc2/3.png)\n![png](../img/dataproc/dataproc2/4.png)\n![png](../img/dataproc/dataproc2/5.png)\n\n## æˆ‘ä»¬æŸ¥çœ‹Dataprocå’Œspark\n![png](../img/dataproc/dataproc2/6.png)\n![png](../img/dataproc/dataproc2/7.png)\n![png](../img/dataproc/dataproc2/8.png)\n![png](../img/dataproc/dataproc2/9.png)\n\n## æˆ‘ä»¬è·‘ä¸€ä¸ªä»»åŠ¡,åŠ è½½æ•°æ®åˆ°memory,æå–å¿…é¡»è¦çš„ä¿¡æ¯,ç„¶åè¾“å‡ºåˆ°GCSé‡Œé¢.æˆ‘ä»¬è¿™é‡Œæ˜¯æå–title,bodyå’Œtimestamp created,ç„¶åæˆ‘ä»¬æŠŠè¿™äº›dataè½¬æˆcsvæ–‡ä»¶,å­˜å…¥gcsé‡Œé¢\n```\ncd ~/cloud-dataproc/codelabs/spark-bigquery\nbash backfill.sh ${CLUSTER_NAME} ${BUCKET_NAME}\n```\n\næŸ¥çœ‹\n```\ngsutil ls gs://${BUCKET_NAME}/reddit_posts/*/*/food.csv.gz\n```\n\n(ç±»ä¼¼çš„å®éªŒå¯ä»¥å‚è€ƒ)(https://codelabs.developers.google.com/codelabs/pyspark-bigquery/index.html?index=..%2F..index#1)"
    },
    {
      "id": "/2020/4/17/dataprocè·‘pyspark",
      "metadata": {
        "permalink": "/blog/2020/4/17/dataprocè·‘pyspark",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataprocè·‘pyspark.md",
        "source": "@site/blog/2020-4-17-dataprocè·‘pyspark.md",
        "title": "dataproc--è·‘pyspark(ä»big queryè·å–æ•°æ®)",
        "description": "æµç¨‹å¾ˆç®€å•",
        "date": "2020-04-17T00:00:00.000Z",
        "formattedDate": "April 17, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 1.83,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc3",
          "title": "dataproc--è·‘pyspark(ä»big queryè·å–æ•°æ®)",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œspark job",
          "permalink": "/blog/2020/4/17/dataprocè‡ªåŠ¨ä¼¸ç¼©å’Œè¿è¡Œsparkjob"
        },
        "nextItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨Dataprocè¿è¡ŒApache Sparké›†ç¾¤",
          "permalink": "/blog/2020/4/17/dataprocè¿è¡ŒApache Sparké›†ç¾¤"
        }
      },
      "content": "## æµç¨‹å¾ˆç®€å•\næˆ‘ä»¬è¦ç”¨sparkè¯»å–ä»bigqueryè¯»å–table,ç„¶åæˆ‘ä»¬å¯¹è¿™ä¸ªtableåšä¸€ä¸ªç®€å•çš„å¤„ç†,å†åˆ†æˆä¸¤dataframeå¯¹è±¡,ç„¶åæŠŠä¸¤ä¸ªå¯¹è±¡å†™å…¥bigquery\n\n### 1. spark åˆå§‹åŒ–,å› ä¸ºè¦è¯»å–æˆdataframeæˆ–è€…sqlå½¢å¼,å¯¼å…¥SparkSession\n```\n#!/usr/bin/python\nfrom pyspark.sql import SparkSession\n```\n### 2. åˆ›å»ºsparkå¯¹è±¡\n```\nspark = SparkSession.builder.master('yarn').appName('your app name').getOrCreate()\n```\n### 3 æˆ‘ä»¬é€šè¿‡connectorè¿æ¥ä¸€ä¸ªgoogle storage bucket ç»™Bigqueryè¾“å‡ºæ•°æ®ä¸´æ—¶ç”¨\n```\nbucket = \"haha_mm_bucket\"\nspark.conf.set('temporaryGcsBucket',bucket)\n```\n### 4 é…ç½®å¥½tmp bucket,æˆ‘ä»¬å¯ä»¥å¼€å§‹è¯»å–æ•°æ®,å¹¶ä¸”æŠŠæ•°æ®æ¡†æ³¨å†Œä¸ºè§†å›¾\n```\ndf = spark.read.format('bigquery').option('table','datasetid:tableid').load()\ndf.createTempView(\"temp table name(æ¯”å¦‚words)\")\nä¹Ÿå¯ä»¥æ˜¯df.createOrReplaceTempView('words') è¿™æ ·å°±å¯ä»¥è¦†ç›–åŸæ¥åŒæ ·åå­—çš„ä¸´æ—¶è§†å›¾\n```\n### 5 å¼€å§‹ä½¿ç”¨sqlè¯­å¥\n```\nlefttable = spark.sql(\"SELECT ACNO, FIELD_1, FIELD_2 FROM words\")\nrighttable = spark.sql(\"SELECT ACNO, FIELD_3, FIELD_4 FROM words\")\nlefttable.show()\nlefttable.printSchema()\nrighttable.show()\nrighttable.printSchema()\n```\n\n### 6 å¤„ç†å¥½çš„dataframeå¯¹è±¡å†™å…¥bigquery (æ³¨æ„,ç”¨sqlå¤„ç†è¿‡åçš„è¿˜æ˜¯dataframeå¯¹è±¡)\n```\nlefttable.write.format('bigquery').option('table','query-11:newdata.lefttable').save()\nrighttable.write.format('bigquery').option('table','query-11:newdata.righttable').save()\n```\n\n### 7 å»åˆ°ç»ˆç«¯è¾“å…¥å‘½ä»¤,æäº¤spark job\n```\ngcloud dataproc jobs submit pyspark wordcount.py \\\n    --cluster cluster-name \\\n    --region cluster-region (example: \"us-central1\") \\\n    --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n```\nä¸»è¦æ ¼å¼: gcloud dataproc jobs submit pyspark python.py(pythonæ–‡ä»¶) \\\n        --cluster cluster-name \\\n        --region cluster-region(æ¯”å¦‚:us-central1,ä¸€å®šè¦å¯¹åº”dataprocé›†ç¾¤çš„region)\n        --jars ä¸biguqeryè¿æ¥çš„åŒ…\næ³¨æ„è¿™é‡Œçš„jars:\nIf you are using Dataproc image 1.5, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\nIf you are using Dataproc image 1.4 or below, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n\n\n```\ngcloud config set dataproc/region us-central1\nBUCKET_NAME=haha_mm_bucket\ninput=new.avro\ngcloud dataproc jobs submit pyspark wordcount3.py \\\n--cluster cluster-662b \\\n-- gs://${BUCKET_NAME}/${input} \\\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n--packages com.databricks:spark-avro_2.11:4.0.0\n```"
    },
    {
      "id": "/2020/4/17/dataprocè¿è¡ŒApache Sparké›†ç¾¤",
      "metadata": {
        "permalink": "/blog/2020/4/17/dataprocè¿è¡ŒApache Sparké›†ç¾¤",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataprocè¿è¡ŒApache Sparké›†ç¾¤.md",
        "source": "@site/blog/2020-4-17-dataprocè¿è¡ŒApache Sparké›†ç¾¤.md",
        "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨Dataprocè¿è¡ŒApache Sparké›†ç¾¤",
        "description": "png",
        "date": "2020-04-17T00:00:00.000Z",
        "formattedDate": "April 17, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 5.165,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataproc1",
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨Dataprocè¿è¡ŒApache Sparké›†ç¾¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "dataproc--è·‘pyspark(ä»big queryè·å–æ•°æ®)",
          "permalink": "/blog/2020/4/17/dataprocè·‘pyspark"
        },
        "nextItem": {
          "title": "google script + excel+ google drive",
          "permalink": "/blog/2020/4/16/bq_è„šæœ¬åˆ¶ä½œpresentation"
        }
      },
      "content": "<!--truncate-->\n![png](../img/dataproc/dataproc1/1.png)\n![png](../img/dataproc/dataproc1/2.png)\n![png](../img/dataproc/dataproc1/3.png)\n\n# å»dataproc->cluster->create cluster\n![png](../img/dataproc/dataproc1/10.png)\n\n# create clusterååœ¨ä»¥ä¸‹å­—æ®µè¾“å…¥å¯¹åº”å€¼\n![png](../img/dataproc/dataproc1/4.png)\n\nå…·ä½“å¦‚ä¸‹:\n\n![png](../img/dataproc/dataproc1/5.png)\n\n# ä»¥ä¸Šæ§åˆ¶å°çš„æ­¥éª¤,å¯ä»¥ç›´æ¥é€šè¿‡gcloud terminalä»£ç å®ç°\n```\ngcloud set config project project ID # è®¾ç½®æŒ‡å®šé¡¹ç›®id\ngcloud config set dataproc/region global #åœ¨dataprocè®¾ç½®region,è¿™ä¸€æ­¥å¾ˆé‡è¦\ngcloud dataproc clusters create example-cluster\n```\n![png](../img/dataproc/dataproc1/1.png)\n## è¿™æ ·gcpå°±ä¼šå¸®ä½ æ­å»ºclusteräº†\n\n# åˆ›å»ºé›†ç¾¤æˆåŠŸå,è¿è¡Œjob\n## å»job,é€‰æ‹© sumbit job\n\n![png](../img/dataproc/dataproc1/6.png)\n\n### åœ¨å¯¹åº”å­—æ®µè¾“å…¥å¯¹åº”å€¼\n![png](../img/dataproc/dataproc1/7.png)\n### å…·ä½“å¦‚ä¸‹,è¾“å…¥å®Œæˆåç‚¹å‡»sumbit\n![png](../img/dataproc/dataproc1/8.png)\n### æˆ‘ä»¬å¯ä»¥ç‚¹å‡»job id æŸ¥çœ‹ç»“æœå’Œæ—¥å¿—\n![png](../img/dataproc/dataproc1/9.png)\n\n# ä»¥ä¸Šæ­¥éª¤,æˆ‘ä»¬åŒæ ·å¯ä»¥ç”¨ä»£ç åœ¨GCPterminalä¸Šæ“ä½œ\n```\ngcloud dataproc jobs submit spark --cluster example-cluster \\\n  --class org.apache.spark.examples.SparkPi \\\n  --jars file:///usr/lib/spark/examples/jars/spark-examples.jar -- 1000\n```\næˆ‘ä»¬æŠŠjobæ‰“åŒ…æˆjar,ç„¶åç”¨submit spark æ¥è¿è¡Œ\nå‘½ä»¤ gcloud dataproc jobs submit spark --cluster é›†ç¾¤åç§° \\ --class ç±»å --jars jaråŒ…è·¯å¾„ --taskæ•°é‡\n\n![png](../img/dataproc/dataproc1/2.png)\n![png](../img/dataproc/dataproc1/3.png)\n\n## æˆ‘ä»¬å¯ä»¥å¯ä»¥æ›´æ–°workeræ•°é‡\ngcloud dataproc clusters update é›†ç¾¤åå­— -num-workers=æ•°é‡\n```\ngcloud dataproc clusters update example-cluster --num-workers= 4\n```\n![png](../img/dataproc/dataproc1/4.png)\n# æˆ‘ä»¬å¯ä»¥å‚è€ƒé›†ç¾¤è®¾ç½®\n```\ngcloud dataproc clusters describe example-cluster\n```\n\n![png](../img/dataproc/dataproc1/5.png)\n\n## å…³äºspark jaråŒ…å’Œclassé—®é¢˜\n[å‚è€ƒé“¾æ¥1](https://www.jianshu.com/p/2c7bcee7001a)\n\n[å‚çœ‹é“¾æ¥2](https://blog.csdn.net/u014234504/article/details/82812343)\n\n[classçš„å†™æ³•](https://wenku.baidu.com/view/a0dd882fa8956bec0975e397.html)\n\n\n# ç”¨dataprocåˆ›å»ºé›†ç¾¤å’Œè¿è¡Œspark job å®Œæˆ!!\nå…³äº[spark job,stage,task](https://zhuanlan.zhihu.com/p/50752866)çš„ç†è§£å’Œå‚è€ƒ\n\n\n# ç”¨gcloudæ¥å¯clusterå‘½ä»¤\n\n[ä¸€ä¸ªNLPå®éªŒ](https://codelabs.developers.google.com/codelabs/spark-nlp/index.html?index=..%2F..index&_ga=2.18367290.242813027.1588130089-996489118.1587002962&_gac=1.182983892.1588923163.Cj0KCQjwhtT1BRCiARIsAGlY51KEFc2-GGnxsXVhFZsKWExLJckKepaugZrKbbr2cvW0KLPRtubd7vAaAkA2EALw_wcB#0)\n\n\n# åœ¨dataprocåˆ›å»ºé›†ç¾¤\n```\nCLUSTER_NAME=my-cluster\nZONE=us-east1-b\nBUCKET_NAME=bm_reddit\nREGION=us-east1\ngcloud beta dataproc clusters create ${CLUSTER_NAME} \\\n     --zone=${ZONE} \\\n     --metadata 'PIP_PACKAGES=google-cloud-storage' \\\n     --worker-machine-type n1-standard-1 \\\n     --num-workers 2 \\\n     --image-version 1.4-debian9 \\\n     --initialization-actions gs://dataproc-initialization-actions/spark-nlp/spark-nlp.sh,gs://dataproc-initialization-actions/python/pip-install.sh \\\n     --region=${REGION} \\\n     --optional-components=JUPYTER,ANACONDA \\\n     --enable-component-gateway \\\n     --worker-boot-disk-size=30\n```\n## å‚æ•°è¯´æ˜:\nmetadataæŒ‡æºæ•°æ®,æ¯”å¦‚æƒ³è¦å®‰è£…CONDA_PACKAGE,æˆ‘ä»¬\n```\n--metadata 'CONDA_PACKAGES=scipy=1.0.0 tensorflow' \\ \n```\nå¦‚æœæƒ³å®‰è£…pip_package,æˆ‘ä»¬å¯ä»¥\n```\n--metadata 'PIP_PACKAGES=pandas==0.23.0 scipy==1.1.0' \\ \n```\nè¯¦ç»†å¯ä»¥[å‚è€ƒé“¾æ¥](https://cloud.google.com/dataproc/docs/tutorials/python-configuration)\n\n## Install PyPI packages\n```\n--initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/pip-install.sh\n```\n## Install Conda packages\n```\n--initialization-actions gs://goog-dataproc-initialization-actions-${REGION}/python/conda-install.sh\n```\n\n--initialization-actionsæ˜¯ç”¨åœ¨å®‰è£…metadataçš„åŒ…\n```\n--initialization-actions \\ \n    gs://goog-dataproc-initialization-actions-${REGION}/conda/bootstrap-conda.sh,gs://goog-dataproc-initialization-actions-${REGION}/conda/install-conda-env.sh\n```\nä¸‹è½½ä»£ç \n```\ncd\ngit clone https://github.com/GoogleCloudPlatform/cloud-dataproc\ncd cloud-dataproc/codelabs/spark-nlp\n```\n\nè¿è¡Œ\n```\ngcloud dataproc jobs submit pyspark --cluster ${CLUSTER_NAME}\\\n    --properties=spark.jars.packages=JohnSnowLabs:spark-nlp:2.0.8 \\\n    --driver-log-levels root=FATAL \\\n    topic_model.py \\\n    -- ${BUCKET_NAME}\n```\n\nCLUSTER_NAME=newnew\ngcloud beta dataproc clusters create ${CLUSTER_NAME} \\\n    --region=global \\\n    --zone=us-east1-b \\\n    --worker-machine-type n1-standard-2 \\\n    --num-workers 2 \\\n    --image-version 1.5-debian \\\n    --initialization-actions gs://dataproc-initialization-actions/python/pip-install.sh \\\n    --metadata 'PIP_PACKAGES=google-cloud-storage avro-python3 dask[dataframe] gcsfs fastavro' \\\n    --enable-component-gateway \\\n    --worker-boot-disk-size=40 \\\n    --optional-components=JUPYTER,ANACONDA \\\n    --enable-component-gateway \\\n    --autoscaling-policy=global\n\n\nworkerConfig:\n  minInstances: 2\n  maxInstances: 100\n  weight: 1\nsecondaryWorkerConfig:\n  minInstances: 0\n  maxInstances: 100\n  weight: 1\nbasicAlgorithm:\n  cooldownPeriod: 4m\n  yarnConfig:\n    scaleUpFactor: 0.05\n    scaleDownFactor: 1.0\n    scaleUpMinWorkerFraction: 0.0\n    scaleDownMinWorkerFraction: 0.0\n    gracefulDecommissionTimeout: 1h\n\n## å¸¸è§é”™è¯¯\n\næ¡ˆä¾‹1:cpusçš„é™é¢é—®é¢˜\nMultiple validation errors: - Insufficient 'CPUS' quota. Requested 12.0, available 7.0. - Insufficient 'CPUS_ALL_REGIONS' quota. Requested 12.0, available 11.0. - This request exceeds CPU quota. Some things to try: request fewer workers (a minimum of 2 is required), use smaller master and/or worker machine types (such as n1-standard-2).\n\n\nè¿™é‡Œçš„insufficent 'CPUS' åªçš„æ˜¯masterå’Œworkeræ‰€æœ‰çš„nodeçš„cpusæ•°é‡æ€»å’Œ\nInsufficient 'CPUS_ALL_REGIONS' quotaæ˜¯åœ¨å…¨çƒçš„cpusé™é¢,å¦‚æœregioné€‰æ‹©global, é‚£ä¹ˆè¿™é‡Œé™é¢å°±æ˜¯11(available 11), å¦‚æœregioné€‰æ‹©æ—¶æŸä¸ªåœ°åŒº,æ¯”å¦‚us-central1,é‚£ä¹ˆæˆ‘è¿™é‡Œçš„quotaå°±æ˜¯7.ä¸ºä»€ä¹ˆæ˜¯7å‘¢,å› ä¸ºè°·æ­Œçš„è¯•ç”¨è´¦å·æœ€å¤šåªèƒ½æœ‰8CPUs,æˆ‘è¿™ä¸ªprojecté‡Œé¢å·²ç»åœ¨ä¸€ä¸ªåœ°åŒºåŒºåŸŸåˆ›å»ºäº†ä¸€ä¸ªvm,è¿™ä¸ªvmçš„machining typeæ˜¯(n1-standard-1 (1 vCPU, 3.75 GB memory)),æ‰€ä»¥å ç”¨äº†ä¸€ä¸ªcpu,æ‰€ä»¥åœ°æ–¹regionçš„cpuså¯ç”¨é¢åº¦å°±æ˜¯8-1=7\nåŒç†,å…¨çƒçš„è¯æ˜¯12cpu,æˆ‘å·²ç»ç”¨äº†1ä¸ªäº†,æ‰€ä»¥å…¨çƒå‰©ä¸‹çš„å°±æ˜¯12-1=11.\n\næ¡ˆä¾‹2: yarn coreæ•° å’Œ yarn memory\nyarn core = workerçš„nodeä¸ªæ•° * vcpu\nyarn memory =  workerçš„nodeä¸ªæ•° * memoery * 0.8\n\n![png](../img/dataproc/dataproc1/11.png)\n\ngoogleå¯¹yarn memoeryçš„å®šä¹‰: \nThe number of worker nodes times the amount of memory on each node times the fraction given to YARN (0.8)\n\ngoogleå¯¹yarn coredsçš„å®šä¹‰:\nthe number of worker nodes times the number of vCPUs per node\n\n## åˆ›å»ºé›†ç¾¤å,ä½¿ç”¨jupyter, å»åˆ°cluster,ç„¶åå»åˆ°web interfaces,é€‰æ‹©jupyter\nå¦‚æœè¿è¡Œsparkçš„æ—¶å€™,å‡ºç° Py4JJavaErroré”™è¯¯\nå¯ä»¥å®‰è£…\n```\nconda install -c cyclus java-jdk\n```\n\nå¦‚æœæƒ³å®‰è£…python3\n```\n!conda create -n py36 python=3.6 anaconda\n```\n\n## Dataproc image version 1.3 æˆ–è€…ä¹‹å‰çš„è¯é»˜è®¤æ˜¯python2.7\næ‰€ä»¥æˆ‘ä»¬æœ€å¥½å®‰è£…Dataproc image version 1.4+,é»˜è®¤å°±æ˜¯python3,å…·ä½“è¯¦ç»†å¦‚ä¸‹\n```\nMiniconda3 is installed on Dataproc 1.4+ clusters. The default Python interpreter is Python 3.6 for Dataproc 1.4 and Python 3.7 for Dataproc 1.5, located on the VM instance at /opt/conda/miniconda3/bin/python3.6 and /opt/conda/miniconda3/bin/python3.7, respectively. Python 2.7 is also available at /usr/bin/python2.7.\n```\n\n## å…·ä½“é…ç½®clusteré…ç½®çš„è¯·æŸ¥çœ‹\n[å‚è€ƒé“¾æ¥](https://cloud.google.com/dataproc/docs/tutorials/python-configuration)"
    },
    {
      "id": "/2020/4/16/bq_è„šæœ¬åˆ¶ä½œpresentation",
      "metadata": {
        "permalink": "/blog/2020/4/16/bq_è„šæœ¬åˆ¶ä½œpresentation",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-16-bq_è„šæœ¬åˆ¶ä½œpresentation.md",
        "source": "@site/blog/2020-4-16-bq_è„šæœ¬åˆ¶ä½œpresentation.md",
        "title": "google script + excel+ google drive",
        "description": "æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªè„šæœ¬å¯ä»¥è¯»å–æ•°æ®,å¯¼å‡ºæˆè¡¨æ ¼å½¢å¼è€Œä¸”åˆ¶ä½œå‡ºå›¾æ ‡,æœ€ååšæˆä¸€ä¸ªpptå¹»ç¯æ¼”ç¤º,çœ‹èµ·æ¥æ˜¯ä¸æ˜¯å¾ˆç‰›,è¿™äº›åŠ¨ä½œåªéœ€è¦å†™ä¸ªè„šæœ¬å°±èƒ½å®Œæˆå•¦",
        "date": "2020-04-16T00:00:00.000Z",
        "formattedDate": "April 16, 2020",
        "tags": [
          {
            "label": "script",
            "permalink": "/blog/tags/script"
          },
          {
            "label": "excel",
            "permalink": "/blog/tags/excel"
          },
          {
            "label": "google",
            "permalink": "/blog/tags/google"
          }
        ],
        "readingTime": 15.43,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "bigquery_presentation",
          "title": "google script + excel+ google drive",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "script",
            "excel",
            "google"
          ]
        },
        "prevItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨Dataprocè¿è¡ŒApache Sparké›†ç¾¤",
          "permalink": "/blog/2020/4/17/dataprocè¿è¡ŒApache Sparké›†ç¾¤"
        },
        "nextItem": {
          "title": "Bigqueryä¸­sqlè¯­å¥å¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/15/bq_sqlå¸¸ç”¨çŸ­è¯­"
        }
      },
      "content": "### æˆ‘ä»¬çš„ç›®æ ‡æ˜¯åˆ›å»ºä¸€ä¸ªè„šæœ¬å¯ä»¥è¯»å–æ•°æ®,å¯¼å‡ºæˆè¡¨æ ¼å½¢å¼è€Œä¸”åˆ¶ä½œå‡ºå›¾æ ‡,æœ€ååšæˆä¸€ä¸ªpptå¹»ç¯æ¼”ç¤º,çœ‹èµ·æ¥æ˜¯ä¸æ˜¯å¾ˆç‰›,è¿™äº›åŠ¨ä½œåªéœ€è¦å†™ä¸ªè„šæœ¬å°±èƒ½å®Œæˆå•¦\n\n#### è¯·çœ‹æ¼”ç¤º\n<!--truncate-->\n#### æˆ‘ä»¬è¿›å…¥script.google.com,ç‚¹å‡»getting started,ç„¶åå†ç‚¹å‡»Apps script\n![png](../img/bigquery/bigquery_presentation/1.png)\n\n#### æˆ‘ä»¬è¿›å…¥scriptsä¸­,æˆ‘ä»¬å¯ä»¥æ”¹åæˆslides demo\n![png](../img/bigquery/bigquery_presentation/2.png)\n\n#### ç„¶åæˆ‘ä»¬å»åˆ°æ§åˆ¶å°æŸ¥çœ‹big query api æ˜¯å¦å·²ç»å¯åŠ¨\n#### ç¡®è®¤å,æˆ‘ä»¬ç‚¹å‡»Resourcesçš„advanced google services\n![png](../img/bigquery/bigquery_presentation/3.png)\n\n#### æˆ‘ä»¬å¼€å¯BigQuery APIæœåŠ¡\n![png](../img/bigquery/bigquery_presentation/4.png)\n\n#### ä¿®æ”¹ä»£ç æ–‡ä»¶åå­—,æ”¹æˆbs-sheets-slides.gs\nè¿™é‡Œç”¨å¾—æ˜¯javascriptæ¥å†™\n![png](../img/bigquery/bigquery_presentation/5.png)\nå…·ä½“ä»£ç å¦‚ä¸‹\n```javascript\n/**\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at apache.org/licenses/LICENSE-2.0.\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Filename for data results\nvar QUERY_NAME = \"Most common words in all of Shakespeare's works\";\n// Replace this value with your Google Cloud API project ID\nvar PROJECT_ID = '<YOUR_PROJECT_ID>';\nif (!PROJECT_ID) throw Error('Project ID is required in setup');\n\n/**\n * Runs a BigQuery query; puts results into Sheet. You must enable\n * the BigQuery advanced service before you can run this code.\n * @see http://developers.google.com/apps-script/advanced/bigquery#run_query\n * @see http://github.com/gsuitedevs/apps-script-samples/blob/master/advanced/bigquery.gs\n *\n * @returns {Spreadsheet} Returns a spreadsheet with BigQuery results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/spreadsheet\n */\nfunction runQuery() {\n  // Replace sample with your own BigQuery query.\n  var request = {\n    query:\n        'SELECT ' +\n            'LOWER(word) AS word, ' +\n            'SUM(word_count) AS count ' +\n        'FROM [bigquery-public-data:samples.shakespeare] ' +\n        'GROUP BY word ' +\n        'ORDER BY count ' +\n        'DESC LIMIT 10'\n  };\n  var queryResults = BigQuery.Jobs.query(request, PROJECT_ID);\n  var jobId = queryResults.jobReference.jobId;\n\n  // Wait for BQ job completion (with exponential backoff).\n  var sleepTimeMs = 500;\n  while (!queryResults.jobComplete) {\n    Utilities.sleep(sleepTimeMs);\n    sleepTimeMs *= 2;\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId);\n  }\n\n  // Get all results from BigQuery.\n  var rows = queryResults.rows;\n  while (queryResults.pageToken) {\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId, {\n      pageToken: queryResults.pageToken\n    });\n    rows = rows.concat(queryResults.rows);\n  }\n\n  // Return null if no data returned.\n  if (!rows) {\n    return Logger.log('No rows returned.');\n  }\n\n  // Create the new results spreadsheet.\n  var spreadsheet = SpreadsheetApp.create(QUERY_NAME);\n  var sheet = spreadsheet.getActiveSheet();\n\n  // Add headers to Sheet.\n  var headers = queryResults.schema.fields.map(function(field) {\n    return field.name.toUpperCase();\n  });\n  sheet.appendRow(headers);\n\n  // Append the results.\n  var data = new Array(rows.length);\n  for (var i = 0; i < rows.length; i++) {\n    var cols = rows[i].f;\n    data[i] = new Array(cols.length);\n    for (var j = 0; j < cols.length; j++) {\n      data[i][j] = cols[j].v;\n    }\n  }\n\n  // Start storing data in row 2, col 1\n  var START_ROW = 2;      // skip header row\n  var START_COL = 1;\n  sheet.getRange(START_ROW, START_COL, rows.length, headers.length).setValues(data);\n\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n}\n```\nè¯¥æŸ¥è¯¢é€šè¿‡æŸ¥çœ‹èå£«æ¯”äºšçš„ä½œå“ï¼ˆå±äº BigQueryçš„å…¬å…±æ•°æ®é›†ï¼‰ï¼Œå¾—å‡ºä»–æ‰€æœ‰ä½œå“ä¸­å‡ºç°æ¬¡æ•°æœ€å¤šçš„å‰10ä¸ªå•è¯ï¼Œå¹¶æŒ‰æµè¡Œç¨‹åº¦ä»é«˜åˆ°ä½æ’åºã€‚è¯•æƒ³ä¸€ä¸‹ï¼Œæ‰‹åŠ¨æ‰§è¡Œæ­¤æ“ä½œä¼šæœ‰å¤šå¤§çš„ä¹è¶£ï¼Œæ‚¨åº”è¯¥å¯¹BigQueryçš„æœ‰ç”¨æ€§æœ‰æ‰€äº†è§£ã€‚\n### ç‚¹å‡»runQueryè¿è¡Œ,æœŸé—´å¯èƒ½éœ€è¦éœ€è¦æˆæƒè®¤è¯\n![png](../img/bigquery/bigquery_presentation/6.png)\n![png](../img/bigquery/bigquery_presentation/7.png)\n\n### æˆåŠŸè¿è¡Œå,æˆ‘ä»¬å¯ä»¥å»drive.google.comä¸­æ‰¾åˆ°excelè¡¨æ ¼çš„urlé“¾æ¥,ç‚¹å‡»Most common wordsé‚£å—æ¡æ¡†\n![png](../img/bigquery/bigquery_presentation/8.png)\n\n### ç‚¹å‡»è¿›å…¥å,æˆ‘ä»¬å¯ä»¥çœ‹åˆ°bigqueryçš„å…¬å…±é›†æŸ¥è¯¢çš„æ•°æ®ç°åœ¨ç”¨è¡¨æ ¼å½¢å¼å‡ºç°äº†\n![png](../img/bigquery/bigquery_presentation/9.png)\n\n### æˆ‘ä»¬å¯ä»¥å»big query ç”¨sqlè¯­å¥æ“ä½œä¸€é,å¾—åˆ°çš„æ•°æ®ä¹Ÿå¾ˆexcelè¡¨æ ¼ä¸€æ ·\n![png](../img/bigquery/bigquery_presentation/10.png)\n\n### ä¸‹ä¸€æ­¥,æˆ‘ä»¬è¦é€šè¿‡æ•°æ®åˆ›å»ºå›¾è¡¨ğŸ“ˆ\n##### 1 åˆ°ç›®å‰ä¸ºæ­¢,æˆ‘ä»¬ç¼–å†™äº†ä¸€ä¸ªæŸ¥è¯¢èå£«æ¯”äºšçš„åº”ç”¨ç¨‹åº,è¿›è¡Œäº†æ’åº,ç„¶åå°†ç»“æ„æ˜¾ç¤ºåœ¨è¡¨æ ¼ä¸­,æˆ‘ä»¬ç°åœ¨è¦createColumnChart()åŠŸèƒ½,{åœ¨æœ€åä¸€è¡Œä»£ç ä¹‹å}bq-sheets-slides.gsrunQuery()\n```\n/**\n * Uses spreadsheet data to create columnar chart.\n * @param {Spreadsheet} Spreadsheet containing results data\n * @returns {EmbeddedChart} visualizing the results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/embedded-chart\n */\nfunction createColumnChart(spreadsheet) {\n  // Retrieve the populated (first and only) Sheet.\n  var sheet = spreadsheet.getSheets()[0];\n  // Data range in Sheet is from cell A2 to B11\n  var START_CELL = 'A2';  // skip header row\n  var END_CELL = 'B11';\n  // Place chart on Sheet starting on cell E5.\n  var START_ROW = 5;      // row 5\n  var START_COL = 5;      // col E\n  var OFFSET = 0;\n\n  // Create & place chart on the Sheet using above params.\n  var chart = sheet.newChart()\n     .setChartType(Charts.ChartType.COLUMN)\n     .addRange(sheet.getRange(START_CELL + ':' + END_CELL))\n     .setPosition(START_ROW, START_COL, OFFSET, OFFSET)\n     .build();\n  sheet.insertChart(chart);\n}\n```\n#### 2 è¿”å›ç”µå­è¡¨æ ¼:åœ¨ä¸Šé¢çš„ä»£ç ä¸­, createColumnChart()å‡½æ•°éœ€è¦ç”µå­è¡¨æ ¼å¯¹è±¡,å› æ­¤è°ƒæ•´åº”ç”¨ç¨‹åºä»¥è¿”å›spreadsheetå¯¹è±¡,ä»¥ä¾¿å¯ä»¥å°†å…¶ä¼ é€’ç»™createColumnChart().æ‰€ä»¥æˆ‘ä»¬åœ¨runQuery()å‡½æ•°æœ€åä¸€è¡Œæ·»åŠ ä¸€ä¸‹ä»£ç \n```\nLogger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n\n  // Return the spreadsheet object for later use.\n  return spreadsheet;\n}\n```\n#### 3 æ‰§è¡ŒcreateBigQueryPresentation()åŠŸèƒ½,æˆ‘ä»¬æŠŠBigQueryå’Œchart-creation åŠŸèƒ½åˆ†å¼€æ˜¯ä¸é”™çš„æ³¨æ„.æˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªcreateBigQueryPresentation()åŠŸèƒ½å»é©±åŠ¨app,è°ƒç”¨ä¸¤è€…å’Œè°ƒç”¨createColumnChart()å‡½æ•°\n```\n/**\n * Runs a BigQuery query, adds data and a chart in a Sheet.\n */\nfunction createBigQueryPresentation() {\n  var spreadsheet = runQuery();\n  createColumnChart(spreadsheet);\n}\n```\næˆ‘ä»¬æŠŠè¿™å—ä»£ç æ”¾åˆ°ä»¥ä¸‹ä»£ç ä¸‹é¢\n```\n// Filename for data results\nvar QUERY_NAME = \"Most common words in all of Shakespeare's works\";\n// Replace this value with your Google Cloud API project ID\nvar PROJECT_ID = 'project-id-4323960745859879834';\nif (!PROJECT_ID) throw Error('Project ID is required in setup');\n```\n\n### ä¸ºäº†ä½¿å¾—ä»£ç å¯ä»¥å¤ç”¨æ€§,æˆ‘ä»¬æœ‰ä¸¤æ­¥è¦åš\n1: è¿”å›spreadsheetå¯¹è±¡\n2: åˆ›å»ºä¸€ä¸ªé©±åŠ¨å‡½æ•°\nåŒæ—¶å¦‚æœä¸€ä¸ªåŒäº‹éœ€è¦å¤ç”¨runQuery()å‡½æ•°,ä½†æ˜¯ä¸æƒ³è¦è¿æ¥ç™»å½•å‘¢\næˆ‘ä»¬å¯ä»¥ä»£ç ä¿®æ”¹ä¸€ä¸‹,å…·ä½“å¦‚ä¸‹:\n```javascript\n/**\n * Runs a BigQuery query, adds data and a chart in a Sheet.\n */\nfunction createBigQueryPresentation() {\n  var spreadsheet = runQuery();\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n  createColumnChart(spreadsheet);\n}\n```\n#### å…·ä½“å‘ˆç°å¦‚ä¸‹:\n\n![png](../img/bigquery/bigquery_presentation/11.png)\n\næ•´æ®µä»£ç å…·ä½“å¦‚ä¸‹:\n``` javascript\n/**\n * Copyright 2018 Google LLC\n *\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at apache.org/licenses/LICENSE-2.0.\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n */\n\n// Filename for data results\nvar QUERY_NAME = \"Most common words in all of Shakespeare's works\";\n// Replace this value with your Google Cloud API project ID\nvar PROJECT_ID = 'qwiklabs-gcp-5c0cf6ad321746e4';\nif (!PROJECT_ID) throw Error('Project ID is required in setup');\n\n/**\n * Runs a BigQuery query, adds data and a chart in a Sheet.\n */\nfunction createBigQueryPresentation() {\n  var spreadsheet = runQuery();\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n  createColumnChart(spreadsheet);\n}\n\n/**\n * Runs a BigQuery query; puts results into Sheet. You must enable\n * the BigQuery advanced service before you can run this code.\n * @see http://developers.google.com/apps-script/advanced/bigquery#run_query\n * @see http://github.com/gsuitedevs/apps-script-samples/blob/master/advanced/bigquery.gs\n *\n * @returns {Spreadsheet} Returns a spreadsheet with BigQuery results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/spreadsheet\n */\nfunction runQuery() {\n  // Replace sample with your own BigQuery query.\n  var request = {\n    query:\n        'SELECT ' +\n            'LOWER(word) AS word, ' +\n            'SUM(word_count) AS count ' +\n        'FROM [bigquery-public-data:samples.shakespeare] ' +\n        'GROUP BY word ' +\n        'ORDER BY count ' +\n        'DESC LIMIT 10'\n  };\n  var queryResults = BigQuery.Jobs.query(request, PROJECT_ID);\n  var jobId = queryResults.jobReference.jobId;\n\n  // Wait for BQ job completion (with exponential backoff).\n  var sleepTimeMs = 500;\n  while (!queryResults.jobComplete) {\n    Utilities.sleep(sleepTimeMs);\n    sleepTimeMs *= 2;\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId);\n  }\n\n  // Get all results from BigQuery.\n  var rows = queryResults.rows;\n  while (queryResults.pageToken) {\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId, {\n      pageToken: queryResults.pageToken\n    });\n    rows = rows.concat(queryResults.rows);\n  }\n\n  // Return null if no data returned.\n  if (!rows) {\n    return Logger.log('No rows returned.');\n  }\n\n  // Create the new results spreadsheet.\n  var spreadsheet = SpreadsheetApp.create(QUERY_NAME);\n  var sheet = spreadsheet.getActiveSheet();\n\n  // Add headers to Sheet.\n  var headers = queryResults.schema.fields.map(function(field) {\n    return field.name.toUpperCase();\n  });\n  sheet.appendRow(headers);\n\n  // Append the results.\n  var data = new Array(rows.length);\n  for (var i = 0; i < rows.length; i++) {\n    var cols = rows[i].f;\n    data[i] = new Array(cols.length);\n    for (var j = 0; j < cols.length; j++) {\n      data[i][j] = cols[j].v;\n    }\n  }\n\n  // Start storing data in row 2, col 1\n  var START_ROW = 2;      // skip header row\n  var START_COL = 1;\n  sheet.getRange(START_ROW, START_COL, rows.length, headers.length).setValues(data);\n\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n\n  // Return the spreadsheet object for later use.\n  return spreadsheet;\n}\n\n/**\n * Uses spreadsheet data to create columnar chart.\n * @param {Spreadsheet} Spreadsheet containing results data\n * @returns {EmbeddedChart} visualizing the results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/embedded-chart\n */\nfunction createColumnChart(spreadsheet) {\n  // Retrieve the populated (first and only) Sheet.\n  var sheet = spreadsheet.getSheets()[0];\n  // Data range in Sheet is from cell A2 to B11\n  var START_CELL = 'A2';  // skip header row\n  var END_CELL = 'B11';\n  // Place chart on Sheet starting on cell E5.\n  var START_ROW = 5;      // row 5\n  var START_COL = 5;      // col E\n  var OFFSET = 0;\n\n  // Create & place chart on the Sheet using above params.\n  var chart = sheet.newChart()\n     .setChartType(Charts.ChartType.COLUMN)\n     .addRange(sheet.getRange(START_CELL + ':' + END_CELL))\n     .setPosition(START_ROW, START_COL, OFFSET, OFFSET)\n     .build();\n  sheet.insertChart(chart);\n}\n```\n\nç„¶åæˆ‘ä»¬é€šè¿‡é€‰run-createBigQueryPresentation()å‡½æ•°,æˆ‘ä»¬å»åˆ°google driveå»çœ‹æˆ‘ä»¬è¡¨æ ¼,å›¾ç‰‡\n\næœ€åä¸€éƒ¨åˆ†,æˆ‘ä»¬å°†åˆ›å»ºä¸€ä¸ªæ–°çš„google ppt,ç„¶åå†æ ‡é¢˜å¹»ç¯ç‰‡ä¸Šå¡«å……æ ‡é¢˜å’Œå‰¯æ ‡é¢˜,ç„¶åæ·»åŠ 2å¼ æ–°slide,ä¸€ä¸ªç”¨äºæ•°æ®å•å…ƒæ ¼,å¦å¤–ä¸€ä¸ªç”¨äºå›¾è¡¨\n#### 1 åˆ›å»ºå¹»ç¯ç‰‡\n``` javascript\n/**\n * Create presentation with spreadsheet data & chart\n * @param {Spreadsheet} Spreadsheet with results data\n * @param {EmbeddedChart} Sheets chart to embed on slide\n * @returns {Presentation} Slide deck with results\n */\nfunction createSlidePresentation(spreadsheet, chart) {\n  // Create the new presentation.\n  var deck = SlidesApp.create(QUERY_NAME);\n\n  // Populate the title slide.\n  var [title, subtitle] = deck.getSlides()[0].getPageElements();\n  title.asShape().getText().setText(QUERY_NAME);\n  subtitle.asShape().getText().setText('via GCP and G Suite APIs:\\n' +\n    'Google Apps Script, BigQuery, Sheets, Slides');\n```\n\n#### 2 æ·»åŠ æ•°æ®è¡¨: æˆ‘ä»¬é€šè¿‡createSlidePresentation()æŠŠå•å…ƒæ ¼æ•°æ®ä»googleè¡¨æ ¼å¯¼å…¥æˆ‘ä»¬çš„æ–°pptä¸­\n``` java\n  // Data range to copy is from cell A1 to B11\n  var START_CELL = 'A1';  // include header row\n  var END_CELL = 'B11';\n  // Add the table slide and insert an empty table on it of\n  // the dimensions of the data range; fails if Sheet empty.\n  var tableSlide = deck.appendSlide(SlidesApp.PredefinedLayout.BLANK);\n  var sheetValues = spreadsheet.getSheets()[0].getRange(\n      START_CELL + ':' + END_CELL).getValues();\n  var table = tableSlide.insertTable(sheetValues.length, sheetValues[0].length);\n\n  // Populate the table with spreadsheet data.\n  for (var i = 0; i < sheetValues.length; i++) {\n    for (var j = 0; j < sheetValues[0].length; j++) {\n      table.getCell(i, j).getText().setText(String(sheetValues[i][j]));\n    }\n  }\n```\n\n#### 3 å¯¼å…¥å›¾è¡¨,åœ¨createSlidePresentation()å‡½æ•°ä¸­å†åˆ›å»ºä¸€å¼ ppt,ä»ç”µå­è¡¨æ ¼ä¸­å¯¼å…¥å›¾è¡¨,è¿”å›Presentationå¯¹è±¡deck\n``` javascript\n  // Add a chart slide and insert the chart on it.\n  var chartSlide = deck.appendSlide(SlidesApp.PredefinedLayout.BLANK);\n  chartSlide.insertSheetsChart(chart);\n\n  // Return the presentation object for later use.\n  return deck;\n}\n```\n#### 4 è¿”å›å›¾: æˆ‘ä»¬éœ€è¦è®©createColumnChart()è¿”å›å¯¹è±¡,æ‰€ä»¥æˆ‘ä»¬åœ¨å°¾ç«¯æ¥æ”¶createColumnChart():\n```javascript\n // Return chart object for later use\n  return chart;\n}\n```\n\n#### æ›´æ–°createBigQueryPresentation(),å› ä¸ºcreateColumnChart()è¿”å›äº†å›¾è¡¨,æ‰€ä»¥æˆ‘ä»¬è¦æŠŠè¿™ä¸ªå›¾è¡¨ä¿å­˜åˆ°å˜é‡,ç„¶åæŠŠç”µå­è¡¨æ ¼å’Œå›¾è¡¨éƒ½ä¼ é€’ç»™createSlidePresentation()å‡½æ•°\n```javascript\n/**\n * Runs a BigQuery query, adds data and a chart in a Sheet,\n * and adds the data and chart to a new slide presentation.\n */\nfunction createBigQueryPresentation() {\n  var spreadsheet = runQuery();\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n  var chart = createColumnChart(spreadsheet);\n  var deck = createSlidePresentation(spreadsheet, chart);\n  Logger.log('Results slide deck created: %s', deck.getUrl());\n}\n```\n\næœ€åçš„ç‰ˆæœ¬å¦‚ä¸‹:\n``` javescript\n// Filename for data results\nvar QUERY_NAME = \"Most common words in all of Shakespeare's works\";\n// Replace this value with your Google Cloud API project ID\nvar PROJECT_ID = '<YOUR_PROJECT_ID>';\nif (!PROJECT_ID) throw Error('Project ID is required in setup');\n\n/**\n * Runs a BigQuery query; puts results into Sheet. You must enable\n * the BigQuery advanced service before you can run this code.\n * @see http://developers.google.com/apps-script/advanced/bigquery#run_query\n * @see http://github.com/gsuitedevs/apps-script-samples/blob/master/advanced/bigquery.gs\n *\n * @returns {Spreadsheet} Returns a spreadsheet with BigQuery results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/spreadsheet\n */\nfunction runQuery() {\n  // Replace sample with your own BigQuery query.\n  var request = {\n    query:\n        'SELECT ' +\n            'LOWER(word) AS word, ' +\n            'SUM(word_count) AS count ' +\n        'FROM [bigquery-public-data:samples.shakespeare] ' +\n        'GROUP BY word ' +\n        'ORDER BY count ' +\n        'DESC LIMIT 10'\n  };\n  var queryResults = BigQuery.Jobs.query(request, PROJECT_ID);\n  var jobId = queryResults.jobReference.jobId;\n\n  // Wait for BQ job completion (with exponential backoff).\n  var sleepTimeMs = 500;\n  while (!queryResults.jobComplete) {\n    Utilities.sleep(sleepTimeMs);\n    sleepTimeMs *= 2;\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId);\n  }\n\n  // Get all results from BigQuery.\n  var rows = queryResults.rows;\n  while (queryResults.pageToken) {\n    queryResults = BigQuery.Jobs.getQueryResults(PROJECT_ID, jobId, {\n      pageToken: queryResults.pageToken\n    });\n    rows = rows.concat(queryResults.rows);\n  }\n\n  // Return null if no data returned.\n  if (!rows) {\n    return Logger.log('No rows returned.');\n  }\n\n  // Create the new results spreadsheet.\n  var spreadsheet = SpreadsheetApp.create(QUERY_NAME);\n  var sheet = spreadsheet.getActiveSheet();\n\n  // Add headers to Sheet.\n  var headers = queryResults.schema.fields.map(function(field) {\n    return field.name.toUpperCase();\n  });\n  sheet.appendRow(headers);\n\n  // Append the results.\n  var data = new Array(rows.length);\n  for (var i = 0; i < rows.length; i++) {\n    var cols = rows[i].f;\n    data[i] = new Array(cols.length);\n    for (var j = 0; j < cols.length; j++) {\n      data[i][j] = cols[j].v;\n    }\n  }\n\n  // Start storing data in row 2, col 1\n  var START_ROW = 2;      // skip header row\n  var START_COL = 1;\n  sheet.getRange(START_ROW, START_COL, rows.length, headers.length).setValues(data);\n\n  // Return the spreadsheet object for later use.\n  return spreadsheet;\n}\n\n/**\n * Uses spreadsheet data to create columnar chart.\n * @param {Spreadsheet} Spreadsheet containing results data\n * @returns {EmbeddedChart} visualizing the results\n * @see http://developers.google.com/apps-script/reference/spreadsheet/embedded-chart\n */\nfunction createColumnChart(spreadsheet) {\n  // Retrieve the populated (first and only) Sheet.\n  var sheet = spreadsheet.getSheets()[0];\n  // Data range in Sheet is from cell A2 to B11\n  var START_CELL = 'A2';  // skip header row\n  var END_CELL = 'B11';\n  // Place chart on Sheet starting on cell E5.\n  var START_ROW = 5;      // row 5\n  var START_COL = 5;      // col E\n  var OFFSET = 0;\n\n  // Create & place chart on the Sheet using above params.\n  var chart = sheet.newChart()\n     .setChartType(Charts.ChartType.COLUMN)\n     .addRange(sheet.getRange(START_CELL + ':' + END_CELL))\n     .setPosition(START_ROW, START_COL, OFFSET, OFFSET)\n     .build();\n  sheet.insertChart(chart);\n\n  // Return the chart object for later use.\n  return chart;\n}\n\n/**\n * Create presentation with spreadsheet data & chart\n * @param {Spreadsheet} Spreadsheet with results data\n * @param {EmbeddedChart} Sheets chart to embed on slide\n * @returns {Presentation} Returns a slide deck with results\n * @see http://developers.google.com/apps-script/reference/slides/presentation\n */\nfunction createSlidePresentation(spreadsheet, chart) {\n  // Create the new presentation.\n  var deck = SlidesApp.create(QUERY_NAME);\n\n  // Populate the title slide.\n  var [title, subtitle] = deck.getSlides()[0].getPageElements();\n  title.asShape().getText().setText(QUERY_NAME);\n  subtitle.asShape().getText().setText('via GCP and G Suite APIs:\\n' +\n    'Google Apps Script, BigQuery, Sheets, Slides');\n\n  // Data range to copy is from cell A1 to B11\n  var START_CELL = 'A1';  // include header row\n  var END_CELL = 'B11';\n  // Add the table slide and insert an empty table on it of\n  // the dimensions of the data range; fails if Sheet empty.\n  var tableSlide = deck.appendSlide(SlidesApp.PredefinedLayout.BLANK);\n  var sheetValues = spreadsheet.getSheets()[0].getRange(\n      START_CELL + ':' + END_CELL).getValues();\n  var table = tableSlide.insertTable(sheetValues.length, sheetValues[0].length);\n\n  // Populate the table with spreadsheet data.\n  for (var i = 0; i < sheetValues.length; i++) {\n    for (var j = 0; j < sheetValues[0].length; j++) {\n      table.getCell(i, j).getText().setText(String(sheetValues[i][j]));\n    }\n  }\n\n  // Add a chart slide and insert the chart on it.\n  var chartSlide = deck.appendSlide(SlidesApp.PredefinedLayout.BLANK);\n  chartSlide.insertSheetsChart(chart);\n\n  // Return the presentation object for later use.\n  return deck;\n}\n\n/**\n * Runs a BigQuery query, adds data and a chart in a Sheet,\n * and adds the data and chart to a new slide presentation.\n */\nfunction createBigQueryPresentation() {\n  var spreadsheet = runQuery();\n  Logger.log('Results spreadsheet created: %s', spreadsheet.getUrl());\n  var chart = createColumnChart(spreadsheet);\n  var deck = createSlidePresentation(spreadsheet, chart);\n  Logger.log('Results slide deck created: %s', deck.getUrl());\n}\n```\n\n## æ‰§è¡Œå,æˆ‘ä»¬å°±ä¼šçœ‹åˆ°ä»¥ä¸‹æ•ˆæœ:\n\n![png](../img/bigquery/bigquery_presentation/12.png)\n![png](../img/bigquery/bigquery_presentation/13.png)\n![png](../img/bigquery/bigquery_presentation/14.png)\n![png](../img/bigquery/bigquery_presentation/15.png)\n![png](../img/bigquery/bigquery_presentation/16.png)\n\n# æ˜¯ä¸æ˜¯è¶…é…·å‘¢??"
    },
    {
      "id": "/2020/4/15/bq_sqlå¸¸ç”¨çŸ­è¯­",
      "metadata": {
        "permalink": "/blog/2020/4/15/bq_sqlå¸¸ç”¨çŸ­è¯­",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-15-bq_sqlå¸¸ç”¨çŸ­è¯­.md",
        "source": "@site/blog/2020-4-15-bq_sqlå¸¸ç”¨çŸ­è¯­.md",
        "title": "Bigqueryä¸­sqlè¯­å¥å¸¸ç”¨å‘½ä»¤",
        "description": "è¿æ¥æ•°æ®åº“",
        "date": "2020-04-15T00:00:00.000Z",
        "formattedDate": "April 15, 2020",
        "tags": [
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "command line",
            "permalink": "/blog/tags/command-line"
          },
          {
            "label": "github",
            "permalink": "/blog/tags/github"
          }
        ],
        "readingTime": 3.475,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "bq_sql",
          "title": "Bigqueryä¸­sqlè¯­å¥å¸¸ç”¨å‘½ä»¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "gcp",
            "command line",
            "github"
          ]
        },
        "prevItem": {
          "title": "google script + excel+ google drive",
          "permalink": "/blog/2020/4/16/bq_è„šæœ¬åˆ¶ä½œpresentation"
        },
        "nextItem": {
          "title": "è°·æ­Œå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/15/gcp_å¸¸ç”¨å‘½ä»¤"
        }
      },
      "content": "## è¿æ¥æ•°æ®åº“\n```sql\ngcloud sql connect  qwiklabs-demo --user=root\n```\n\n## åˆå¹¶ä¸¤ä¸ªè¡¨æ ¼union\n<!-- truncate -->\n```sql\nSELECT start_station_name AS top_stations, num FROM london1 WHERE num>100000\nUNION\nSELECT end_station_name, num FROM london2 WHERE num>100000\nORDER BY top_stations DESC;\n```\nå‚è€ƒ [Uninonå’Œjoinçš„åŒºåˆ«](https://blog.csdn.net/qq_41359051/article/details/98469387#UNION_157)\n\n[UNION](https://www.cnblogs.com/CraryPrimitiveMan/p/3665154.html)ä¸­é—´çš„å…³é”®å­—é€šè¿‡å°†â€œ london2â€æ•°æ®ä¸â€œ london1â€åŒåŒ–æ¥ç»„åˆè¿™äº›æŸ¥è¯¢çš„è¾“å‡ºã€‚ç”±äºå°†â€œ london1â€ä¸â€œ london2â€ç»“åˆåœ¨ä¸€èµ·ï¼Œå› æ­¤åˆ—åä¼˜å…ˆä¸ºâ€œ top_stationsâ€å’Œâ€œ numâ€ã€‚\n\nORDER BY å°†æŒ‰ç…§â€œ top_stationsâ€åˆ—å€¼çš„å­—æ¯é¡ºåºå’Œé™åºå¯¹æœ€ç»ˆçš„è”åˆè¡¨è¿›è¡Œæ’åºã€‚\n![png](../img/mysql/bq_mysql.png)\n\n## æ·»åŠ æ•°æ®  insert into è¡¨ (å­—æ®µ,å­—æ®µ) values (å€¼,å€¼);\n```sql\nINSERT INTO london1 (start_station_name, num) VALUES (\"test destination\", 1);\n```\n## è¿è¡ŒæŸ¥è¯¢å‘½ä»¤\nbq query --use_legacy_sql=false 'select å­—æ®µ from è¡¨æ ¼ where æ¡ä»¶'\næ³¨æ„çš„åœ°æ–¹æ˜¯ \n### use_legacy_sql=false è¡¨ç¤ºä½¿ç”¨æ ‡å‡†sqlè¯­å¥\n### æ¡ä»¶çš„æ—¶å€™å¯ä»¥ä½¿ç”¨åŒå¼•å·åšåŒºåˆ†\"\"\n\n``` sql\n#standardSQL\nSELECT  FROM `data-to-inghts.ecommerce.rev_transactions` LIMIT 1000\n```\n```\nWhat's wrong with the previous query to view 1000 items? check\nThere is a typo in the dataset name check\nWe have not specified any columns in the SELECT\nThere is a typo in the table name\nWe are using legacy SQL\n```\n\nwhat about this updated query?\n```sql\n#standardSQL\nSELECT * FROM [data-to-insights:ecommerce.rev_transactions] LIMIT 1000\n'''\nwe are using legacy sql\n\nwhat about this query that uses standard SQL\n```sql\n#standardSQL\nSELECT FROM `data-to-insights.ecommerce.rev_transactions`\n```\nno columns defined in select\n\nwhat about now?\n```sql\n#standardSQL\nSELECT\nfullVisitorId\nFROM `data-to-insights.ecommerce.rev_transactions`\n```\nwithout aggregations,limits or sorting, this query is not insightful\n\nwhat about now?\n```sql\n#standardSQL\nSELECT fullVisitorId hits_page_pageTitle\nFROM `data-to-insights.ecommerce.rev_transactions` LIMIT 1000\n```\nit can be excuated.\n\nwhat about now?\n```sql\n#standardSQL\nSELECT\n  fullVisitorId\n  , hits_page_pageTitle\nFROM `data-to-insights.ecommerce.rev_transactions` LIMIT 1000\n```\nthis returns result, but visitors maybe counted twice.\n\nwhat about this? an aggregation function, count(), was added.\n```sql\n#standardSQL\nSELECT\nCOUNT(fullVisitorId) AS visitor_count\n, hits_page_pageTitle\nFROM `data-to-insights.ecommerce.rev_transactions`\n```\næ²¡å»é‡,the count()function does not de-deduplicate the same fullvisitorid\nit is missing a group by clause\n\nin this next query, group by and distinct statements were added\n```sql\n#standardSQL\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS visitor_count\n, hits_page_pageTitle\nFROM `data-to-insights.ecommerce.rev_transactions`\nGROUP BY hits_page_pageTitle\n```\n\nwe can add filter 'where' to filter results\n```sql\n#standardSQL\nSELECT\nCOUNT(DISTINCT fullVisitorId) AS visitor_count\n, hits_page_pageTitle\nFROM `data-to-insights.ecommerce.rev_transactions`\nWHERE hits_page_pageTitle = \"Checkout Confirmation\"\nGROUP BY hits_page_pageTitle\n```\n\nList the cities with the most transactions with your ecommerce site\n```sql\nSELECT\ngeoNetwork_city,\nsum(totals_transactions) as totals_transactions,\nCOUNT( DISTINCT fullVisitorId) AS distinct_visitors\nFROM\n`data-to-insights.ecommerce.rev_transactions`\nGROUP BY geoNetwork_city\nOrder by distinct_visitors Desc\n```\n\nwhats wrong with the following query?\n```sql\n#standardSQL\nSELECT\ngeoNetwork_city,\nSUM(totals_transactions) AS total_products_ordered,\nCOUNT( DISTINCT fullVisitorId) AS distinct_visitors,\nSUM(totals_transactions) / COUNT( DISTINCT fullVisitorId) AS avg_products_ordered\nFROM\n`data-to-insights.ecommerce.rev_transactions`\nWHERE avg_products_ordered > 20\nGROUP BY geoNetwork_city\nORDER BY avg_products_ordered DESC\n```\nwe cannot filter aggregated fields in the 'where' clause ( use 'Having' instead) ä¸å¯ä»¥ç”¨whereæ¥èšåˆå‡½æ•°çš„å­—æ®µ,è¦ç”¨having\nwe cannot filter on aliased fields within the 'where' clause\nwhereè¿‡æ»¤å¥ä¸­ä¸èƒ½ä½¿ç”¨åˆ«å\n\npossible solution\n```sql\nselect geoNetwork_city, SUM(totals_transactions) as total_products_ordered, count(distinct fullvisitorID) as distinct_visitors,\nsum(totals_transactions) / count(distinct fullVisitorId) As avg_products_ordered\nfrom\n`data-to-insights.ecommerce.rev_transactions`\nGroup by geoNetwork_city\nHaving avg_products_ordered > 20\norder by avg_products_ordered\n```\n\n```sql\n#standardSQL\nSELECT\nCOUNT(hits_product_v2ProductName) as number_of_products,\nhits_product_v2ProductCategory\nFROM `data-to-insights.ecommerce.rev_transactions`\nWHERE hits_product_v2ProductName IS NOT NULL\nGROUP BY hits_product_v2ProductCategory\nORDER BY number_of_products DESC\n```\nè¿™é‡Œçš„é—®é¢˜æ˜¯count()å‡½æ•°é‡Œé¢çš„å­—æ®µæ²¡æœ‰åšdistinct,æœ‰å¯èƒ½å¯¼è‡´é‡å¤\nThe count() function is not the distinct number of products in each category\n\npossible solution\n```sql\n#standardSQL\nSELECT\nCOUNT(DISTINCT hits_product_v2ProductName) as number_of_products,\nhits_product_v2ProductCategory\nFROM `data-to-insights.ecommerce.rev_transactions`\nWHERE hits_product_v2ProductName IS NOT NULL\nGROUP BY hits_product_v2ProductCategory\nORDER BY number_of_products DESC\nLIMIT 5\n```"
    },
    {
      "id": "/2020/4/15/gcp_å¸¸ç”¨å‘½ä»¤",
      "metadata": {
        "permalink": "/blog/2020/4/15/gcp_å¸¸ç”¨å‘½ä»¤",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-15-gcp_å¸¸ç”¨å‘½ä»¤.md",
        "source": "@site/blog/2020-4-15-gcp_å¸¸ç”¨å‘½ä»¤.md",
        "title": "è°·æ­Œå¸¸ç”¨å‘½ä»¤",
        "description": "åˆ—å‡ºæ´»åŠ¨è´¦å·åç§°",
        "date": "2020-04-15T00:00:00.000Z",
        "formattedDate": "April 15, 2020",
        "tags": [
          {
            "label": "gcp",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "command line",
            "permalink": "/blog/tags/command-line"
          },
          {
            "label": "github",
            "permalink": "/blog/tags/github"
          }
        ],
        "readingTime": 0.355,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "gcp_command_line",
          "title": "è°·æ­Œå¸¸ç”¨å‘½ä»¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "gcp",
            "command line",
            "github"
          ]
        },
        "prevItem": {
          "title": "Bigqueryä¸­sqlè¯­å¥å¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/15/bq_sqlå¸¸ç”¨çŸ­è¯­"
        },
        "nextItem": {
          "title": "dataflowç®€å•å…¥é—¨-apache beam åŸºæœ¬æ¦‚å¿µ",
          "permalink": "/blog/2020/4/11/dataflow-apache beamåŸºæœ¬æ¦‚å¿µ"
        }
      },
      "content": "åˆ—å‡ºæ´»åŠ¨è´¦å·åç§°\n```python\ngcloud auth list\n```\n<!--truncate-->\nåˆ—å‡ºé¡¹ç›®id\n```\ngcloud config list project\n```\n\nè®¾ç½®é¡¹ç›®id \n```\ngcloud config set project project ID\n```\n\nåˆ—ä¸¾æ‰€æœ‰é¡¹ç›®\n```\ngcloud projects list\n```\n\næŸ¥è¯¢æœ‰å“ªäº›å¯ä»¥å¼€å¯çš„api,å¹¶ä¸”å¼€å¯\n```\ngcloud services list\ngcloud services enable bigquery.googleapis.com\n```"
    },
    {
      "id": "/2020/4/11/dataflow-apache beamåŸºæœ¬æ¦‚å¿µ",
      "metadata": {
        "permalink": "/blog/2020/4/11/dataflow-apache beamåŸºæœ¬æ¦‚å¿µ",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-dataflow-apache beamåŸºæœ¬æ¦‚å¿µ.md",
        "source": "@site/blog/2020-4-11-dataflow-apache beamåŸºæœ¬æ¦‚å¿µ.md",
        "title": "dataflowç®€å•å…¥é—¨-apache beam åŸºæœ¬æ¦‚å¿µ",
        "description": "1 Pipeline ç®¡é“",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "dataflow",
            "permalink": "/blog/tags/dataflow"
          },
          {
            "label": "bigquery",
            "permalink": "/blog/tags/bigquery"
          },
          {
            "label": "subpub",
            "permalink": "/blog/tags/subpub"
          },
          {
            "label": "steaming",
            "permalink": "/blog/tags/steaming"
          }
        ],
        "readingTime": 3.46,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataflow4",
          "title": "dataflowç®€å•å…¥é—¨-apache beam åŸºæœ¬æ¦‚å¿µ",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataflow",
            "bigquery",
            "subpub",
            "steaming"
          ]
        },
        "prevItem": {
          "title": "è°·æ­Œå¸¸ç”¨å‘½ä»¤",
          "permalink": "/blog/2020/4/15/gcp_å¸¸ç”¨å‘½ä»¤"
        },
        "nextItem": {
          "title": "dataflowç®€å•å…¥é—¨-ä½¿ç”¨apache_beamåˆ›å»º,è¿è¡Œä½œä¸š",
          "permalink": "/blog/2020/4/11/dataflowåˆ›å»ºä½œä¸š"
        }
      },
      "content": "## 1 Pipeline ç®¡é“\n\n## 2 Pcollection\n\n## 3 Ptransform\n\n<!--truncate-->\næ€»ä½“æµç¨‹å°±æ˜¯ è®¾ç½®pipeline >> read data >> pcollection >> ptransform >> pcollection \n\nå…¶ä¸­ptransformæœ‰ParDoå’Œè€¦åˆå‡½æ•°åŠŸèƒ½\n\nParDo()é‡Œé¢åªèƒ½æ¥æ”¶çš„æ˜¯DoFnç±»æˆ–é›†æˆDoFnç±»çš„å¯¹è±¡çš„å‡½æ•°,ParDoæ“ä½œçš„æ˜¯æ¯ä¸€è¡Œçš„æ•°æ®,å°±å¥½åƒdataframeé‡Œé¢çš„ä¸€è¡Œ\n# æ•²é»‘æ¿æ—¶é—´!!\n## è¯»å–Csvå’Œtxtæ–‡ä»¶,Pipelineè¯»å–å¾—æ¯ä¸€è¡Œä¸ºå­—ç¬¦ä¸²,ä¹Ÿå°±æ˜¯,å±äºpandasé‡Œé¢çš„seris, ä¹Ÿå°±æ˜¯åªæœ‰ä¸€åˆ—,å¦‚æœè¦åˆ†å¼€å‡ åˆ—,æˆ‘ä»¬å°±è¦splitå­—ç¬¦ä¸²,ç„¶ååšæˆkey:valueå­—å…¸æ ¼å¼.\n## è¯»å–avroæ–‡ä»¶æ—¶å€™,Pipelineè¯»å–çš„æ¯ä¸€è¡Œä¸ºå­—å…¸{},ä¹Ÿå°±æ˜¯pandasé‡Œé¢çš„ä¸€è¡Œdataframe,å¦‚æœè¦å–å€¼,æˆ‘ä»¬éœ€è¦element[åˆ—å]å°±å¯ä»¥å–åˆ°\n\nèšåˆå‡½æ•°æ“ä½œå,å°±ä¼šè¿”å›ä¸€ä¸ªæ•´ä½“çš„æ–°çš„Pcollection\nè®°ä½å­—å…¸æ ¼å¼è¦åšèšåˆå‡½æ•°è¦å˜æˆåˆ—è¡¨æˆ–è€…å…ƒç»„\n## Groupbykey--å¯¹è±¡æ˜¯ä¸€ä¸ªPcollection,é¦–å…ˆé€‰æ‹©è¦åšèšåˆçš„keyå’Œå€¼,ç„¶åtranformä¸€ä¸ªpcollectionæ ¼å¼ä¸ºturple,é‡Œé¢ä¸º(key,value),æœ€åé€šè¿‡ç®¡é“ | beam.GroupByKey()\nå°±ä¼šç”ŸæˆæŒ‰keyåˆ†ç±», ä»¥ä¸‹è¿™æ ·çš„æ•ˆæœ,å…·ä½“è¯´æ˜[ä¾‹å­](https://beam.apache.org/documentation/programming-guide/#core-beam-transforms)\n```\ncat, 1\ndog, 5\nand, 1\njump, 3\ntree, 2\ncat, 5\ndog, 2\nand, 2\ncat, 9\nand, 6\n...\n```\nå˜æˆ\n```\ncat, [1,5,9]\n\ndog, [5,2]\n\nand, [1,2,6]\n\njump, [3]\n\ntree, [2]               \n...\n```\n\n##CoGroupKey--æ“ä½œå¯¹è±¡Pcollection,æŠŠä¸¤ä¸ªPcollectioné€šè¿‡keyè¿æ¥èµ·æ¥,\næ¯”å¦‚Pcollection1:  æ˜¯å® ç‰©åå­—å’Œå¹´é¾„\n'''\n\"Amy\", 9\n\n\"Tom\", 3\n\n\"Shierly\", 3\n\n\"Miccle\", 4\n\n\"Dockey\", 4\n```\nPcollection2: æ˜¯å® ç‰©åå­—å’Œä¸»äººåå­—\n```\n\"Amy\", \"michael\"\n\n\"Tom\", \"Tommy\"\n\n\"Shierly\", \"Darren\"\n\n\"Miccle\", \"Cherry\"\n\n\"Dockey\", \"Dick\"\n```\n```\nage_list = [(\"Amy\", 9),\n\n       (\"Tom\", 3),\n\n      (\"Shierly\", 3)\n\n      (\"Miccle\", 4)\n\n      (\"Dockey\", 4])]\n\nOwner_list = [(\"Amy\", \"michael\"),\n\n(\"Tom\", \"Tommy\"),\n\n(\"Shierly\", \"Darren\"),\n\n(\"Miccle\", \"Cherry\"),\n\n(\"Dockey\", \"Dick\")]\n\nç„¶åæˆ‘ä»¬å¼€å§‹åˆ›å»ºä¸¤ä¸ªPcollections\n\nage = P |\"create age\" >> beam.Create(age_list)\nowner = P | \"create owner\" >> beam.Create(owner_list)\n\næˆ‘ä»¬ç”¨CoGroupbyKeyçš„æ—¶å€™,æ˜¯ä½¿ç”¨key,valueçš„å­—å…¸æ ¼å¼ä½œä¸ºè¾“å…¥\n\næ ¼å¼ä¸º results = {\"Pcollection1åå­—\":Pcollection1, \"Pcollection2åå­—\":Pcollection2} | beam.CoGroupByKey()\n\nå¾—åˆ°çš„æ•ˆæœæ˜¯ [(Key1,{\"Pcollection1åå­—\":Pcollection1, \"Pcollection2åå­—\":Pcollection2}), (Key2,{\"Pcollection1åå­—\":Pcollection1, \"Pcollection2åå­—\":Pcollection2}),(Key3,{\"Pcollection1åå­—\":Pcollection1, \"Pcollection2åå­—\":Pcollection2})]\n\n\nå‘ˆç°æ•ˆæœæ˜¯:\n[\"Tom\" , {'age':3, \"owner\":\"Tommy\"}\n\"Shierly\" ,{'age':3,\"owner\":\"Darren\"}\n\"Amy\",{'age':9,\"owner\":\"michael\"}\n...\n]\n```\n```\n## æ€»ç»“CoGroupByKeyå°±æ˜¯æŠŠä¸¤ä¸ªPcollectioné€šè¿‡å…±åŒçš„Keyè¿æ¥èµ·æ¥,ç„¶åç”¨å…ƒç»„(key,value)æ˜¾ç¤ºå‡ºæ¥,valuesæ˜¯ä¸€ä¸ªå­—å…¸æ ¼å¼,åŒ…å«Pcollectionåå­—:value_list\n\n# ä¸€å¥è¯è¡¨ç¤º: \n## COGroupByKeyå°±æ˜¯å…ƒç»„keyåŒ…å«å­—å…¸pcollectionä¸å®šä¹‰çš„value\n## GroubByKeyå°±æ˜¯å…ƒç»„keyåŒ…å«value_list\n\n## CombinePerKey(beam.combiners.MeanCombineFn)\nå°±æ˜¯æŠŠgroupbykey å†å¯¹æ¯ä¸ªkeyçš„valueåšåŠ æƒå¹³å‡\n\n## Flatten æŠŠå¤šä¸ªPCollection å˜æˆä¸€ä¸ª PCollection, \n## è¯´ç™½äº†å°±æ˜¯æŠŠå¤šä¸ªåˆ—è¡¨çš„å€¼æ”¾åˆ°ä¸€ä¸ªåˆ—è¡¨\n```\n# Flatten takes a tuple of PCollection objects.\n# Returns a single PCollection that contains all of the elements in the PCollection objects in that tuple.\nmerged = (\n    (pcoll1, pcoll2, pcoll3)\n    # A list of tuples can be \"piped\" directly into a Flatten transform.\n    | beam.Flatten())\n```"
    },
    {
      "id": "/2020/4/11/dataflowåˆ›å»ºä½œä¸š",
      "metadata": {
        "permalink": "/blog/2020/4/11/dataflowåˆ›å»ºä½œä¸š",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-dataflowåˆ›å»ºä½œä¸š.md",
        "source": "@site/blog/2020-4-11-dataflowåˆ›å»ºä½œä¸š.md",
        "title": "dataflowç®€å•å…¥é—¨-ä½¿ç”¨apache_beamåˆ›å»º,è¿è¡Œä½œä¸š",
        "description": "1. åœ¨æœ¬åœ°åˆ›å»ºæ¥æµ‹è¯•è¿è¡Œ",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "dataflow",
            "permalink": "/blog/tags/dataflow"
          },
          {
            "label": "bigquery",
            "permalink": "/blog/tags/bigquery"
          },
          {
            "label": "subpub",
            "permalink": "/blog/tags/subpub"
          },
          {
            "label": "steaming",
            "permalink": "/blog/tags/steaming"
          }
        ],
        "readingTime": 4.76,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataflow2",
          "title": "dataflowç®€å•å…¥é—¨-ä½¿ç”¨apache_beamåˆ›å»º,è¿è¡Œä½œä¸š",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataflow",
            "bigquery",
            "subpub",
            "steaming"
          ]
        },
        "prevItem": {
          "title": "dataflowç®€å•å…¥é—¨-apache beam åŸºæœ¬æ¦‚å¿µ",
          "permalink": "/blog/2020/4/11/dataflow-apache beamåŸºæœ¬æ¦‚å¿µ"
        },
        "nextItem": {
          "title": "dataflowç®€å•å…¥é—¨-æµæ•°æ®è¾“å…¥åˆ°bigquery",
          "permalink": "/blog/2020/4/11/dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery"
        }
      },
      "content": "1. åœ¨æœ¬åœ°åˆ›å»ºæ¥æµ‹è¯•è¿è¡Œ\n2. æ”¾åˆ°dataflowä¸Šè¿è¡Œ\n<!--truncate-->\n## æœ¬åœ°åˆ›å»ºjob\n1 é¦–å…ˆæ˜¯å®‰è£…æˆ‘ä»¬éœ€è¦æ‰“å·¥å…·åŒ…,å› ä¸ºæˆ‘æ˜¯å°†æ¥æ˜¯è¦è¿è¡Œåˆ°GCPä¸Šçš„,æ‰€ä»¥æˆ‘ä»¬å®‰è£…çš„æ˜¯\n```\npip install apache_beam[gcp]\n```\n2 å¯¼å…¥å„ç§åŒ…\n```\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import GoogleCloudOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nfrom apache_beam.io.textio import ReadFromText, WriteToText #ç”¨æ¥è¯»å†™æ–‡ä»¶\n```\n3 è®¾ç½®é…ç½®\n```\n# è¾“å…¥è¾“å‡ºè·¯å¾„\ninput_filename = \"./input.txt\"\noutput_filename = \"./output.txt\"\n\n#æŒ‡å®šæ‰§è¡Œé€‰é¡¹,ä»¥å‘Šè¯‰Pipelineè¿è¡Œä½ç½®å’Œè¿è¡Œæ–¹å¼\noptions = PipelineOptions()\noptions.view_as(StandardOptions).runner = \"direct\" #è¡¨ç¤ºæœ¬åœ°è¿è¡Œ\n\n# å†™åŠŸèƒ½ç±»\n#DoFnå°±æ˜¯æŠŠç±»,è½¬æ¢,callableçš„åŠŸèƒ½é›†åˆåœ¨ä¸€èµ·,æˆ‘ä»¬å¯ä»¥ç›´æ¥ç»§æ‰¿,æ–¹ä¾¿åé¢ç®¡é“ä½¿ç”¨\n#æ‰€æœ‰ParDoçš„æ“ä½œéƒ½å¿…é¡»è¦è·ŸDoFnç±»çš„å‡½æ•°,æ¯”å¦‚ParDo(DoFn())\n\n\nclass Split(beam.DoFn):\n    def process(self, element):\n        \"\"\"\n        Splits each row on commas and returns a dictionary representing the row\n        æˆ‘ä»¬è¿™é‡Œåšçš„äº‹æƒ…å°±æ˜¯ç±»ä¼¼mapper, å°†æ‰€æœ‰å…ƒç´ å˜æˆå­—å…¸\n        \"\"\"\n        country,duration,user = element.split(\",\")\n        print(len(element))# elementå°±æ˜¯æ¯è¡Œçš„æ•°æ®,è·Ÿhdfsä¸€æ ·,è§†åŠ›æœ‰é—®é¢˜\n        return [\n            {\n                'country':country,\n                'duration':duration,\n                'user':user\n            }\n        ]\n    \nclass CollectTimings(beam.DoFn):\n    def process(self,element):\n        result = [element('country'),element('duration')]\n        return result\n\nclass CollectUsers(beam.DoFn):\n    def process(self,element):\n        \"\"\"\n        Returns a list of tuples containing country and user name\n        \"\"\"\n        return [element('country'),element('user')]\n\nclass WriteToCSV(beam.DoFn):\n    def process(self,element):\n        \"\"\"\n        Prepares each row to be written in the csv\n        \"\"\"\n        result = [\"%s,%s,%s\"%(element[0],element[1]['user'][0],element[1]['timings'][0])]\n        return result\n\n#åˆ›å»ºç®¡é“å¯¹è±¡, åˆ›å»ºå˜é‡æ¥æ”¶Pcollection, ä¸€å®šè¦åŠ ä¸Š(),é˜²æ­¢æ­§ä¹‰,å¦‚æœå˜æˆ rows = P ç„¶å å†ç®¡ | ReadFromText(input_filename), å¾ˆå®¹æ˜“æŠ¥é”™\nwith beam.Pipeline(options=options) as p:\n    rows = (\n        P | ReadFromText(input_filename) | beam.ParDo(SPlit())\n    )\n    timings = (\n        rows |\n        beam.ParDo(CollectTimings()) |\n        \"Grouping timings\" >> beam.GroupByKey() | \n        \"Calculating average\" >> beam.CombineValues(\n            beam.combiners.MeanCombineFn()\n        )\n    )\n    users = (\n        rows |\n        beam.ParDo(CollectUsers()) |\n        \"Grouping users\" >> beam.GroupByKey() |\n        \"Counting users\" >> beam.CombineValues(\n            beam.combiners.CountCombineFn()\n        )\n    )\n    to_be_joined = (\n        {\n            'timings': timings,\n            'users': users\n        } |\n        beam.CoGroupByKey() |\n        beam.ParDo(WriteToCSV()) |\n        WriteToText(output_filename)\n    )\n\n\n#è¿™é‡Œçš„æ ¼å¼ä¸ºpvalue | \"label\" >> transform\nä¸ºä»€ä¹ˆè¦ä¸ºä»€ä¹ˆè¦ç”¨\"label\" >>,å…¶å®å¦‚æœä»»åŠ¡ä¸é‡å¤çš„æ—¶å€™,æ˜¯å¯ä»¥ä¸ç”¨çš„,ä½†æ˜¯æ¯”å¦‚è¿™é‡Œè€¦åˆå‡½æ•°groupbykeyå‡ºç°å·²ç»åœ¨pipelineäº†,å¦‚æœæ²¡æœ‰labelå°±ä¼šæŠ¥é”™,æ‰§è¡Œusersæ—¶å€™å°±ä¼šæŠ¥é”™\n\nGroupByKeyæ˜¯æŠŠkeyç›¸åŒçš„æ‹¼ä¸ºä¸ºä¸€ç»„,CombineValuesæ˜¯æŠŠå€¼ç´¯ç§¯ç›¸åŠ \nCoGroupByKeyæ˜¯æ ¹æ®keyæ‹¼æ¥ä¸€èµ·\n```\n\n# å¥½çš„,æœ¬åœ°æµ‹è¯•å¥½å, æˆ‘ä»¬è¦æ”¾åˆ°dataflowä¸Šè·‘äº†\n\n1 æˆ‘ä»¬éœ€è¦æ”¹çš„å°±æ˜¯ input,ouput è·¯å¾„,è®°ä½storage bucketçš„æƒé™\n```\ninput_filename = \"gs://dataflow_s/input.txt\"\noutput_filename = \"gs://dataflow_s/output.txt\"\n```\n\n2 options\n```\ndataflow_options = ['--project=query-11','--job_name=test-job','--temp_location=gs://dataflow_s/tmp','--region=us-central1']\ndataflow_options.append('--staging_location=gs://dataflow_s/stage')\noptions = PipelineOptions(dataflow_options)\ngcloud_options = options.view_as(GoogleCloudOptions)\noptions.view_as(StandardOptions).runner = \"dataflow\" # æŒ‡å®šåç«¯è·‘åœ¨dataflow\n```\nè¿™é‡Œæœ‰ä¸ªå‘,å¦‚æœä½ çš„apache beamæ˜¯2.15ç‰ˆæœ¬ä»¥ä¸Šçš„è¯,æ˜¯éœ€è¦å†™regionè¿™ä¸ªå‚æ•°çš„\nç„¶åå…¶ä»–çš„éƒ½å¾ˆæœ¬åœ°ä¸€æ ·,æ•´ä½“ä»£ç å¦‚ä¸‹:\n```\nimport logging\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import SetupOptions\nfrom apache_beam.options.pipeline_options import GoogleCloudOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nfrom apache_beam.io.textio import ReadFromText, WriteToText\n\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ninput_filename = \"gs://dataflow_s/input.txt\"\noutput_filename = \"gs://dataflow_s/output.txt\"\n\n\ndataflow_options = ['--project=query-11','--job_name=test-job','--temp_location=gs://dataflow_s/tmp']\ndataflow_options.append('--staging_location=gs://dataflow_s/stage')\noptions = PipelineOptions(dataflow_options)\ngcloud_options = options.view_as(GoogleCloudOptions)\n\n# gcloud_options.job_name = \"test-job\"\n\n\noptions.view_as(StandardOptions).runner = \"dataflow\"\n\n\nclass Split(beam.DoFn):\n\n    def process(self, element):\n        \"\"\"\n        Splits each row on commas and returns a dictionary representing the\n        row\n        \"\"\"\n        country, duration, user = element.split(\",\")\n\n        return [{\n            'country': country,\n            'duration': float(duration),\n            'user': user\n        }]\n\n\nclass CollectTimings(beam.DoFn):\n\n    def process(self, element):\n        \"\"\"\n        Returns a list of tuples containing country and duration\n        \"\"\"\n\n        result = [\n            (element['country'], element['duration'])\n        ]\n        return result\n\n\nclass CollectUsers(beam.DoFn):\n\n    def process(self, element):\n        \"\"\"\n        Returns a list of tuples containing country and user name\n        \"\"\"\n        result = [\n            (element['country'], element['user'])\n        ]\n        return result\n\n\nclass WriteToCSV(beam.DoFn):\n\n    def process(self, element):\n        \"\"\"\n        Prepares each row to be written in the csv\n        \"\"\"\n        result = [\n            \"{},{},{}\".format(\n                element[0],\n                element[1]['users'][0],\n                element[1]['timings'][0]\n            )\n        ]\n        return result\n\n\n\n\nwith beam.Pipeline(options=options) as p:\n    rows = (\n        p |\n        ReadFromText(input_filename) |\n        beam.ParDo(Split())\n    )\n\n    timings = (\n        rows |\n        beam.ParDo(CollectTimings()) |\n        \"Grouping timings\" >> beam.GroupByKey() |\n        \"Calculating average\" >> beam.CombineValues(\n            beam.combiners.MeanCombineFn()\n        )\n    )\n\n    users = (\n        rows |\n        beam.ParDo(CollectUsers()) |\n        \"Grouping users\" >> beam.GroupByKey() |\n        \"Counting users\" >> beam.CombineValues(\n            beam.combiners.CountCombineFn()\n        )\n    )\n\n    to_be_joined = (\n        {\n            'timings': timings,\n            'users': users\n        } |\n        beam.CoGroupByKey() |\n        beam.ParDo(WriteToCSV()) |\n        WriteToText(output_filename)\n    )\n```\n\n# ç„¶åæŠŠè¿™æ®µä»£ç æ”¾åˆ°gcloudä¸Š\nä½¿ç”¨å‘½ä»¤å¯åŠ¨,å…·ä½“æ˜¯å®‰è£…è™šæ‹Ÿç¯å¢ƒ,è¿›å…¥è™šæ‹Ÿç¯å¢ƒ,å®‰è£…apache beamåŒ…,è¿è¡Œpythonæ–‡ä»¶\n```\npip3 install --upgrade virtualenv --user\npython3 -m virtualenv env\nsource env/bin/activate\npip3 install --quiet apache-beam[gcp]\npython dataflow.py\n```\n\n# ç„¶åæˆ‘ä»¬å°±å¯ä»¥å»jobä¸Šçœ‹åˆ°è¿è¡Œæƒ…å†µ"
    },
    {
      "id": "/2020/4/11/dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery",
      "metadata": {
        "permalink": "/blog/2020/4/11/dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery.md",
        "source": "@site/blog/2020-4-11-dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery.md",
        "title": "dataflowç®€å•å…¥é—¨-æµæ•°æ®è¾“å…¥åˆ°bigquery",
        "description": "æ¦‚å¿µ: streaming å°±æ˜¯ åŠ¨æ€çš„æ„æ€, streaming dataå°±æ˜¯åŠ¨æ€æ•°æ®, job status is streaming å°±æ˜¯è¿™ä¸ªä½œä¸šæ˜¯ä¸€ç›´æŒç»­çš„",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "dataflow",
            "permalink": "/blog/tags/dataflow"
          },
          {
            "label": "bigquery",
            "permalink": "/blog/tags/bigquery"
          },
          {
            "label": "subpub",
            "permalink": "/blog/tags/subpub"
          },
          {
            "label": "steaming",
            "permalink": "/blog/tags/steaming"
          }
        ],
        "readingTime": 1.89,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataflow1",
          "title": "dataflowç®€å•å…¥é—¨-æµæ•°æ®è¾“å…¥åˆ°bigquery",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataflow",
            "bigquery",
            "subpub",
            "steaming"
          ]
        },
        "prevItem": {
          "title": "dataflowç®€å•å…¥é—¨-ä½¿ç”¨apache_beamåˆ›å»º,è¿è¡Œä½œä¸š",
          "permalink": "/blog/2020/4/11/dataflowåˆ›å»ºä½œä¸š"
        },
        "nextItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨dataflowæ¥è¿è¡Œjob",
          "permalink": "/blog/2020/4/11/dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2"
        }
      },
      "content": "æ¦‚å¿µ: streaming å°±æ˜¯ åŠ¨æ€çš„æ„æ€, streaming dataå°±æ˜¯åŠ¨æ€æ•°æ®, job status is streaming å°±æ˜¯è¿™ä¸ªä½œä¸šæ˜¯ä¸€ç›´æŒç»­çš„\n<!--truncate-->\n## å¤§ä½“æµç¨‹æ˜¯\n\ncreate dataset,table in Bigquery >> create topic in SubPub \n\n| >> create job and run >> public message in topic \n\n| >> go to your job to check wrte SucessfulRecords \n\n| >> go to your bigquery to check your data\n\n<!--truncate-->\n\n## å…·ä½“æµç¨‹æ˜¯\n\n1. é¦–å…ˆå»project åˆ›å»ºdatasetå’Œtable\n\n![png](../img/dataflow/dataflow_1/1.png)\n\n2. ç„¶åæˆ‘ä»¬å»åˆ°Dataflow, create job from template\n\n![png](../img/dataflow/dataflow_1/2.png)\n\n3. è¿™é‡Œæœ‰å‡ ç‚¹æˆ‘ä»¬è¦å¡«:\n  \njob name: ä½œä¸šåå­—\n\ncloud pub/sub input topic: è¾“å…¥è¯é¢˜,dataflowè¾“å…¥æ•°æ®åˆ°bigqueryåˆ›å»ºä¸€ä¸ªtopic\n\næ‰€ä»¥,æˆ‘ä»¬è¿™é‡Œå»åˆ°Pub/Sub,åˆ›å»ºtopic,æŠŠtopic name æ”¾åˆ° cloud pub/sub input topic\n![png](../img/dataflow/dataflow_1/3.png)\n\nBigquery output: Bigqueryæ¥æ”¶æ•°æ®çš„tableè¡¨,è¿™é‡Œæˆ‘ä»¬å»åˆ°æˆ‘ä»¬ç¬¬ä¸€æ­¥åˆ›å»ºçš„é¡µé¢,å¤åˆ¶è¡¨æ ¼æ•´ä½“è·¯å¾„\n\nTemporary location: è¿™é‡Œæ˜¯åˆ›å»ºæ•°æ®ä¸´æ—¶æ”¾çš„åœ°æ–¹,è¿™ä¸ªæ–‡ä»¶å¯ä»¥æ”¾åœ¨gs://my_bucket/tmpä¸­, æ³¨æ„,è¿™ä¸ªtmpæ–‡ä»¶å¤¹ä¸€å®šè¦å­˜åœ¨, è¿™ä¸ªtmpæ–‡ä»¶å¤¹å¯ä»¥ç»™å¤šä¸ªjobå­˜æ”¾\n\n4. ç„¶årun job\n   \n5. run jobæˆåŠŸå,æˆ‘ä»¬å…ˆå»åˆ°æˆ‘ä»¬çš„topicä¸­,ç„¶åé€‰æ‹©PUBLISH MESSAGE,\n\n![png](../img/dataflow/dataflow_1/4.png)\n\nç„¶åæˆ‘ä»¬åœ¨Message bodyä¸Šè¾“å…¥æˆ‘ä»¬éœ€è¦è¾“å…¥çš„æ•°æ®,æ•°æ®æ ¼å¼æ˜¯jsonæ ¼å¼{\"key\":\"value\",\"k\",\"v\"},ç„¶åpublish\n\n![png](../img/dataflow/dataflow_1/5.png)\n\n6. ç„¶åæˆ‘ä»¬å›åˆ°job,æŸ¥çœ‹job detail, æˆ‘ä»¬ç‚¹å‡»writesuccessfulRecords,å¯ä»¥çœ‹åˆ°å³è¾¹Elements added å‡ºç°äº†ä½ æ·»åŠ äº†å¤šå°‘æ¡,æ¯”å¦‚æˆ‘æ·»åŠ äº†ä¸¤æ¡,ä»–å°±æ˜¾ç¤º2æ¡\n\n![png](../img/dataflow/dataflow_1/6.png)\n\n7. æœ€åæˆ‘ä»¬å¯ä»¥å»bigqueryæŸ¥çœ‹\n   \n![png](../img/dataflow/dataflow_1/7.png)"
    },
    {
      "id": "/2020/4/11/dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2",
      "metadata": {
        "permalink": "/blog/2020/4/11/dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2.md",
        "source": "@site/blog/2020-4-11-dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2.md",
        "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨dataflowæ¥è¿è¡Œjob",
        "description": "png",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "dataproc",
            "permalink": "/blog/tags/dataproc"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "Spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "Hadoop",
            "permalink": "/blog/tags/hadoop"
          }
        ],
        "readingTime": 0.5,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataflow",
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨dataflowæ¥è¿è¡Œjob",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataproc",
            "GCP",
            "Spark",
            "Hadoop"
          ]
        },
        "prevItem": {
          "title": "dataflowç®€å•å…¥é—¨-æµæ•°æ®è¾“å…¥åˆ°bigquery",
          "permalink": "/blog/2020/4/11/dataflowæµæ•°æ®è¾“å…¥åˆ°bigquery"
        },
        "nextItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šåˆ›å»ºjupyterhub",
          "permalink": "/blog/2020/4/11/jupyterhub_GCP"
        }
      },
      "content": "```\ngcloud config set project query-11\n```\n# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ,å¹¶ä¸”æ¿€æ´»\n```python\npip3 install --upgrade virtualenv --user\npython3 -m virtualenv env\nsource env/bin/activate\n```\n<!--truncate-->\n# å®‰è£…sampleså’Œapache Beam SDK\n```python\npip3 install --quiet apache-beam[gcp]\n```\n# å»ºç«‹ä¸€ä¸ªcloud storage bucket\n```python\ngustil mb gs://query-11\n```\n\n# åœ¨dataflowå¼€å¯pipeline\n```python\npython3 -m \\\n    apache_beam.examples.wordcount \\\n    --project query-11 --runner \\\n    DataflowRunner --temp_location \\\n    gs://query-11/temp --output \\\n    gs://query-11/results/output \\\n    --job_name dataflow-intro\n```\n\n# æˆ‘ä»¬å¯ä»¥å»åˆ°dataflow,ç‚¹å‡»flow\n![png](../img/dataflow/1.png)\n![png](../img/dataflow/2.png)\n![png](../img/dataflow/3.png)"
    },
    {
      "id": "/2020/4/11/jupyterhub_GCP",
      "metadata": {
        "permalink": "/blog/2020/4/11/jupyterhub_GCP",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-jupyterhub_GCP.md",
        "source": "@site/blog/2020-4-11-jupyterhub_GCP.md",
        "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šåˆ›å»ºjupyterhub",
        "description": "è¿™ä¸ªæ˜¯å¸¸è§„æ“ä½œ,æ‰€ä»¥å°±ä¸è§£é‡Šäº†",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "git",
            "permalink": "/blog/tags/git"
          },
          {
            "label": "lfs",
            "permalink": "/blog/tags/lfs"
          },
          {
            "label": "github",
            "permalink": "/blog/tags/github"
          }
        ],
        "readingTime": 2.645,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "jupyterhub_GCP",
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šåˆ›å»ºjupyterhub",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "git",
            "lfs",
            "github"
          ]
        },
        "prevItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šä½¿ç”¨dataflowæ¥è¿è¡Œjob",
          "permalink": "/blog/2020/4/11/dataflowç”¨Apache Beam pythonè¿è¡Œ Apache Beam copy 2"
        },
        "nextItem": {
          "title": "dataflow sql",
          "permalink": "/blog/2020/4/11/ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š"
        }
      },
      "content": "è¿™ä¸ªæ˜¯å¸¸è§„æ“ä½œ,æ‰€ä»¥å°±ä¸è§£é‡Šäº†\n![png](../img/jupyterhub/left-menu-button.png)\n![png](../img/jupyterhub/vm-instances-menu.png)\n![png](../img/jupyterhub/enable-billing.png)\n![png](../img/jupyterhub/create-vm-first.png)\n## é€‰æ‹©region,\n## cpuè¦è¶…è¿‡1GB,\n## Boot diskå¯åŠ¨ç£ç›˜é€‰æ‹©ubuntu 18.04LTS\n<!--truncate-->\n![png](../img/jupyterhub/machine-type-basic.png)\n![png](../img/jupyterhub/boot-disk-button.png)\n![png](../img/jupyterhub/boot-disk-ubuntu.png)\n\n## åœ¨identity and API access é€‰æ‹©No service account\nè¿™æ ·åšå¯ä»¥é˜²æ­¢ä½ çš„jupyter hub users è¿›å…¥å…¶ä»–äº‘æœåŠ¡,æå‡å®‰å…¨\n![png](../img/jupyterhub/no-service-account.png)\n\n## é˜²ç«å¢™çš„é€‰æ‹©,å…è®¸httpå’Œhttps\n![png](../img/jupyterhub/firewall.png)\n\n## copy ä»¥ä¸‹é“¾æ¥åˆ°startup scriptä¸Šæ¥å®‰è£…jupyterhub\nè¿™é‡Œadmin-user-nameè¦æ›¿æ¢æˆä½ çš„ç”¨æˆ·å,ç”¨æ¥ç­‰ä¸‹çš„ç™»å½•,å¦‚\"flybird\"\n```python\n#!/bin/bash\ncurl https://raw.githubusercontent.com/jupyterhub/the-littlest-jupyterhub/master/bootstrap/bootstrap.py \\\n  | sudo python3 - \\\n    --admin <admin-user-name>\n```\n## åˆ›å»ºvmå®ä¾‹\n![png](../img/jupyterhub/create-vm-button.png)\n![png](../img/jupyterhub/vm-created.png)\n\n## å¤§æ¦‚20åˆ†é’Ÿå,jupyterhubå°±åˆ›å»ºæˆåŠŸ,æˆ‘ä»¬å¯ä»¥å¤åˆ¶external ipåˆ°æµè§ˆå™¨æŸ¥çœ‹\n!! æ³¨æ„, æ²¡åˆ›å»ºæˆåŠŸæˆ, æµè§ˆå™¨ä¼šæç¤ºdiaed tcp, conection refused, æ‰€ä»¥ä¸ç”¨ç€æ€¥\n![png](../img/jupyterhub/first-login.png)\n\n## ç”¨ä¹‹å‰startup scriptå†™çš„ç”¨æˆ·åç™»å½•\n![png](../img/jupyterhub/1.png)\n\n## é€‰æ‹©admin,å¯ä»¥åˆ›å»ºç”¨æˆ·\n![png](../img/jupyterhub/2.png)\n![png](../img/jupyterhub/3.png)\n![png](../img/jupyterhub/4.png)\n## å¼€å¯server,å¼€å¯å,ç”¨æˆ·å°±å¯ä»¥ç™»å½•äº†\n![png](../img/jupyterhub/5.png)\n\n## è¿›å…¥ç»ˆç«¯,åˆ†åˆ«å®‰è£…conda/pipå®‰è£…åŒ…ç»™æ‰€æœ‰ç”¨æˆ·\nç®¡ç†å‘˜adminèƒ½å¤Ÿä½¿ç”¨å‘½ä»¤ sudo -E å¯¹æ•´ä¸ªç¯å¢ƒå®‰è£…å·¥å…·åŒ…\n```python\nsudo -E conda install -c conda-forge gdal\n```\n![png](../img/jupyterhub/6.png)\n![png](../img/jupyterhub/7.png)\n![png](../img/jupyterhub/8.png)\n![png](../img/jupyterhub/9.png)\n```python\nsudo -E pip install there\n```\n![png](../img/jupyterhub/10.png)\n\n## æµ‹è¯•åˆ›å»ºæ–‡ä»¶\n![png](../img/jupyterhub/11.png)\n\n## æµ‹è¯•æ–°ç”¨æˆ·ç™»å½•\n![png](../img/jupyterhub/12.png)\n![png](../img/jupyterhub/13.png)\n\n# æˆåŠŸå•¦!!!\n\n## å¥½å•¦,ç°åœ¨è¦ä½ æœ‰äº†ç¡¬æ ¸äº†,ä½†æ˜¯è¦æœ‰è½¯ä¸œè¥¿å•¦,packageè¦å®‰è£…,å¯¹ä¸å¯¹å•Š\næ¯”å¦‚å®‰è£… [conda, pip æˆ–è€…apt package](http://tljh.jupyter.org/en/latest/install/google.html)å˜›\n\n## å»åˆ°jupyter terminal,æ‰€æœ‰packageéƒ½åœ¨jupyter terminalå®‰è£…å“¦\n```\nsudo -E conda install -c conda-forge gdal\nsudo -E pip install there\npip install jupyter_contrib_nbextensions --user #ç”¨åšjupyterè‡ªåŠ¨æç¤º\njupyter contrib nbextension install --user\npip install --user jupyter_nbextensions_configurator\njupyter nbextensions_configurator enable --user\n```\n[jupyter ä»£ç æç¤ºè‡ªåŠ¨è¡¥å…¨å‚è€ƒé“¾æ¥](https://blog.csdn.net/mengfei2656/article/details/89287140)\nè¿™é‡Œè¦æ•²é»‘æ¿å•¦,æƒ³å®‰è£…æ›´å¤špip , apt packageså’Œæƒé™è¿›å…¥ä¸å†jupyter Hubç”¨æˆ·ç¯å¢ƒçš„è®¾ç½®ç­‰,è¯·çœ‹[å®˜ç½‘æ–‡æ¡£](http://tljh.jupyter.org/en/latest/howto/env/user-environment.html#howto-env-user-environment)\n\nå¼•ç”¨å®˜ç½‘ä¸€æ®µæ–‡å­—:\nAccessing user environment outside JupyterHub\nWe add /opt/tljh/user/bin to the $PATH environment variable for all JupyterHub users, so everything installed in the user environment is available to them automatically. If you are using ssh to access your server instead, you can get access to the same environment with:\n```\nexport PATH=/opt/tljh/user/bin:${PATH}\n```"
    },
    {
      "id": "/2020/4/11/ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š",
      "metadata": {
        "permalink": "/blog/2020/4/11/ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š.md",
        "source": "@site/blog/2020-4-11-ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š.md",
        "title": "dataflow sql",
        "description": "æ€»ä½“æµç¨‹",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "dataflow",
            "permalink": "/blog/tags/dataflow"
          },
          {
            "label": "GCP",
            "permalink": "/blog/tags/gcp"
          },
          {
            "label": "apache beam",
            "permalink": "/blog/tags/apache-beam"
          },
          {
            "label": "sql",
            "permalink": "/blog/tags/sql"
          }
        ],
        "readingTime": 4.06,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dataflow3",
          "title": "dataflow sql",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "dataflow",
            "GCP",
            "apache beam",
            "sql"
          ]
        },
        "prevItem": {
          "title": "5åˆ†é’Ÿåœ¨è°·æ­Œäº‘ä¸Šåˆ›å»ºjupyterhub",
          "permalink": "/blog/2020/4/11/jupyterhub_GCP"
        },
        "nextItem": {
          "title": "macå®‰è£…spark+jupyter+annocade+pycharmé…ç½®",
          "permalink": "/blog/2020/4/11/å®‰è£…spark"
        }
      },
      "content": "[æ€»ä½“æµç¨‹](https://www.youtube.com/watch?v=GBNBnobxsiI)\n# é€‰æ‹©é¡¹ç›® \n```\ngcloud config set project query-11\n```\n# å¯ç”¨API\nå¯ç”¨ Cloud Dataflow, Compute Engine, Stackdriver Logging, Cloud Storage, Cloud Storage JSON, BigQuery, Cloud Pub/Sub, and Cloud Resource Manager APIã€‚\n\nå…·ä½“æµç¨‹å¯æŸ¥çœ‹[Dataflow SQL ç•Œé¢](https://cloud.google.com/dataflow/docs/guides/sql/dataflow-sql-ui-walkthrough)\n\n<!--truncate-->\n# åˆ›å»ºPub/Subä¸»é¢˜å’Œå‘å¸ƒè„šæ­¥\n\n(1)\n```\ngcloud pubsub topics create transactions\n```\n\n(2)\nåˆ›å»ºpythonæ–‡ä»¶, transactions_injector.py,å†…å®¹ä¸ºä¸€ä¸‹\n```\n#!/usr/bin/env python\n\nimport datetime, json, os, random, time\n\n# Set the `project` variable to a Google Cloud project ID.\nproject = 'query-11'\n\nFIRST_NAMES = ['Monet', 'Julia', 'Angelique', 'Stephane', 'Allan', 'Ulrike', 'Vella', 'Melia',\n'Noel', 'Terrence', 'Leigh', 'Rubin', 'Tanja', 'Shirlene', 'Deidre', 'Dorthy', 'Leighann',\n'Mamie', 'Gabriella', 'Tanika', 'Kennith', 'Merilyn', 'Tonda', 'Adolfo', 'Von', 'Agnus',\n'Kieth', 'Lisette', 'Hui', 'Lilliana',]\nCITIES = ['Washington', 'Springfield', 'Franklin', 'Greenville', 'Bristol', 'Fairview', 'Salem',\n'Madison', 'Georgetown', 'Arlington', 'Ashland',]\nSTATES = ['MO','SC','IN','CA','IA','DE','ID','AK','NE','VA','PR','IL','ND','OK','VT','DC','CO','MS',\n'CT','ME','MN','NV','HI','MT','PA','SD','WA','NJ','NC','WV','AL','AR','FL','NM','KY','GA','MA',\n'KS','VI','MI','UT','AZ','WI','RI','NY','TN','OH','TX','AS','MD','OR','MP','LA','WY','GU','NH']\nPRODUCTS = ['Product 2', 'Product 2 XL', 'Product 3', 'Product 3 XL', 'Product 4', 'Product 4 XL', 'Product 5',\n'Product 5 XL',]\n\nwhile True:\n    first_name, last_name = random.sample(FIRST_NAMES, 2)\n    data = {\n    'tr_time_str': datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"),\n    'first_name': first_name,\n    'last_name': last_name,\n    'city': random.choice(CITIES),\n    'state':random.choice(STATES),\n    'product': random.choice(PRODUCTS),\n    'amount': float(random.randrange(50000, 70000)) / 100,\n    }\n    message = json.dumps(data)\n    command = \"gcloud --project={} pubsub topics publish transactions --message='{}'\".format(project, message)\n    print(command)\n    os.system(command)\n    time.sleep(random.randrange(1, 5))\n```\n## pythonè„šæœ¬ä¸‹çš„PubSubçš„ä¸»è¦å‘½ä»¤æœ‰:\n```\ngcloud pubsub topics create transactions åˆ›å»º topics\ngcloud --project=project_id pubsub topics publish transactions(topicåå­—) --message=(jsonæ ¼å¼çš„data,æœ€åç”¨json.dump(data))\ncommand = \"gcloud --project={} pubsub topics publish transactions --message='{}'\".format(project, message)\nos.system(command)\n```\n\n\n\n# åˆ›å»ºæ•°æ®é›†å’Œè¡¨\n```\nbq mk dataflow_sql_dataset\n```\n# åˆ›å»ºä¸€ä¸ªus_state_salesregions.csvæ–‡ä»¶,æŠŠä»¥ä¸‹æ•°æ®å¤åˆ¶åˆ°csvæ–‡ä»¶\n```\nstate_id,state_code,state_name,sales_region\n1,MO,Missouri,Region_1\n2,SC,South Carolina,Region_1\n3,IN,Indiana,Region_1\n6,DE,Delaware,Region_2\n15,VT,Vermont,Region_2\n16,DC,District of Columbia,Region_2\n19,CT,Connecticut,Region_2\n20,ME,Maine,Region_2\n35,PA,Pennsylvania,Region_2\n38,NJ,New Jersey,Region_2\n47,MA,Massachusetts,Region_2\n54,RI,Rhode Island,Region_2\n55,NY,New York,Region_2\n60,MD,Maryland,Region_2\n66,NH,New Hampshire,Region_2\n4,CA,California,Region_3\n8,AK,Alaska,Region_3\n37,WA,Washington,Region_3\n61,OR,Oregon,Region_3\n33,HI,Hawaii,Region_4\n59,AS,American Samoa,Region_4\n65,GU,Guam,Region_4\n5,IA,Iowa,Region_5\n32,NV,Nevada,Region_5\n11,PR,Puerto Rico,Region_6\n17,CO,Colorado,Region_6\n18,MS,Mississippi,Region_6\n41,AL,Alabama,Region_6\n42,AR,Arkansas,Region_6\n43,FL,Florida,Region_6\n44,NM,New Mexico,Region_6\n46,GA,Georgia,Region_6\n48,KS,Kansas,Region_6\n52,AZ,Arizona,Region_6\n56,TN,Tennessee,Region_6\n58,TX,Texas,Region_6\n63,LA,Louisiana,Region_6\n7,ID,Idaho,Region_7\n12,IL,Illinois,Region_7\n13,ND,North Dakota,Region_7\n31,MN,Minnesota,Region_7\n34,MT,Montana,Region_7\n36,SD,South Dakota,Region_7\n50,MI,Michigan,Region_7\n51,UT,Utah,Region_7\n64,WY,Wyoming,Region_7\n9,NE,Nebraska,Region_8\n10,VA,Virginia,Region_8\n14,OK,Oklahoma,Region_8\n39,NC,North Carolina,Region_8\n40,WV,West Virginia,Region_8\n45,KY,Kentucky,Region_8\n53,WI,Wisconsin,Region_8\n57,OH,Ohio,Region_8\n49,VI,United States Virgin Islands,Region_9\n62,MP,Commonwealth of the Northern Mariana Islands,Region_9\n```\nåˆ›å»ºè¡¨\n```\nbq load --autodetect --source_format=CSV dataflow_sql_dataset.us_state_salesregions us_state_salesregions.csv\n```\n\n# æŸ¥æ‰¾ Pub/Sub æ¥æº\né¦–å…ˆæŠŠdatasetè®¾ç½®æˆGloud dataflow engine\n\nç„¶åå†ç‚¹å‡»æ·»åŠ æ•°æ®ä¸‹æ‹‰åˆ—è¡¨ï¼Œç„¶åé€‰æ‹© Cloud Dataflow æ¥æº\n\nåœ¨å³ä¾§æ‰“å¼€çš„æ·»åŠ  Cloud Dataflow æ¥æºé¢æ¿ä¸­ï¼Œé€‰æ‹© Pub/Sub ä¸»é¢˜ã€‚åœ¨æœç´¢æ¡†ä¸­ï¼Œæœç´¢ transactionsã€‚ é€‰æ‹©ç›¸åº”ä¸»é¢˜ï¼Œç„¶åç‚¹å‡»æ·»åŠ ã€‚\n\nåœ¨Cloud dataflow sourcesçš„ cloud pub/sub topicsä¸‹é€‰æ‹©transactions >> å»åˆ°Schema >> edit schema,\nç„¶åè¾“å…¥ä¸€ä¸‹schemaæ ¼å¼\n```\n[\n  {\n      \"description\": \"Pub/Sub event timestamp\",\n      \"name\": \"event_timestamp\",\n      \"mode\": \"REQUIRED\",\n      \"type\": \"TIMESTAMP\"\n  },\n  {\n      \"description\": \"Transaction time string\",\n      \"name\": \"tr_time_str\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"First name\",\n      \"name\": \"first_name\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"Last name\",\n      \"name\": \"last_name\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"City\",\n      \"name\": \"city\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"State\",\n      \"name\": \"state\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"Product\",\n      \"name\": \"product\",\n      \"type\": \"STRING\"\n  },\n  {\n      \"description\": \"Amount of transaction\",\n      \"name\": \"amount\",\n      \"type\": \"FLOAT64\"\n  }\n]\n```\n# è¿è¡Œpythonè„šæœ¬,è¿™æ ·æˆ‘ä»¬å°±å¼€å§‹ä¸åœå‘é€æ•°æ®\n```\npython transactions_injector.py\n```\n\n# åˆ›å»ºSQLæŸ¥è¯¢\nåˆ›å»ºSQLæŸ¥è¯¢æ¥è¿è¡ŒDataflow jobs\næˆ‘ä»¬è¿™é‡Œä¾‹å­æ˜¯æ·»åŠ ä¸€ä¸ªå¤„ç†PubSubå‘é€çš„å­—æ®µå†æ·»åŠ ä¸€ä¸ªå­—æ®µ\n```\nSELECT tr.*, sr.sales_region\nFROM pubsub.topic.`project-id`.transactions as tr\n  INNER JOIN bigquery.table.`project-id`.dataflow_sql_dataset.us_state_salesregions AS sr\n  ON tr.state = sr.state_code\n```\n\n# æˆ‘ä»¬è®¾ç½®å¥½æŸ¥è¯¢åå°±å¯ä»¥å¼€å§‹åˆ›å»ºjobäº†\n\n1 åœ¨Query editorä¸‹é¢,é€‰æ‹©Create Dataflow job (è¿™ä¸ªæŒ‰é’®åªæœ‰åœ¨è®¾ç½®å¥½queryåæ‰èƒ½ç”Ÿæ•ˆ)\n\n2 ç‚¹å‡»è¿›å»å,æˆ‘ä»¬å¡«å†™job name, Primary ouput(é€‰æ‹©Bigquery), Project, Dataset idå’Œå¡«å†™table name (è‡ªå·±å‘½å)\n\n3 write dispositionä¸­ é€‰æ‹©write if empty\n\n4 ç‚¹å‡»create\n\n# è¿™æ ·jobå°±å¼€å¯äº†\nå¤§æ¦‚5åˆ†é’Ÿjobåº”è¯¥å·®ä¸å¤šå¼€å¯äº†,æˆ‘ä»¬å¯ä»¥å»dataflowæŸ¥çœ‹jobçš„è¿è¡Œæƒ…å†µ,åŒæ—¶æˆ‘ä»¬ä¹Ÿå¯ä»¥å»bigqueryæŸ¥çœ‹æˆ‘ä»¬çš„tableæ˜¯å¦åˆ›ç«‹æˆåŠŸå’Œæ•°æ®æœ‰æ²¡æœ‰æ›´æ–°"
    },
    {
      "id": "/2020/4/11/å®‰è£…spark",
      "metadata": {
        "permalink": "/blog/2020/4/11/å®‰è£…spark",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-11-å®‰è£…spark.md",
        "source": "@site/blog/2020-4-11-å®‰è£…spark.md",
        "title": "macå®‰è£…spark+jupyter+annocade+pycharmé…ç½®",
        "description": "Sparkçš„å®‰è£…å¤§å¤šæ¯”è¾ƒéº»çƒ¦ï¼Œè€ŒMacå®‰è£…Sparkéå¸¸ç®€å•ï¼Œæœ¬æ–‡åˆ†ä¸‰éƒ¨åˆ†å†…å®¹ã€‚",
        "date": "2020-04-11T00:00:00.000Z",
        "formattedDate": "April 11, 2020",
        "tags": [
          {
            "label": "spark",
            "permalink": "/blog/tags/spark"
          },
          {
            "label": "jupyter",
            "permalink": "/blog/tags/jupyter"
          },
          {
            "label": "pycharm",
            "permalink": "/blog/tags/pycharm"
          },
          {
            "label": "java",
            "permalink": "/blog/tags/java"
          }
        ],
        "readingTime": 4.925,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "spark1",
          "title": "macå®‰è£…spark+jupyter+annocade+pycharmé…ç½®",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "spark",
            "jupyter",
            "pycharm",
            "java"
          ]
        },
        "prevItem": {
          "title": "dataflow sql",
          "permalink": "/blog/2020/4/11/ä½¿ç”¨Dataflow SQLç•Œé¢è¿è¡ŒDataflowä½œä¸š"
        },
        "nextItem": {
          "title": "tf_servingéƒ¨ç½²+é‡åˆ°çš„é—®é¢˜",
          "permalink": "/blog/2020/4/05/tf_serving"
        }
      },
      "content": "Sparkçš„å®‰è£…å¤§å¤šæ¯”è¾ƒéº»çƒ¦ï¼Œè€ŒMacå®‰è£…Sparkéå¸¸ç®€å•ï¼Œæœ¬æ–‡åˆ†ä¸‰éƒ¨åˆ†å†…å®¹ã€‚\n1. å®‰è£…JDK\n2. å®‰è£…Spark\n3. ç®€å•æµ‹è¯•\n<!--truncate-->\nè¿™é‡Œå…·ä½“å¯ä»¥å‚è€ƒé“¾æ¥\n\n[å®‰è£…JDK](https://blog.csdn.net/a595130080/article/details/53350076?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)\n\næˆ‘çš„uç›˜æœ‰ JDK + annocada + spark,æ‰€ä»¥ç›´æ¥passä¸‹è½½å®‰è£…æ­¥éª¤å•¦(å¦‚å›¾æ˜¾ç¤º),åŒå‡»ç‚¹å‡»JDK,Anaconda3å®‰è£…å°±å¯ä»¥äº†,spark-3.0.0-preview2-bin-hadoop2.7å°±æ˜¯spark,ç›´æ¥è·³åˆ°æµ‹è¯•é˜¶æ®µ\n\n![png](../img/spark/1.png)\n\næ‰“å¼€ç»ˆç«¯,åˆ‡æ¢åˆ°sparkçš„è·¯å¾„(spark-3.0.0-preview2-bin-hadoop2.7):\nç„¶åè¾“å…¥\n```\n./sbin/start-master.sh\n```\nç„¶åå†(http://localhost:8080),å°±å¯ä»¥çœ‹åˆ°æ•ˆæœ:\n![png](../img/spark/2.png)\n\nè¡¨ç¤ºå®‰è£…æˆåŠŸäº†\n\nç„¶ååœ¨ä¸€ä¸ªæ–°çš„ç»ˆç«¯,è¿›å…¥åŒæ ·çš„sparkè·¯å¾„,ç„¶åè¾“å…¥\n```\n./bin/spark-class org.apache.spark.deploy.worker.Worker spark://IP:PORT\n```\nè¿™é‡Œçš„spark://IP:PORTä¿®æ”¹æˆå›¾ç‰‡ä¸Šçš„URL,å¦‚: ./bin/spark-class org.apache.spark.deploy.worker.Worker\nspark://chenbindeMacBook-Pro.local:7077\n\nè¿™æ ·æˆ‘ä»¬å°±å¼€å¯äº†ä¸€ä¸ªæ–°çš„worker\n\nç„¶åæˆ‘ä»¬åœ¨ç»ˆç«¯command+cå°±å¯ä»¥å…³æ‰worker\n\næœ€åæ˜¯å…³æ‰ä¸»æœº,åœ¨ç»ˆç«¯è¾“å…¥\n```\n./sbin/stop-master.sh\n```\nè¿™ä¸ªæ˜¯ç®€å•ç‰ˆçš„\n\n# äºŒ Anocada+jupyter+spark\n\næˆ‘ä»¬å®‰è£…å¥½spark,jdkå,æˆ‘ä»¬è¿˜è¦å®‰è£…Anocada,æˆ‘çš„æ–‡ä»¶é‡Œé¢ä¹Ÿæœ‰,ç›´æ¥åŒå‡»å®‰è£…å°±å¯ä»¥äº†\n\n1 æˆ‘ä»¬åˆ‡æ¢åˆ°ä¸»ç›®å½•\n\n2 #æ‰“å¼€bash_profile\n\n3 è®¾ç½®anacondaå’Œsparkè·¯å¾„, æ³¨æ„!!!è¿™é‡Œspark_pathè·¯å¾„æ˜¯sparkçš„å…·ä½“è·¯å¾„\n\n4 ä½¿å‘½ä»¤ç«‹åˆ»ç”Ÿæ•ˆ\n\n```\ncd ~\nopen .bash_profile  \nexport PATH=\"/Applications/anaconda3/bin:$PATH\"\nexport SPARK_PATH=\"/Users/flybird/Desktop/spark/spark-3.0.0-preview2-bin-hadoop2.7\"\nexport PATH=$SPARK_PATH/bin:$PATH\nsource .bash_profile\n```\n\n## å®‰è£…pyspark,è¿™ä¸€æ­¥å¾ˆé‡è¦å“¦\n```\nsudo pip install pyspark -i https://pypi.douban.com/simple/\n```\n\n## åœ¨Jupyter Notebooké‡Œè¿è¡ŒPySpark, é…ç½®PySpark driver\nè¯¦ç»†æ•™ç¨‹å¯ä»¥çœ‹[è¿™é‡Œurlé“¾æ¥](https://blog.csdn.net/a1272899331/article/details/90081945?utm_medium=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase&depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromMachineLearnPai2-1.nonecase)\né…ç½®PySpark driverï¼Œå½“è¿è¡Œpysparkå‘½ä»¤å°±ç›´æ¥è‡ªåŠ¨æ‰“å¼€ä¸€ä¸ªJupyter Notebookï¼Œæ­¤æ—¶shellç«¯ä¸ä¼šæ‰“å¼€,å…·ä½“é…ç½®æ­¥éª¤:\n```\nsudo vim ~/.bashrc åœ¨è¿™ä¸ªæ–‡ä»¶æ·»åŠ é…ç½®PySpark driverçš„ç¯å¢ƒå˜é‡\nexport PYSPARK_DRIVER_PYTHON=jupyter\nexport PYSPARK_DRIVER_PYTHON_OPTS='notebook'\nsource ~/.bashrc\n```\nç„¶åé‡å¯terminal\n\n## å¯åŠ¨jupyter notebook3\n\nå¯åŠ¨å,æˆ‘ä»¬åœ¨jupyter notebookä¸Šåˆ›å»ºpythonæ–‡ä»¶\nç„¶åè¾“å…¥ä»¥ä¸‹å‘½ä»¤\n![png](../img/spark/3.png)\n```\nimport os\nimport sys\nspark_path = os.environ.get('SPARK_PATH', None)\nsys.path.insert(0, os.path.join(spark_path, 'python/lib/py4j-0.10.8.1-src.zip'))\nexec(open(os.path.join(spark_path, 'python/pyspark/shell.py')).read())\n```\n![png](../img/spark/4.png)\n\npy4j-0.10.8.1-src.zipéœ€è¦æ ¹æ®å®é™…åç§°ä¿®æ”¹,å¦‚æœæ˜¯ç”¨æˆ‘çš„åŒ…,å°±ä¸ç”¨æ”¹,å¦‚æœæ˜¯ç”¨sparkå®˜ç½‘ä¸‹è½½çš„,å°±éœ€è¦å¯¹åº”çš„zipæ–‡ä»¶åå­—\n\nè¾“å…¥å‘½ä»¤åçš„æ•ˆæœå¦‚ä¸‹, ç„¶åè¾“å…¥sc,æŸ¥çœ‹ç›¸åº”çš„è¾“å‡º:\n![png](../img/spark/7.png)\n\nå¯ä»¥ç”¨commandæ¥è¯•è¯•ä¸€ä¸‹å‘½ä»¤\n```\nimport pyspark\n \nimport random\nsc = pyspark.SparkContext(appName=\"Pi\")\nnum_samples = 100000000\ndef inside(p):     \n  x, y = random.random(), random.random()\n  return x*x + y*y < 1\ncount = sc.parallelize(range(0, num_samples)).filter(inside).count()\npi = 4 * count / num_samples\nprint(pi)\nsc.stop()\n```\n\nå¦‚æœå‘ç°å‡ºç°\n```\nUnsupported class file major version 57\n```\nå°±æ˜¯jdkç‰ˆæœ¬é—®é¢˜,å»åˆ°ç»ˆç«¯\n```\njava -version #æŸ¥çœ‹ç‰ˆæœ¬ java version \"13.0.2\" 2020-01-14\ncd /Library/Java/JavaVirtualMachines\nls\nsudo rm -rf jdk-13.0.2.jdk #åˆ é™¤java version\n```\nå®‰è£…JDKï¼ˆjdk-8u251ï¼‰ï¼Œ[ä¸‹è½½jdk-8u251-macosx-x64.dmg](https://www.oracle.com/java/technologies/javase-jdk8-downloads.html)\n\nç„¶åå†å›åˆ°jupyter notebook,é‡æ–°è¾“å…¥å‘½ä»¤,æŸ¥çœ‹æ˜¯å¦æˆåŠŸ\n![png](../img/spark/8.png)\n\n\n# Pycharmè®¾ç½®å•¦\nPycharmè¿™é‡Œå…·ä½“å¯ä»¥[å‚è€ƒä¸€ä¸‹æ–‡ç« ](https://www.jianshu.com/p/22426c490066)\né…ç½®åŸå› ï¼šåœ¨pysparkå‘½ä»¤è¡Œ ç»ƒä¹ æ¯”è¾ƒéº»çƒ¦ï¼Œä¸èƒ½è‡ªåŠ¨è¡¥å…¨ï¼Œæµªè´¹æ—¶é—´ã€‚Jupyter notebook æ˜¯æœ€ç†æƒ³çš„ï¼Œä½†æ˜¯è¿˜æ²¡é…ç½®æˆåŠŸã€‚\n\n1.æ‰“å¼€pycharmï¼Œæ–°å»ºä¸€ä¸ªå·¥ç¨‹\n\n2.ç‚¹å‡» run --Edit Configuration..\n![png](../img/spark/9.png)\n\n3.é…ç½®\n\n3.1 æ–°å»º Python ï¼Œèµ·ä¸ªå\n\n3.2 é…ç½®scriptï¼ŒæŒ‡å‘ä½ è¦å¼•ç”¨ spark çš„é‚£ä¸ªæ–‡ä»¶\n\n3.3 Enviroment variablesï¼š\n![png](../img/spark/10.png)\nå¯ä»¥ç›´æ¥åœ¨Enviroment variablesä¸Šè¾“å…¥:\nPYTHONUNBUFFERED=1;SPARK_HOME=/Users/flybird/Desktop/spark/spark-3.0.0-preview2-bin-hadoop2.7;PYTHONPATH=/Users/flybird/Desktop/spark/spark-3.0.0-preview2-bin-hadoop2.7/python;PYSPARK_PYTHON=/Users/flybird/opt/anaconda3/bin/python3\n\nPYSPARK_PYTHON; æŒ‡å‘ ä½ æœ¬æœº çš„ python è·¯å¾„, (å¯ä»¥å»ç»ˆç«¯è¾“å…¥which python æ¥æ‰¾åˆ°è·¯å¾„)\n\n\nSPARK_HOME ï¼šæŒ‡å‘ spark å®‰è£…ç›®å½•(å°±æ˜¯spark-3.0.0-preview2-bin-hadoop2.7çš„ç»å¯¹è·¯å¾„)\n\nPYTHONPATHï¼šæŒ‡å‘ spark å®‰è£…ç›®å½•çš„ Python æ–‡ä»¶å¤¹(å°±æ˜¯spark-3.0.0-preview2-bin-hadoop2.7çš„pythonæ–‡ä»¶å¤¹çš„ç»å¯¹è·¯å¾„)\n\n4 å®‰è£… py4j\nsudo pip3 install py4j\n\n5.çœ‹åˆ°ç½‘ä¸Šå¾ˆå¤šæ•™ç¨‹ï¼Œä¸€èˆ¬éƒ½åªæ‰§è¡Œåˆ°ç¬¬å››æ­¥å³å¯ï¼Œä½†æ˜¯æˆ‘ä»ç„¶æ— æ³•å¯¼å…¥ pyspark åŒ…ï¼Œè¿˜éœ€è¦ä¸‹é¢çš„æ­¥éª¤ï¼š\n\né€‰æ‹© File--->setting--->ä½ çš„project--->project structure\nå³ä¸Šè§’Add content rootæ·»åŠ ï¼špy4j-some-version.zipå’Œpyspark.zipçš„è·¯å¾„ï¼ˆè¿™ä¸¤ä¸ªæ–‡ä»¶éƒ½åœ¨Sparkä¸­çš„pythonæ–‡ä»¶å¤¹ä¸‹ï¼‰\n![png](../img/spark/10.png)\n\nè¿™é‡Œæˆ‘ä»¬å¯ä»¥å»åˆ°sparkä¸­çš„pythonæ–‡ä»¶å¤¹(spark-3.0.0-preview2-bin-hadoop2.7/python),ç„¶åæŸ¥æ‰¾zip!,ç„¶åçœ‹åˆ°é€‰æ‹©æ·»åŠ å°±å¯ä»¥äº†\n\n6 æµ‹è¯•ç¨‹åº\nç”¨ä¹‹å‰çš„ä»£ç å†æ¬¡æµ‹è¯•,ä¸€æ ·å¯ä»¥äº†"
    },
    {
      "id": "/2020/4/05/tf_serving",
      "metadata": {
        "permalink": "/blog/2020/4/05/tf_serving",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-05-tf_serving.md",
        "source": "@site/blog/2020-4-05-tf_serving.md",
        "title": "tf_servingéƒ¨ç½²+é‡åˆ°çš„é—®é¢˜",
        "description": "å‚è€ƒè¿‡çš„åšå®¢",
        "date": "2020-04-05T00:00:00.000Z",
        "formattedDate": "April 5, 2020",
        "tags": [
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          },
          {
            "label": "tf_serving",
            "permalink": "/blog/tags/tf-serving"
          },
          {
            "label": "model",
            "permalink": "/blog/tags/model"
          }
        ],
        "readingTime": 11.09,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "tf_serving",
          "title": "tf_servingéƒ¨ç½²+é‡åˆ°çš„é—®é¢˜",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "docker",
            "tf_serving",
            "model"
          ]
        },
        "prevItem": {
          "title": "macå®‰è£…spark+jupyter+annocade+pycharmé…ç½®",
          "permalink": "/blog/2020/4/11/å®‰è£…spark"
        },
        "nextItem": {
          "title": "ä½¿ç”¨webscrapperçˆ¬å–ä¿¡æ¯",
          "permalink": "/blog/2020/4/04/webscrapper"
        }
      },
      "content": "[å‚è€ƒè¿‡çš„åšå®¢](https://blog.csdn.net/u011734144/article/details/82107610?depth_1-utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1&utm_source=distribute.pc_relevant.none-task-blog-BlogCommendFromBaidu-1)\n\n[Macä¸‹dockerä¿å­˜è·¯å¾„](https://www.cnblogs.com/zhzhlong/p/9465571.html)\n\n<!--truncate-->\n# tf_serving éƒ¨ç½²\n## Step1: æ¨¡å‹æ„å»ºä¸è®­ç»ƒ\næˆ‘ä»¬é€šè¿‡æ¨¡å‹æ„å»ºä¸è®­ç»ƒå,æˆ‘ä»¬å¯ä»¥å¾—åˆ°æ¨¡å‹(cnn_model.h5)\n\n### æ¨¡å‹ç»“æ„æ‰“å°\n\n```python\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)\n```\n\n![png](../img/tf_serving/output_11_0.png)\n\n\n\n## Step2: æ¨¡å‹çš„å¯¼å‡ºä¸æ£€æŸ¥\n\n### æ¨¡å‹å¯¼å‡º\n\n\n```python\nimport tensorflow as tf\nimport shutil \n\nmodel = tf.keras.models.load_model('./cnn_model.h5')\n\n#  æŒ‡å®šè·¯å¾„\nif os.path.exists('./Models/CNN/1'):\n     shutil.rmtree('./Models/CNN/1')\nexport_path = './Models/CNN/1'\n\n# å¯¼å‡ºtensorflowæ¨¡å‹ä»¥ä¾¿éƒ¨ç½²\ntf.saved_model.save(model,export_path)\n```\n\n![png](../img/tf_serving/5.png) \n\n\n\n### æ¨¡å‹çš„éƒ¨ç½²å‰æ£€æŸ¥ä¸æµ‹è¯•\ntensorflowå®˜æ–¹æä¾›äº†éå¸¸å¥½çš„ä¸€äº›å·¥å…·ç»™å¤§å®¶ï¼Œæ¯”å¦‚åœ¨å®é™…éƒ¨ç½²æœåŠ¡ä¹‹å‰ï¼Œæˆ‘æƒ³å¼ºè°ƒä¸€ä¸‹TensorFlowçš„SavedModelå‘½ä»¤è¡Œå·¥å…·ï¼Œè¿™å¯¹äºå¿«é€Ÿæ£€æŸ¥æˆ‘ä»¬æ¨¡å‹çš„è¾“å…¥å’Œè¾“å‡ºè§„èŒƒå¾ˆæœ‰ç”¨ï¼Œæˆ‘ä»¬ç”¨ä¸‹é¢çš„å‘½ä»¤æ£€æŸ¥ä¸€ä¸‹æˆ‘ä»¬çš„CNNæ¨¡å‹ï¼š\n```shell\n$ saved_model_cli show --dir ./Models/CNN/1 --all\n```\n<!--truncate-->\næˆ‘ä»¬ä¼šçœ‹åˆ°ä»¥ä¸‹è¾“å‡ºä¿¡æ¯:\n```shell\nMetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n\nsignature_def['__saved_model_init_op']:\n  The given SavedModel SignatureDef contains the following input(s):\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['__saved_model_init_op'] tensor_info:\n        dtype: DT_INVALID\n        shape: unknown_rank\n        name: NoOp\n  Method name is: \n\nsignature_def['serving_default']:\n  The given SavedModel SignatureDef contains the following input(s):\n    inputs['input_1'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 100)\n        name: serving_default_input_1:0\n  The given SavedModel SignatureDef contains the following output(s):\n    outputs['dense'] tensor_info:\n        dtype: DT_FLOAT\n        shape: (-1, 5)\n        name: StatefulPartitionedCall:0\n  Method name is: tensorflow/serving/predict\n```\n\næˆ‘ä»¬è¿˜å¯ä»¥éšæœºé€ä¸€äº›ç¬¦åˆè¾“å…¥ç»´åº¦è¦æ±‚çš„æ•°æ®ç»™æ¨¡å‹ï¼Œçœ‹çœ‹è¾“å‡ºç»“æœçš„å½¢æ€ã€‚\n```shell\n$ saved_model_cli run --dir ./Models/CNN/1 --tag_set serve --signature_def serving_default --input_exp 'input_1=np.random.rand(1,100)'\n```\n<!--truncate-->\nå¤§å®¶å°†çœ‹åˆ°ä»¥ä¸‹è¾“å‡ºï¼š\n```shell\nserve --signature_def serving_default --input_exp 'input_1=np.random.rand(1,100)'\n2019-06-13 16:33:46.095550: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\nWARNING: Logging before flag parsing goes to stderr.\nW0613 16:33:46.095993 140736529130432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/tools/saved_model_cli.py:339: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\nInstructions for updating:\nThis function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\nW0613 16:33:46.141968 140736529130432 deprecation.py:323] From /usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse standard file APIs to check for files with this prefix.\nResult for output key dense:\n[[0.14112209 0.22561029 0.2605021  0.22022876 0.15253687]]\n```\n\nè¿™è¡¨æ˜æˆ‘ä»¬éšæœºè¾“å…¥é•¿åº¦ä¸º100çš„æ–‡æœ¬åºåˆ—(è¯id)ç»™æ¨¡å‹ï¼Œå¾—åˆ°äº†é•¿åº¦ä¸º5çš„æ¦‚ç‡å‘é‡ï¼Œåˆ†åˆ«è¡¨ç¤º5ä¸ªç±»åˆ«çš„æ¦‚ç‡ã€‚åˆ°æ­¤ä¸ºæ­¢ï¼Œæˆ‘ä»¬çš„æ¨¡å‹ä¸€åˆ‡æ­£å¸¸ã€‚\n\n# æ¨¡å‹éƒ¨ç½²ä¸æœåŠ¡æ„å»ºä»‹ç»\næ¨¡å‹éƒ¨ç½²éƒ¨åˆ†ï¼Œå¼ºå¤§çš„googleç”Ÿæ€ä¸‹ï¼Œå·²ç»æœ‰å®Œæ•´çš„éƒ¨ç½²æ–¹æ¡ˆï¼Œéƒ¨ç½²å·¥å…·å¯ä»¥ç›´æ¥ä½¿ç”¨googleçš„tensorflow-model-serverã€‚\n\n### tensorflow-model-serverå®‰è£…(æœ€ç®€å•å°±æ˜¯ç”¨dockeræ¥ç”¨tf serving)\næˆ‘æ˜¯ä½¿ç”¨dockeræ¥å®‰è£…,æ–¹ä¾¿ç®€å•ï¼Œ\n\nå¦‚æœæ˜¯Ubuntuç¯å¢ƒå¯ä»¥ä½¿ç”¨apt-get installå®‰è£…ï¼Œå…¶ä»–ç¯å¢ƒå¯ä»¥ä»æºç ç¼–è¯‘ï¼Œå…·ä½“çš„å†…å®¹å¤§å®¶å¯ä»¥å‚è€ƒï¼š\n- [tensorflowå®˜ç½‘å®‰è£…æŒ‡å—](https://www.tensorflow.org/tfx/serving/setup)\n- [Ubuntuå®‰è£…æŒ‡å—](https://blog.51cto.com/aaronsa/2284396)\n  \n### å…³äºtensorflow servingä»‹ç»\nå¤§å®¶ä¹ æƒ¯ä½¿ç”¨TensorFlowè¿›è¡Œæ¨¡å‹çš„è®­ç»ƒã€éªŒè¯å’Œé¢„æµ‹ï¼Œä½†æ¨¡å‹å®Œå–„ä¹‹åçš„ç”Ÿäº§ä¸Šçº¿æµç¨‹ï¼Œå°±å˜å¾—äº”èŠ±å…«é—¨äº†ã€‚é’ˆå¯¹è¿™ç§æƒ…å†µGoogleæä¾›äº†TensorFlow Serveringï¼Œå¯ä»¥å°†è®­ç»ƒå¥½çš„æ¨¡å‹ç›´æ¥ä¸Šçº¿å¹¶æä¾›æœåŠ¡ã€‚æ—©åœ¨2017å¹´çš„TensorFlowå¼€å‘è€…Summitä¸Šå°±æå‡ºäº†TensorFlow Servingã€‚\n ä½†é‚£æ—¶å€™å®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯çš„é€šä¿¡åªæ”¯æŒgRPCã€‚åœ¨å®é™…çš„ç”Ÿäº§ç¯å¢ƒä¸­æ¯”è¾ƒå¹¿æ³›ä½¿ç”¨çš„C/Sé€šä¿¡æ‰‹æ®µæ˜¯åŸºäºRESTfull APIçš„ï¼Œå¹¸è¿çš„æ˜¯ä»TF1.8ä»¥åï¼ŒTF Servingä¹Ÿæ­£å¼æ”¯æŒRESTfull APIé€šä¿¡æ–¹å¼äº†ã€‚\n\n#### æœåŠ¡æ¡†æ¶\n![img](../img/tf_serving/tf1.png)\n\nTF ServingæœåŠ¡æ¡†æ¶\n\nåŸºäºTF Servingçš„æŒç»­é›†æˆæ¡†æ¶è¿˜æ˜¯æŒºç®€æ˜çš„ï¼ŒåŸºæœ¬åˆ†ä¸‰ä¸ªæ­¥éª¤ï¼š\n\n- æ¨¡å‹è®­ç»ƒ\n   è¿™æ˜¯å¤§å®¶æœ€ç†Ÿæ‚‰çš„éƒ¨åˆ†ï¼Œä¸»è¦åŒ…æ‹¬æ•°æ®çš„æ”¶é›†å’Œæ¸…æ´—ã€æ¨¡å‹çš„è®­ç»ƒã€è¯„æµ‹å’Œä¼˜åŒ–ï¼›\n- æ¨¡å‹ä¸Šçº¿\n   å‰ä¸€ä¸ªæ­¥éª¤è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨TF Serverä¸­ä¸Šçº¿ï¼›\n- æœåŠ¡ä½¿ç”¨\n   å®¢æˆ·ç«¯é€šè¿‡gRPCå’ŒRESTfull APIä¸¤ç§æ–¹å¼åŒTF Serveringç«¯è¿›è¡Œé€šä¿¡ï¼Œå¹¶è·å–æœåŠ¡ï¼›\n\n#### TF Servingå·¥ä½œæµç¨‹\n![img](../img/tf_serving/tf2.png)\n\nTF Servingå·¥ä½œæµç¨‹\n\nTF Servingçš„å·¥ä½œæµç¨‹ä¸»è¦åˆ†ä¸ºä»¥ä¸‹å‡ ä¸ªæ­¥éª¤ï¼š\n\n- Sourceä¼šé’ˆå¯¹éœ€è¦è¿›è¡ŒåŠ è½½çš„æ¨¡å‹åˆ›å»ºä¸€ä¸ªLoaderï¼ŒLoaderä¸­ä¼šåŒ…å«è¦åŠ è½½æ¨¡å‹çš„å…¨éƒ¨ä¿¡æ¯ï¼›\n- Sourceé€šçŸ¥Manageræœ‰æ–°çš„æ¨¡å‹éœ€è¦è¿›è¡ŒåŠ è½½ï¼›\n- Manageré€šè¿‡ç‰ˆæœ¬ç®¡ç†ç­–ç•¥ï¼ˆVersion Policyï¼‰æ¥ç¡®å®šå“ªäº›æ¨¡å‹éœ€è¦è¢«ä¸‹æ¶ï¼Œå“ªäº›æ¨¡å‹éœ€è¦è¢«åŠ è½½ï¼›\n- Mangeråœ¨ç¡®è®¤éœ€è¦åŠ è½½çš„æ¨¡å‹ç¬¦åˆåŠ è½½ç­–ç•¥ï¼Œä¾¿é€šçŸ¥Loaderæ¥åŠ è½½æœ€æ–°çš„æ¨¡å‹ï¼›\n- å®¢æˆ·ç«¯åƒæœåŠ¡ç«¯è¯·æ±‚æ¨¡å‹ç»“æœæ—¶ï¼Œå¯ä»¥æŒ‡å®šæ¨¡å‹çš„ç‰ˆæœ¬ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨æœ€æ–°æ¨¡å‹çš„ç»“æœï¼›\n\n#### ç®€å•ç¤ºä¾‹\n\nTF Servingå®¢æˆ·ç«¯å’ŒæœåŠ¡ç«¯çš„é€šä¿¡æ–¹å¼æœ‰ä¸¤ç§ï¼ˆgRPCå’ŒRESTfull APIï¼‰\n\n##### ç¤ºä¾‹ï¼ˆä¸€ï¼‰ï¼šRESTfull APIå½¢å¼\n\n- **1. å‡†å¤‡TF Servingçš„Dockerç¯å¢ƒ**\n\nç›®å‰TF Servingæœ‰Dockerã€APTï¼ˆäºŒçº§åˆ¶å®‰è£…ï¼‰å’Œæºç ç¼–è¯‘ä¸‰ç§æ–¹å¼ï¼Œä½†è€ƒè™‘å®é™…çš„ç”Ÿäº§ç¯å¢ƒé¡¹ç›®éƒ¨ç½²å’Œç®€å•æ€§ï¼Œæ¨èä½¿ç”¨Dockeræ–¹å¼ã€‚\n\n```shell\ndocker pull tensorflow/serving\n```\n\n- **2. ä¸‹è½½å®˜æ–¹ç¤ºä¾‹ä»£ç **\n\nç¤ºä¾‹ä»£ç ä¸­åŒ…å«å·²è®­ç»ƒå¥½çš„æ¨¡å‹å’Œä¸æœåŠ¡ç«¯è¿›è¡Œé€šä¿¡çš„å®¢æˆ·ç«¯ï¼ˆRESTfull APIå½¢å¼ä¸éœ€è¦ä¸“é—¨çš„å®¢æˆ·ç«¯ï¼‰\n\n```shell\nmkdir -p /tmp/tfserving\ncd /tmp/tfserving\ngit clone https://github.com/tensorflow/serving\n```\n\n- **3. è¿è¡ŒTF Serving**\n\n```shell\ndocker run -p 8501:8501 \\\n  --mount type=bind,\\\n   source=/tmp/tfserving/serving/tensorflow_serving/servables/tensorflow/testdata/saved_model_half_plus_two_cpu,\\\ntarget=/models/half_plus_two \\\n-e MODEL_NAME=half_plus_two -t tensorflow/serving &\n```\n\nè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¾ƒæ—©çš„dockerç‰ˆæœ¬æ²¡æœ‰â€œ--mountâ€é€‰é¡¹ï¼Œæ¯”å¦‚Ubuntu16.04é»˜è®¤å®‰è£…çš„dockerå°±æ²¡æœ‰ï¼ˆæˆ‘çš„ç¯å¢ƒæ˜¯Ubuntu 18.04ï¼‰ã€‚\n\n- **4.å®¢æˆ·ç«¯éªŒè¯**\n\n```shell\ncurl -d '{\"instances\": [1.0, 2.0, 5.0]}' \\\n  -X POST http://localhost:8501/v1/models/half_plus_two:predict \n```\n\nè¿”å›ç»“æœï¼Œ\n\n```shell\n{ \"predictions\": [2.5, 3.0, 4.5] }\n```\n\n##### ç¤ºä¾‹ï¼ˆäºŒï¼‰ï¼šgRPCå½¢å¼\n\n- **1. å‡†å¤‡TF Servingçš„Dockerç¯å¢ƒ**\n\nç›®å‰TF Servingæœ‰Dockerã€APTï¼ˆäºŒçº§åˆ¶å®‰è£…ï¼‰å’Œæºç ç¼–è¯‘ä¸‰ç§æ–¹å¼ï¼Œä½†è€ƒè™‘å®é™…çš„ç”Ÿäº§ç¯å¢ƒé¡¹ç›®éƒ¨ç½²å’Œç®€å•æ€§ï¼Œæ¨èä½¿ç”¨Dockeræ–¹å¼ã€‚\n\n```shell\ndocker pull tensorflow/serving\n```\n\n- **2. ä¸‹è½½å®˜æ–¹ç¤ºä¾‹ä»£ç **\n\n```shell\nmkdir -p /tmp/tfserving\ncd /tmp/tfserving\ngit clone https://github.com/tensorflow/serving\n```\n\n- **3. æ¨¡å‹ç¼–è¯‘**\n\n```shell\npython tensorflow_serving/example/mnist_saved_model.py models/mnist\n```\n\n- **4. è¿è¡ŒTF Serving**\n\n```shell\ndocker run -p 8500:8500 \\\n--mount type=bind,source=$(pwd)/models/mnist,target=/models/mnist \\\n-e MODEL_NAME=mnist -t tensorflow/serving\n```\n\nè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œè¾ƒæ—©çš„dockerç‰ˆæœ¬æ²¡æœ‰â€œ--mountâ€é€‰é¡¹ï¼Œæ¯”å¦‚Ubuntu16.04é»˜è®¤å®‰è£…çš„dockerå°±æ²¡æœ‰ï¼ˆè¿™é‡Œçš„ç¯å¢ƒæ˜¯Ubuntu 18.04ï¼‰ã€‚\n\n- **5.å®¢æˆ·ç«¯éªŒè¯**\n\n```shell\npython tensorflow_serving/example/mnist_client.py --num_tests=1000 --server=127.0.0.1:8500\n```\n\nè¿”å›ç»“æœï¼Œ\n\n```shell\nInference error rate: 11.13%\n```\n\nè¿™é‡Œéœ€è¦æ³¨æ„çš„æ˜¯ï¼Œç›´æ¥è¿è¡Œmnist_client.pyä¼šå‡ºç°æ‰¾ä¸åˆ°â€œtensorflow_servingâ€çš„é—®é¢˜ï¼Œéœ€è¦æ‰‹åŠ¨å®‰è£…ï¼Œ\n\n```shell\npip install tensorflow-serving-api\n```\n\n#### èµ„æ–™å‚è€ƒ\nTF Servingå®˜æ–¹æ–‡æ¡£ï¼šhttps://www.tensorflow.org/tfx/guide/serving\nä¸ªäººçš„é¡¹ç›®æ˜¯ä½¿ç”¨RESTfull APIå½¢å¼,æ„Ÿè§‰ç®€å•å¾ˆå¤š,ä¸éœ€è¦gRpcå½¢å¼é‚£æ ·åˆ›å»ºå®¢æˆ·ç«¯å’Œæ¨¡å‹ç¼–è¯‘\n\n## Step3: å…·ä½“å®æ“, å®‰è£…Dockerç‰ˆçš„tensorflow/serving\nç›®å‰TF Servingæœ‰Dockerã€APTï¼ˆäºŒçº§åˆ¶å®‰è£…ï¼‰å’Œæºç ç¼–è¯‘ä¸‰ç§æ–¹å¼ï¼Œæˆ‘ä½¿ç”¨Dockeræ–¹å¼ã€‚\n```python\ndocker pull tensorflow/serving\n```\n\n## Step4:æ¨¡å‹éƒ¨ç½²\n### è·å–å½“å‰ç»å¯¹è·¯å¾„\n\n```python\nimport os\n# è·å–å½“å‰ç»å¯¹è·¯å¾„\nMODEL_DIR = os.getcwd()+\"/Models/RNN\" #æŒ‡å®šç»å¯¹è·¯å¾„\nos.environ[\"MODEL_DIR\"] = MODEL_DIR #è®¾ç½®å…¨å±€å˜é‡\nprint(MODEL_DIR)  æ‰“å°ç»å¯¹è·¯å¾„\n\n```\n\n\n    /Volumes/Untitled/NLPé¡¹ç›®/dockeréƒ¨ç½²/flask_news_classifier/Models/RNN\n\n\n## Step5: ç”¨Dockerå¯åŠ¨tf serving\n\n### sourceè¿™é‡Œä¸€å®šè¦å†™ç»å¯¹è·¯å¾„\n\n###  targetè¿™é‡Œè¦å†™/models/è‡ªå®šä¹‰åå­—(æ¯”å¦‚rnn_serving)\n\n### MODEL_NAME å’Œtargetçš„è‡ªå®šä¹‰åå­—ä¸€æ ·\n\n\n```bash\n%%bash --bg ##åå°ç»ˆç«¯è¿è¡Œ\ndocker run -p 8501:8501 --mount type=bind,source=\"${MODEL_DIR}\",target=/models/rnn_serving -e MODEL_NAME=rnn_serving -t tensorflow/serving & >server.log 2>&1\n\n# å†™æ—¥è®°\n! tail server.log\n\n# å®‰è£… requestsåŒ…,ç”¨æ¥æ¥æ”¶è¯·æ±‚\n\n! pip install -q requests\n\n```\n\n## Step6: æ£€æµ‹æ¨¡å‹æ˜¯å¦éƒ¨ç½²åˆ°dockerä¸Š,è¿›å…¥ç»ˆç«¯\n### é¦–å…ˆè¾“å…¥ä¸€ä¸‹å‘½ä»¤,æŸ¥çœ‹è¿è¡Œçš„å®¹å™¨åå­—æˆ–è€…id\n```\ndocker ps\n```\n![png](../img/tf_serving/2.png)\n\n### ç„¶åè¿›å…¥è¿è¡Œçš„å®¹å™¨,æŸ¥çœ‹å®¹å™¨çš„models\n```\ndocker exec -it å®¹å™¨åå­—æˆ–è€…å®¹å™¨id /bin/bash\ndocker exec -it wonderful_meitner /bin/bash\n```\n```\ncd models\nls\n```\n![png](../img/tf_serving/3.png)\n\n## æˆ‘ä»¬çœ‹åˆ°æˆ‘ä»¬é‡Œé¢æœ‰æ–‡ä»¶å¤¹rnn_serving,è¿™å°±æ˜¯æˆ‘ä»¬ä¹‹å‰step2tensorflowæ¨¡å‹å¯¼å‡ºçš„æ–‡ä»¶\n\n![png](../img/tf_serving/4.png)\n\n\n## æµ‹è¯•æ•°æ®é¢„å¤„ç†\n\n```python\nfrom tensorflow.keras.preprocessing import sequence\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom utils import *\nimport json\nimport numpy\nimport requests\nimport jieba\n\n# è·¯å¾„ç­‰é…ç½®\ndata_dir = \"./processed_data\"\nvocab_file = \"./vocab/vocab.txt\"\nvocab_size = 40000\n\n# ç¥ç»ç½‘ç»œé…ç½®\nmax_features = 40001\nmaxlen = 100\nbatch_size = 256\nembedding_dims = 50\nepochs = 8\n\nprint('æ•°æ®é¢„å¤„ç†ä¸åŠ è½½æ•°æ®...')\n# å¦‚æœä¸å­˜åœ¨è¯æ±‡è¡¨ï¼Œé‡å»º\nif not os.path.exists(vocab_file):  \n    build_vocab(data_dir, vocab_file, vocab_size)\n# è·å¾— è¯æ±‡/ç±»åˆ« ä¸idæ˜ å°„å­—å…¸\ncategories, cat_to_id = read_category()\nwords, word_to_id = read_vocab(vocab_file)\n```\n\n    æ•°æ®é¢„å¤„ç†ä¸åŠ è½½æ•°æ®...\n\n\n###  å­—å…¸æ•°æ®è½¬æ¢æˆjsonæ ¼å¼,ä½¿ç”¨requestè¯·æ±‚\n\n\n```python\ntext = \"æ¨å¹‚å¥½æ¼‚äº®,å‘ç”ŸåŸå­å¼¹\"\nprint(jieba.lcut(text))\ntext_seg = encode_sentences([jieba.lcut(text)], word_to_id)\ntext_input = sequence.pad_sequences(text_seg, maxlen=maxlen)\n\ndata = json.dumps({\"signature_name\": \"serving_default\",\n                   \"instances\": text_input.reshape(1,100).tolist()})\nheaders = {\"content-type\": \"application/json\"}\njson_response = requests.post('http://localhost:8501/v1/models/rnn_serving:predict',\n                              data=data, headers=headers)\n```\n\n    ['æ¨å¹‚', 'å¥½', 'æ¼‚äº®', ',', 'å‘ç”Ÿ', 'åŸå­å¼¹']\n\n\n### å‘ˆç°å‡ºæµ‹è¯•æ•°æ®çš„ç±»åˆ«\n\n\n```python\nprint(json.loads(json_response.text))\n# print(json_response.text.split(':')[1].strip()[2:-9])\n# print(json_response.text.split(':')[1].strip()[2:-9].split(','))\nproba = json_response.text.split(':')[1].strip()[2:-9].split(',')\nproba\nproba = [float(i) for i in proba]\nprint(proba)\n\nimport numpy as np\n#\nnews_dict = {'0': 'car', '1':'entertainment', '2':'military', '3':'sports', '4':'technology'}\nprint('News Type:',news_dict[str(np.argmax(proba))])\n```\n\n    {'predictions': [[0.00735603366, 0.974295, 0.00240160106, 0.00155786274, 0.0143894823]]}\n    [0.00735603366, 0.974295, 0.00240160106, 0.00155786274, 0.0143894823]\n    News Type: entertainment\n\n# æˆåŠŸéƒ¨ç½²è‡ªå·±çš„æ¨¡å‹åˆ°tf_servingå•¦\n## æœ€é‡è¦æ˜¯step5!!!step5!!!step5!!!"
    },
    {
      "id": "/2020/4/04/webscrapper",
      "metadata": {
        "permalink": "/blog/2020/4/04/webscrapper",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-04-webscrapper.md",
        "source": "@site/blog/2020-4-04-webscrapper.md",
        "title": "ä½¿ç”¨webscrapperçˆ¬å–ä¿¡æ¯",
        "description": "step 1: æ¯”å¦‚åœ¨ä¸€ä¸ªç½‘ç«™æœç´¢çº¸å°¿è£¤, æˆ‘ä»¬åœ¨google chromeçš„æ›´å¤šå·¥å…·ä¸­ç‚¹å‡»å¼€å‘è€…å·¥å…·",
        "date": "2020-04-04T00:00:00.000Z",
        "formattedDate": "April 4, 2020",
        "tags": [
          {
            "label": "web",
            "permalink": "/blog/tags/web"
          },
          {
            "label": "scrapper",
            "permalink": "/blog/tags/scrapper"
          },
          {
            "label": "shopping",
            "permalink": "/blog/tags/shopping"
          }
        ],
        "readingTime": 1.3,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "webscrapper",
          "title": "ä½¿ç”¨webscrapperçˆ¬å–ä¿¡æ¯",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "web",
            "scrapper",
            "shopping"
          ]
        },
        "prevItem": {
          "title": "tf_servingéƒ¨ç½²+é‡åˆ°çš„é—®é¢˜",
          "permalink": "/blog/2020/4/05/tf_serving"
        },
        "nextItem": {
          "title": "ç”¨fakeræ¨¡æ‹Ÿæ•°æ®+éšæœºç§å­",
          "permalink": "/blog/2020/4/02/faker"
        }
      },
      "content": "<!--truncate-->\n## step 1: æ¯”å¦‚åœ¨ä¸€ä¸ªç½‘ç«™æœç´¢çº¸å°¿è£¤, æˆ‘ä»¬åœ¨google chromeçš„æ›´å¤šå·¥å…·ä¸­ç‚¹å‡»å¼€å‘è€…å·¥å…·\n\n![png](../img/scrapper/1.png)\n\n## step 2: \n### 1 .é€‰æ‹©web scrapper\n### 2 .é€‰æ‹©create new sitemap\n### 3 .é€‰æ‹©select, ç„¶ååœ¨å•†å“é¡µé¢é€‰æ‹©èƒ½å¤Ÿè¦†ç›–å•†å“æ‰€æœ‰ä¿¡æ¯çš„ä½ç½®,ç„¶åç‚¹å‡»done selecting, é€‰æ‹©mulitple\n\n## step3: \ndone selectingå,ä½ å‘ç°selectorç¬¬å››ä¸ªå­—æ®µæ˜¯link_54224078139(è¿™ä¸ªæ˜¯ç‰¹ç‚¹å•†å“çš„ç¼–å·),æˆ‘ä»¬å»é™¤å®ƒ,ä½¿ä»–æ³›åŒ–,å˜æˆdiv.search_prolist_info\n\n\n![png](../img/scrapper/2.png)\n\n## step4: ç‚¹å‡»save selector,ç”¨element previewæŸ¥çœ‹æ•ˆæœæ˜¯å¦æ‰€æœ‰é¡µé¢éƒ½åŒ…å«\n![png](../img/scrapper/3.png)\n\n\n## step5: ç‚¹å‡»item,ç„¶ååˆ›å»ºæ–°çš„selector\næµç¨‹åŸºæœ¬ä¸€æ ·,ä½†æ˜¯ä¸é€‰æ‹©multiple,ç„¶åè¯„è®ºå­—æ®µçš„regexå†™[0-9]+\n\n## step6: ä¿å­˜selector\n\n### å¦‚æœè¦æ€•æ‰€æœ‰é¡µ,å¯ä»¥å»Sitemapä¸‹é€‰æ‹©edit metadataæ¥è®¾ç½®\n\n![png](../img/scrapper/4.png)\n\n## step7: å›åˆ°root,ç„¶åé€‰æ‹©sitemapçš„ä¸‹æ‹‰èœå•çš„Scrape\n![png](../img/scrapper/5.png)\n\n## step8: ç‚¹å‡»start scraping\n![png](../img/scrapper/6.png)\n\n## step9: Sitemapé€‰æ‹©browse,å¯ä»¥æŸ¥çœ‹æ‰€æœ‰data\n![png](../img/scrapper/7.png)\n\n## é€‰æ‹©Sitemap,å¯¼å‡ºcsvæ–‡ä»¶"
    },
    {
      "id": "/2020/4/02/faker",
      "metadata": {
        "permalink": "/blog/2020/4/02/faker",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-02-faker.md",
        "source": "@site/blog/2020-4-02-faker.md",
        "title": "ç”¨fakeræ¨¡æ‹Ÿæ•°æ®+éšæœºç§å­",
        "description": "Pretty printing has been turned OFF",
        "date": "2020-04-02T00:00:00.000Z",
        "formattedDate": "April 2, 2020",
        "tags": [
          {
            "label": "faker",
            "permalink": "/blog/tags/faker"
          },
          {
            "label": "æ±‡ä¸°",
            "permalink": "/blog/tags/æ±‡ä¸°"
          },
          {
            "label": "random seed",
            "permalink": "/blog/tags/random-seed"
          }
        ],
        "readingTime": 0.895,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "faker",
          "title": "ç”¨fakeræ¨¡æ‹Ÿæ•°æ®+éšæœºç§å­",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "faker",
            "æ±‡ä¸°",
            "random seed"
          ]
        },
        "prevItem": {
          "title": "ä½¿ç”¨webscrapperçˆ¬å–ä¿¡æ¯",
          "permalink": "/blog/2020/4/04/webscrapper"
        },
        "nextItem": {
          "title": "è½»æ¾ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶è‡³GitHub",
          "permalink": "/blog/2020/4/02/git_big_file copy"
        }
      },
      "content": "<!--truncate-->\n\n```python\n%config ZMQInteractiveShell.ast_node_interactivity='all' \n%pprint\n```\n\n    Pretty printing has been turned OFF\n\n\n## å¯¼å…¥å·¥å…·åŒ…\n\n\n```python\nimport pandas as pd\nfrom faker import Faker\n```\n\n## åˆ›å»ºå®ä¾‹,è®¾ç½®æœ¬åœ°åŒ–\n\n```python\nfake = Faker('zh_CN')\n```\n\n## åˆ›å»ºæ¨¡æ‹Ÿä¸ªäººæ•°æ®å‡½æ•°,è®¾å®šéšæœºç§å­\n\n\n```python\ndef generate_user(i):\n    fake.random.seed(i)\n    return dict(name=fake.name(),password=fake.password(length=10),company=fake.company(),job=fake.job(),birthday=fake.date_of_birth(minimum_age=0, maximum_age=120),\n                telephone=fake.phone_number(),\n                address=fake.address())\n```\n\n## ç”Ÿæˆå®¢æˆ·æ¨¡æ‹Ÿæ•°æ®åˆ—è¡¨, ç”¨dataframeå‘ˆç°\n\n```python\nusers = []\nfor i in range(5):\n    users.append(generate_user(i))\ndf = pd.DataFrame(users)\ndf\n```\n![png](../img/faker/1.png)\n\n### éªŒè¯éšæœºç§å­è®¾å®šæ˜¯å¦æˆåŠŸ\n```python\nusers = []\nfor i in range(8):\n    users.append(generate_user(i))\ndf = pd.DataFrame(users)\ndf\n```\n![png](../img/faker/2.png)\n\n## å¯¼å‡ºæ•°æ®,ç”Ÿæˆcsvæ–‡ä»¶\n\n```python\ndf.to_csv('./fakedata.csv')\n```\n# æŸ¥çœ‹åšå®¢èµ„æ–™\n\n## èµ„æ–™ç´¢å¼•\n\n1.  [ç”¨fakeræ¨¡æ‹Ÿæ•°æ®](https://blog.csdn.net/u011054333/article/details/84203878)\n\n2.  [fakerå®˜ç½‘](https://faker.readthedocs.io/en/master/locales/zh_CN.html)\n\n3.  [æ ‡å‡†provides](https://faker.readthedocs.io/en/master/providers.html)\n\n4.  [ç¬¬ä¸‰æ–¹provides](https://faker.readthedocs.io/en/master/communityproviders.html)\n\n\n```python\n\n```"
    },
    {
      "id": "/2020/4/02/git_big_file copy",
      "metadata": {
        "permalink": "/blog/2020/4/02/git_big_file copy",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-02-git_big_file copy.md",
        "source": "@site/blog/2020-4-02-git_big_file copy.md",
        "title": "è½»æ¾ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶è‡³GitHub",
        "description": "GitHubæœ‰ä¸€ä¸ªé™åˆ¶ï¼Œä¸èƒ½ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶ã€‚æƒ³è¦ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶ï¼Œå°±éœ€è¦å€ŸåŠ©Git LFS",
        "date": "2020-04-02T00:00:00.000Z",
        "formattedDate": "April 2, 2020",
        "tags": [
          {
            "label": "git",
            "permalink": "/blog/tags/git"
          },
          {
            "label": "lfs",
            "permalink": "/blog/tags/lfs"
          },
          {
            "label": "github",
            "permalink": "/blog/tags/github"
          }
        ],
        "readingTime": 1.195,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "git_big_file",
          "title": "è½»æ¾ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶è‡³GitHub",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "git",
            "lfs",
            "github"
          ]
        },
        "prevItem": {
          "title": "ç”¨fakeræ¨¡æ‹Ÿæ•°æ®+éšæœºç§å­",
          "permalink": "/blog/2020/4/02/faker"
        },
        "nextItem": {
          "title": "å¿«é€ŸæŒ‰ç…§å·¥å…·åŒ…",
          "permalink": "/blog/2020/3/31/douban"
        }
      },
      "content": "GitHubæœ‰ä¸€ä¸ªé™åˆ¶ï¼Œä¸èƒ½ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶ã€‚æƒ³è¦ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶ï¼Œå°±éœ€è¦å€ŸåŠ©Git LFS\n<!--truncate-->\n\n## step1: å®‰è£…LFS,æ‰§è¡Œå‘½ä»¤\n```python\nbrew install git-lfs\n```\n\n## step2: è¿›å…¥ä»“åº“ç›®å½•,æ‰§è¡Œå‘½ä»¤\n\n```python\ngit lfs track \"file\"\ngit add .gitattributes\ngit commit -m \"submit file\"\ngit push -u origin master \n```\nfileæ˜¯è¦ä¸Šä¼ çš„æ–‡ä»¶,ä¸€èˆ¬æ‰§è¡Œå®Œstep2å,ä¼šç”Ÿæˆ\".gitattributes\"æ–‡ä»¶ï¼Œæ–‡ä»¶å†…è®°å½•äº†æˆ‘ä»¬è¦ä¸Šä¼ æ–‡ä»¶çš„ä¿¡æ¯ã€‚åªæœ‰å…ˆæŠŠ\".gitattributes\"ä¼ ä¸Šå»ï¼Œæ‰å¯ä»¥ä¸Šä¼ å¤§æ–‡ä»¶ã€‚\n\n## step3: ä¸Šä¼ å¤§æ–‡ä»¶\n\n```python\ngit add file\ngit commit -m \"add file\"\ngit push -u origin master\n```\n## å®æˆ˜demoå¦‚ä¸‹:\n### åˆ‡æ¢åˆ°ä»“åº“ç›®å½•,æ˜¯git statusæŸ¥çœ‹çŠ¶æ€\n![png](../img/git/1.png)\n### æ‰§è¡Œåˆšæ‰çš„æ‰€æœ‰å‘½ä»¤\n![png](../img/git/2.png)\næˆ‘ä»¬å‘ç°ä¸Šä¼ å¤±è´¥,æ˜¯å› ä¸ºconnectionå¤±è´¥äº†\n\n### æˆ‘ä»¬å°è¯•è®¾ç½®å…¨çƒå˜é‡\n```python\ngit config --global user.name\"name\"\n```\n![png](../img/git/3.png)\n\n### é‡æ–°æ‰§è¡Œpushå‘½ä»¤,æœ€åä¸Šä¼ æˆåŠŸå•¦\n```python\ngit push -u origin master\n```"
    },
    {
      "id": "/2020/3/31/douban",
      "metadata": {
        "permalink": "/blog/2020/3/31/douban",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-31-douban.md",
        "source": "@site/blog/2020-3-31-douban.md",
        "title": "å¿«é€ŸæŒ‰ç…§å·¥å…·åŒ…",
        "description": "å®‰è£…google-cloud-bigquery and google-cloud-bigquery-storage packages.",
        "date": "2020-03-31T00:00:00.000Z",
        "formattedDate": "March 31, 2020",
        "tags": [
          {
            "label": "python",
            "permalink": "/blog/tags/python"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 0.29,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "douban",
          "title": "å¿«é€ŸæŒ‰ç…§å·¥å…·åŒ…",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "python",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "è½»æ¾ä¸Šä¼ è¶…è¿‡100Mçš„æ–‡ä»¶è‡³GitHub",
          "permalink": "/blog/2020/4/02/git_big_file copy"
        },
        "nextItem": {
          "title": "Install the BigQuery Python client library version 1.9.0 or higher and the BigQuery Storage API Python client library.",
          "permalink": "/blog/2020/3/30/BigQuery Storage API"
        }
      },
      "content": "å®‰è£…google-cloud-bigquery and google-cloud-bigquery-storage packages.\néœ€è¦è®¤è¯\n<!--truncate-->\n## step1 å®‰è£…åŒ…å¾ˆå¤šæ—¶å€™å¾ˆæ…¢æ¯”å¦‚æ‰§è¡Œä¸€ä¸‹å‘½ä»¤\n``` \npip install --upgrade google-cloud-bigquery[bqstorage,pandas] \n```\n## step2 åœ¨å‘½ä»¤åé¢åŠ ä¸Š\n``` \npip install --upgrade google-cloud-bigquery[bqstorage,pandas] -i https://pypi.douban.com/simple\n```\n\nä¸‹è½½ç¬é—´å¿«å¾ˆå¤š"
    },
    {
      "id": "/2020/3/30/BigQuery Storage API",
      "metadata": {
        "permalink": "/blog/2020/3/30/BigQuery Storage API",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-30-BigQuery Storage API.md",
        "source": "@site/blog/2020-3-30-BigQuery Storage API.md",
        "title": "Install the BigQuery Python client library version 1.9.0 or higher and the BigQuery Storage API Python client library.",
        "description": "å®‰è£…google-cloud-bigquery and google-cloud-bigquery-storage packages.",
        "date": "2020-03-30T00:00:00.000Z",
        "formattedDate": "March 30, 2020",
        "tags": [
          {
            "label": "python",
            "permalink": "/blog/tags/python"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 0.42,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "BigQueryStorageAPI",
          "title": "Install the BigQuery Python client library version 1.9.0 or higher and the BigQuery Storage API Python client library.",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "python",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "å¿«é€ŸæŒ‰ç…§å·¥å…·åŒ…",
          "permalink": "/blog/2020/3/31/douban"
        },
        "nextItem": {
          "title": "æœ¬åœ°è¿æ¥google cloud shell",
          "permalink": "/blog/2020/3/29/ssh_gcs"
        }
      },
      "content": "å®‰è£…google-cloud-bigquery and google-cloud-bigquery-storage packages.\néœ€è¦è®¤è¯\n<!--truncate-->\n## step1 ä¸€èˆ¬æ–¹æ³•æ˜¯å¤åˆ¶ä»¥ä¸‹å‘½ä»¤åœ¨mac osç»ˆç«¯æ‰§è¡Œ\n``` \npip install --upgrade google-cloud-bigquery[bqstorage,pandas]\n```\n## step2 æˆ‘ä»¬åå‘step1æ“ä½œ,å¾€å¾€ä¸æˆåŠŸä¼šå‡ºç°2\n![png](../img/BQ_API/2.png)\n\n## step3 æˆ‘ä»¬åœ¨å‘½ä»¤è¡Œåé¢åŠ ä¸Š--user\n``` \npip install --upgrade google-cloud-bigquery[bqstorage,pandas] --user\n```\n![png](../img/BQ_API/1.png)\n\né€šè¿‡æ“ä½œå°±æˆåŠŸäº†"
    },
    {
      "id": "/2020/3/29/ssh_gcs",
      "metadata": {
        "permalink": "/blog/2020/3/29/ssh_gcs",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-29-ssh_gcs.md",
        "source": "@site/blog/2020-3-29-ssh_gcs.md",
        "title": "æœ¬åœ°è¿æ¥google cloud shell",
        "description": "google cloud shell ç»å¸¸æ–­çº¿,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å°è¯•ç”¨æœ¬åœ°sshè¿æ¥google cloud shell",
        "date": "2020-03-29T00:00:00.000Z",
        "formattedDate": "March 29, 2020",
        "tags": [
          {
            "label": "python",
            "permalink": "/blog/tags/python"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 1.025,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "ssh_gcs",
          "title": "æœ¬åœ°è¿æ¥google cloud shell",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "python",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "Install the BigQuery Python client library version 1.9.0 or higher and the BigQuery Storage API Python client library.",
          "permalink": "/blog/2020/3/30/BigQuery Storage API"
        },
        "nextItem": {
          "title": "App Engine ä½¿ç”¨å¿«é€Ÿå…¥é—¨",
          "permalink": "/blog/2020/3/28/App Engine"
        }
      },
      "content": "google cloud shell ç»å¸¸æ–­çº¿,æ‰€ä»¥æˆ‘ä»¬å¯ä»¥å°è¯•ç”¨æœ¬åœ°sshè¿æ¥google cloud shell\n## step1 \n``` \ngcloud alpha cloud-shell ssh\n```\n<!--truncate-->\n![png](../img/ssh/1.png)\n\n## step2 æŒ‰ç…§ç³»ç»Ÿè¦æ±‚æŒ‰ç…§å¯†é’¥\n![png](../img/ssh/2.png)\n\n## step3 è¿æ¥æˆåŠŸ\n![png](../img/ssh/3.png)\n\n## step4 å¦‚æœè¿æ¥å¤±è´¥,å¯èƒ½çš„åŸå› æ˜¯gcloudçš„è®¾ç½®\n1 æˆ‘ä»¬å¯ä»¥é‡æ–°å®‰è£…SDK\n2 å¯¹gcloud åˆå§‹åŒ–, é‡æ–°è®¾ç½®project, account\n3 é‡æ–°èµ°step1\n\nå…·ä½“:\n```\n./google-cloud-sdk/install.sh #é‡æ–°å®‰è£…SKDå,é‡æ–°å¼€å¯ç»ˆç«¯\n```\n\n```\ngcloud init åˆå§‹åŒ– SDK\n```\n```\nTo continue, you must log in. Would you like to log in (Y/n)? Y\n\nPick cloud project to use:\n     [1] [my-project-1]\n     [2] [my-project-2]\n     ...\n     Please enter your numeric choice:\n\nWhich compute zone would you like to use as project default?\n     [1] [asia-east1-a]\n     [2] [asia-east1-b]\n     ...\n     [14] Do not use default zone\n     Please enter your numeric choice:\n\ngcloud has now been configured!\n    You can use [gcloud config] to change more gcloud settings.\n\n    Your active configuration is: [default]\n\ngcloud config set accessibility/screen_reader true\n```"
    },
    {
      "id": "/2020/3/28/App Engine",
      "metadata": {
        "permalink": "/blog/2020/3/28/App Engine",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-28-App Engine.md",
        "source": "@site/blog/2020-3-28-App Engine.md",
        "title": "App Engine ä½¿ç”¨å¿«é€Ÿå…¥é—¨",
        "description": "step1: åˆ›å»ºè‡ªå·±çš„ç‹¬ç«‹é¡¹ç›®",
        "date": "2020-03-28T00:00:00.000Z",
        "formattedDate": "March 28, 2020",
        "tags": [
          {
            "label": "python",
            "permalink": "/blog/tags/python"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 0.74,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "App",
          "title": "App Engine ä½¿ç”¨å¿«é€Ÿå…¥é—¨",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "python",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "æœ¬åœ°è¿æ¥google cloud shell",
          "permalink": "/blog/2020/3/29/ssh_gcs"
        },
        "nextItem": {
          "title": "mysqlåŸºæœ¬å‘½ä»¤",
          "permalink": "/blog/2020/3/28/mysql"
        }
      },
      "content": "## step1: åˆ›å»ºè‡ªå·±çš„ç‹¬ç«‹é¡¹ç›®\n\n![png](../img/appengine/1.png)\n<!--truncate-->\n## step2: ä½¿ç”¨App Engine\n![png](../img/appengine/2.png)\n\n## step3: ä½¿ç”¨App Engineçš„ä¸¤ä¸ªé‡è¦å‘½ä»¤\n```\ngcloud init åˆå§‹åŒ–SDK\ngcloud app deploy éƒ¨ç½²åˆ°App Engine\n```\n![png](../img/appengine/3.png)\n\n## step4: æŒ‰ç…§éœ€è¦, å¼€å¯API \n![png](../img/appengine/4.png)\n\n## step5:æœ¬åœ°ç»ˆç«¯æ“ä½œç™»å½•è´¦å·,è®¾ç½®é»˜è®¤é¡¹ç›®\n![png](../img/appengine/5.png)\n\n![png](../img/appengine/6.png)\n\n![png](../img/appengine/7.png)\n\n## step6: ä¸‹è½½é¡¹ç›®/æˆ–è€…æœ¬åœ°é¡¹ç›®\n![png](../img/appengine/8.png)\n\n## step7: ä½¿ç”¨step3çš„å‘½ä»¤éƒ¨ç½², ç‚¹å‡»å¾—åˆ°çš„é“¾æ¥\n```\ngcloud app deploy éƒ¨ç½²\ngcloud app browse æŸ¥çœ‹æ•ˆæœ\n```\n![png](../img/appengine/13.png)\n\n![png](../img/appengine/9.png)\n\n## å¤‡æ³¨: éƒ¨ç½²åˆ°app engineçš„å‡ ä¸ªé‡è¦æ–‡ä»¶\n1 app.yaml\n\n2 requirements.text\n\n3 main.py\n\n\n![png](../img/appengine/10.png)\n![png](../img/appengine/11.png)\n![png](../img/appengine/12.png)"
    },
    {
      "id": "/2020/3/28/mysql",
      "metadata": {
        "permalink": "/blog/2020/3/28/mysql",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-28-mysql.md",
        "source": "@site/blog/2020-3-28-mysql.md",
        "title": "mysqlåŸºæœ¬å‘½ä»¤",
        "description": "æ•°æ®åº“æ“ä½œ",
        "date": "2020-03-28T00:00:00.000Z",
        "formattedDate": "March 28, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 6.61,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "mysql",
          "title": "mysqlåŸºæœ¬å‘½ä»¤",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "App Engine ä½¿ç”¨å¿«é€Ÿå…¥é—¨",
          "permalink": "/blog/2020/3/28/App Engine"
        },
        "nextItem": {
          "title": "pythonè„šæœ¬åŸºç¡€(1)-pythonä¸­osçš„å¸¸ç”¨æ–¹æ³•",
          "permalink": "/blog/2020/3/28/python"
        }
      },
      "content": "æ•°æ®åº“æ“ä½œ\nè¿›å…¥æ•°æ®åº“ \n\næ–¹å¼1 mysql -uç”¨æˆ·å -p å¯†ç  --------ç›´æ¥è¾“å…¥å¯†ç ï¼Œç¼ºç‚¹ï¼Œä¼šæš´éœ²è‡ªå·±çš„å¯†ç å“¦ğŸ˜\n\næ–¹å¼2 mysql -uç”¨æˆ·å -p å›è½¦åè¾“å…¥å¯†ç \n\n![png](../img/mysql/1.png)ã€€ã€€\n<!--truncate-->\nã€€ã€€ã€€ã€€\nä¸»è¦å†…å®¹ï¼šæŸ¥è¯¢\n1ã€æŸ¥è¯¢å½“å‰æ‰€æœ‰çš„æ•°æ®åº“ show databases;\n\n![png](../img/mysql/2.png)\n\n2ã€ä½¿ç”¨æ•°æ®åº“ use æ•°æ®åº“åå­—;\n\n3ã€æŸ¥çœ‹å½“å‰æ•°æ®åº“ç‰ˆæœ¬ select version();\n\n![png](../img/mysql/3.png)\n\n4ã€ åˆ›å»ºæ•°æ®åº“ create database æ•°æ®åº“åï¼›\nã€€create database æ•°æ®åº“å charset = utf8ï¼›\n![png](../img/mysql/4.png)\n\n5ã€æŸ¥çœ‹å½“å‰ä½¿ç”¨æ•°æ®åº“ select database();\n\n![png](../img/mysql/5.png)\n\n6 æŸ¥çœ‹åˆ›å»ºæ•°æ®åº“ show create database æ•°æ®åº“åç§°;\n\n![png](../img/mysql/6.png)\n\n7ã€åˆ é™¤æ•°æ®åº“ drop database æ•°æ®åº“åç§°;\n\n![png](../img/mysql/7.png)\n \næ•°æ®è¡¨çš„æ“ä½œ\n\n1ã€æŸ¥çœ‹å½“å‰æ•°æ®åº“æ‰€æœ‰è¡¨ show tables;\n2ã€åˆ›å»ºè¡¨ creat table è¡¨åï¼ˆå­—æ®µ ç±»å‹ çº¦æŸ[å­—æ®µ ç±»å‹ çº¦æŸ]);\n3ã€æŸ¥çœ‹è¡¨ç»“æ„ desc è¡¨åï¼›\n4ã€æŸ¥çœ‹åˆ›å»ºè¡¨çš„è¯­å¥ show create table è¡¨åï¼›\n5ã€æŸ¥çœ‹è¡¨æ•°æ® select * from è¡¨åï¼›\n6ã€æ·»åŠ è¡¨çš„å­—æ®µ alter table è¡¨å add å­—æ®µå ç±»å‹;\n7ã€ä¿®æ”¹è¡¨ç»“æ„å­—æ®µç±»å‹ alter table è¡¨å modify å­—æ®µ ç›®æ ‡ç±»å‹\n8ã€ä¿®æ”¹è¡¨çš„å­—æ®µé‡å‘½åç‰ˆ alter table è¡¨å chang å­—æ®µåŸå å­—æ®µæ–°å ç›®æ ‡ç±»å‹ çº¦æŸ;\n9ã€åˆ é™¤è¡¨å­—æ®µ alter table è¡¨å drop å­—æ®µ;\n10ã€åˆ é™¤è¡¨ drop table è¡¨å;\n\n \n \nè¡¨å†…æ•°æ®æ“ä½œ\n\nå¢ï¼š\n\n1ã€æ·»åŠ æ•°æ® ---æ’å…¥æ•°æ® insert into è¡¨å values(éœ€è¦æ’å…¥çš„å†…å®¹)ï¼›\nå¯ä»¥åˆ†æ¡æ’å…¥ï¼Œå¯ä»¥ä¸€æ¬¡æ’å…¥å¤šæ¡ï¼Œæ¯ä¸€æ¡éƒ½æ˜¯å®Œæ•´()\n2ã€æ·»åŠ æ•°æ® ----éƒ¨åˆ†æ’å…¥ insert into è¡¨å(å­—æ®µ1ï¼Œå­—æ®µ2...) values (å€¼1ï¼Œå€¼2,...)\nå¯ä»¥åˆ†æ¡æ’å…¥ï¼Œå¯ä»¥ä¸€æ¬¡æ’å…¥å¤šæ¡ï¼Œæ¯ä¸€æ¡éƒ½æ˜¯å®Œæ•´()\næ”¹ï¼š\n1ã€æ”¹è¡¨é‡ŒæŸå­—æ®µé‡Œçš„å€¼ update è¡¨å set å­—æ®µ(åˆ—) = å€¼ (æœ‰æ—¶å€™æŠ¥é”™è¦åŠ \"\") é»˜è®¤æ”¹æ‰€æœ‰äººæœ¬å­—æ®µçš„å†…å®¹\nupdate è¡¨å set å­—æ®µ = å€¼ where æ¡ä»¶ æ”¹ç¬¦åˆæ¡ä»¶çš„å­—æ®µå†…å®¹\n2ã€update å’Œ alter çš„åŒºåˆ« alter æ˜¯ä¿®æ”¹è¡¨ç»“æ„(æ·»åŠ å­—æ®µï¼Œåˆ å­—æ®µï¼Œä¿®æ”¹å­—æ®µåå­—) update ä¿®æ”¹è¡¨é‡Œçš„æ•°æ®\n \næŸ¥ï¼š\n\n1ã€æŸ¥çœ‹è¡¨æ•°æ® select * from è¡¨åï¼›\n2ã€ç»™å®šæ¡ä»¶çš„æŸ¥è¯¢ select * from è¡¨å where æ¡ä»¶;\n3ã€æŸ¥è¯¢æŒ‡å®šå­—æ®µ select å­—æ®µå1,å­—æ®µå2 from è¡¨åï¼›\nå­—æ®µé¡ºåºå½±å“æ˜¾ç¤ºé¡ºåº\nselect å­—æ®µ1 as åˆ«å1,å­—æ®µ2 as åˆ«å2 from è¡¨å;\nselect è¡¨å.å­—æ®µ1,è¡¨å.å­—æ®µ2 from è¡¨å;\nselcect åˆ«å.å­—æ®µ1,åˆ«å.å­—æ®µ from è¡¨å as åˆ«å;\n4ã€å¯ä»¥ä½¿ç”¨asæŒ‡å®šè¡¨oråˆ—å select å­—æ®µ1 asæŒ‡å®šå1,å­—æ®µ2 as æŒ‡å®šå2 from è¡¨å as æŒ‡å®šè¡¨å;\n5ã€æ¶ˆé™¤é‡å¤è¡Œ select distinct å­—æ®µå from è¡¨å;\n6ã€æ¡ä»¶æŸ¥è¯¢\n6.1 æ¯”è¾ƒè¿ç®—ç¬¦ select * from è¡¨å where æ¡ä»¶è¯­å¥\nã€€ã€€<\nã€€ã€€>\nã€€ã€€=\nã€€ã€€<=\n>=\n!= -----ä¸ç­‰äº\n6.2 é€»è¾‘è¿ç®—ç¬¦ select * from è¡¨å where æ¡ä»¶1 and æ¡ä»¶2;\nselect * from è¡¨å where æ¡ä»¶1 or æ¡ä»¶2ï¼›\nselect * from è¡¨å where not æ¡ä»¶ï¼›------ æ¡ä»¶å¯ä»¥æ˜¯ä¸€ä¸ªæˆ–å¤šä¸ª\n6.3 æ¨¡ç³ŠæŸ¥è¯¢\n6.3.1like select * from è¡¨å where å­—æ®µ like â€œâ€ -----ä¸€èˆ¬æŸ¥è¯¢å­—ç¬¦ä¸²\n%æ›¿æ¢ä»»æ„å¤šä¸ªå­—ç¬¦\n_æ›¿æ¢ä¸€ä¸ªå­—ç¬¦_\n6.3.2 rlike select * from è¡¨å where å­—æ®µ rlike \"^ .* $\" ^å­— ---ä»¥è¯¥å­—å¼€å§‹,.* --- å¤šä¸ªå­—ç¬¦ å­—$----ä»¥å­—ç»“å°¾\n6.4 èŒƒå›´æŸ¥è¯¢ select * from è¡¨å where å­—æ®µ in () -------éè¿ç»­èŒƒå›´\nselect * from è¡¨å where å­—æ®µ not in () -------éè¿ç»­èŒƒå›´\nselect * from è¡¨å where å­—æ®µ between å€¼1 and å€¼2ï¼› ------è¿ç»­èŒƒå›´\nselect * from è¡¨å where å­—æ®µ not between å€¼1 and å€¼2;\n6.5 ç©ºåˆ¤æ–­ select * from è¡¨å where å­—æ®µ is null; -----null å¯ä»¥æ˜¯NULLä¹Ÿå¯ä»¥æ˜¯NuLL\nselect * from è¡¨å where å­—æ®µ is not null;\n7ã€æ’åº select * from è¡¨å where å­—æ®µ æ¡ä»¶(å…³ç³») order by å­—æ®µ asc (å‡åº) desc (é™åº) å¤šä¸ªæ’åºå­—æ®µï¼Œåªéœ€\nè¦å†™ä¸€ä¸ªorder by ä¹‹é—´ç”¨, éš”å¼€ï¼Œä¼˜å…ˆæŒ‰ç…§å†™åœ¨å‰é¢çš„å­—æ®µæ’åºã€‚\n8ã€èšåˆå‡½æ•° select * from è¡¨å æ¡ä»¶\nä¾‹ï¼šselect count(*) as ç”·ç”Ÿäººæ•° from students where gender = 1;\nåœ¨select ä¹‹å fromä¹‹å‰ä½¿ç”¨å‡½æ•° ï¼Œç”¨æ‹¬å·æ‹¬ä½å­—æ®µæˆ–è€…*ï¼Œcount---è®¡ç®—æ•°é‡ max----è®¡ç®—æœ€å¤§å€¼\nmin--- è®¡ç®—æœ€å°å€¼ sum ---æ±‚å’Œ avg--- æ±‚å¹³å‡å€¼ round(ç®—æ•°å€¼ï¼Œä¿ç•™å°æ•°ä½æ•°)\nä¾‹ï¼šselect round(avg(height), 2) from students where gender =1;\n \n9ã€åˆ†ç»„ group by\n \n6ã€è¡¨å…³è”\n6.1 å¤–é“¾æ¥ åŸºæœ¬æ ¼å¼ï¼š select * from è¡¨å1ï¼Œè¡¨å2 where è¡¨å1.å­—æ®µ1 = è¡¨å2.å­—æ®µ2 ;\n6.2 å†…å…³è” åŸºæœ¬æ ¼å¼ï¼š select * from è¡¨å1 inner join è¡¨å2 on è¡¨å1.å­—æ®µ1 = è¡¨å2.å­—æ®µ2\n \nåˆ ï¼š\n\nç‰©ç†åˆ é™¤ -------ä¸æ¨è\n\n1ã€åˆ é™¤è¡¨ drop table è¡¨å; -----è¡¨ç»“æ„ä¸€èµ·åˆ é™¤\n2ã€ delete from è¡¨å; -----åˆ é™¤è¡¨å†…å®¹ï¼Œä¸åˆ é™¤è¡¨ç»“æ„,è®°å½•ä¸»é”®çš„ä½ç½®\ndelete from è¡¨å where ;ä¾‹å­ï¼šdelect from students where name = 'å¼ ä¸‰'\n3ã€åˆ é™¤è¡¨ truncate è¡¨å ------æ¸…ç©ºè¡¨ï¼Œä¸åˆ è¡¨ç»“æ„ï¼Œä¸»é”®ä½ç½®ä»æ–°å¼€å§‹\n \n \né€»è¾‘åˆ é™¤\n\nç”¨ä¸€ä¸ªå­—æ®µæ¥è®°å½•æ˜¯å¦è¿™æ¡ä¿¡æ¯æ˜¯å¦ä»¥åŠä¸å†ä½¿ç”¨äº†\næ·»åŠ ä¸€ä¸ªå­—æ®µ ,é»˜è®¤å€¼ä¸º0 è¡¨ç¤ºæ²¡æœ‰åˆ é™¤ ä½¿ç”¨1 è¡¨ç¤ºå·²åˆ é™¤ alter table è¡¨å add is_delete bit default 0,\næ”¹è®°å½•ä¸­å­—æ®µis_delete çš„å€¼ä¸º1ï¼Œè¡¨ç¤ºé€»è¾‘åˆ é™¤ update è¡¨å set is_delete =1 where name = \"\""
    },
    {
      "id": "/2020/3/28/python",
      "metadata": {
        "permalink": "/blog/2020/3/28/python",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-28-python.md",
        "source": "@site/blog/2020-3-28-python.md",
        "title": "pythonè„šæœ¬åŸºç¡€(1)-pythonä¸­osçš„å¸¸ç”¨æ–¹æ³•",
        "description": "1.osæ¨¡å—ï¼šosæ¨¡å—åœ¨pythonä¸­åŒ…å«æ™®éçš„æ“ä½œç³»ç»ŸåŠŸèƒ½ï¼Œä¸‹é¢åˆ—å‡ºäº†ä¸€äº›åœ¨osæ¨¡å—ä¸­æ¯”è¾ƒæœ‰ç”¨çš„éƒ¨åˆ†ã€‚",
        "date": "2020-03-28T00:00:00.000Z",
        "formattedDate": "March 28, 2020",
        "tags": [
          {
            "label": "python",
            "permalink": "/blog/tags/python"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 3.88,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "python",
          "title": "pythonè„šæœ¬åŸºç¡€(1)-pythonä¸­osçš„å¸¸ç”¨æ–¹æ³•",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "python",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "mysqlåŸºæœ¬å‘½ä»¤",
          "permalink": "/blog/2020/3/28/mysql"
        },
        "nextItem": {
          "title": "ä»Dockerhubæ‹‰å–é•œåƒå¹¶ä¸”ä½¿ç”¨å‘½ä»¤è¿è¡Œ",
          "permalink": "/blog/2020/3/27/dockerhub_2"
        }
      },
      "content": "1.osæ¨¡å—ï¼šosæ¨¡å—åœ¨pythonä¸­åŒ…å«æ™®éçš„æ“ä½œç³»ç»ŸåŠŸèƒ½ï¼Œä¸‹é¢åˆ—å‡ºäº†ä¸€äº›åœ¨osæ¨¡å—ä¸­æ¯”è¾ƒæœ‰ç”¨çš„éƒ¨åˆ†ã€‚\n\nos.sepå¯ä»¥å–ä»£æ“ä½œç³»ç»Ÿç‰¹å®šçš„è·¯å¾„åˆ†éš”ç¬¦ã€‚windowsä¸‹ä¸º â€œ\\\\â€\n\nos.nameå­—ç¬¦ä¸²æŒ‡ç¤ºä½ æ­£åœ¨ä½¿ç”¨çš„å¹³å°ã€‚æ¯”å¦‚å¯¹äºWindowsï¼Œå®ƒæ˜¯'nt'ï¼Œè€Œå¯¹äºLinux/Unixç”¨æˆ·ï¼Œå®ƒæ˜¯'posix'ã€‚\n\nos.getcwd()å‡½æ•°å¾—åˆ°å½“å‰å·¥ä½œç›®å½•ï¼Œå³å½“å‰Pythonè„šæœ¬å·¥ä½œçš„ç›®å½•è·¯å¾„ã€‚\n\n<!--truncate-->\nos.getenv()è·å–ä¸€ä¸ªç¯å¢ƒå˜é‡ï¼Œå¦‚æœæ²¡æœ‰è¿”å›none\n\nos.putenv(key, value)è®¾ç½®ä¸€ä¸ªç¯å¢ƒå˜é‡å€¼\n\nos.listdir(path)è¿”å›æŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œç›®å½•åã€‚\n\nos.remove(path)å‡½æ•°ç”¨æ¥åˆ é™¤ä¸€ä¸ªæ–‡ä»¶ã€‚\n\nos.system(command)å‡½æ•°ç”¨æ¥è¿è¡Œshellå‘½ä»¤ã€‚\n\nos.linesepå­—ç¬¦ä¸²ç»™å‡ºå½“å‰å¹³å°ä½¿ç”¨çš„è¡Œç»ˆæ­¢ç¬¦ã€‚ä¾‹å¦‚ï¼ŒWindowsä½¿ç”¨'\\r\\n'ï¼ŒLinuxä½¿ç”¨'\\n'è€ŒMacä½¿ç”¨'\\r'ã€‚\n\nos.curdir:è¿”å›å½“å‰ç›®å½•ï¼ˆ'.')\nos.chdir(dirname):æ”¹å˜å·¥ä½œç›®å½•åˆ°dirname\n\n========================================================================================\n\nos.pathå¸¸ç”¨æ–¹æ³•ï¼š\n\nos.getcwd() è·å–å½“å‰å·¥ä½œç›®å½•ï¼Œå³å½“å‰pythonè„šæœ¬å·¥ä½œçš„ç›®å½•è·¯å¾„\n\nos.chdir(\"dirname\")  æ”¹å˜å½“å‰è„šæœ¬å·¥ä½œç›®å½•ï¼›ç›¸å½“äºshellä¸‹cd\n\nos.curdir  è¿”å›å½“å‰ç›®å½•: ('.')\n\nos.pardir  è·å–å½“å‰ç›®å½•çš„çˆ¶ç›®å½•å­—ç¬¦ä¸²åï¼š('..')\n\nos.makedirs('dirname1/dirname2')    å¯ç”Ÿæˆå¤šå±‚é€’å½’ç›®å½•\n\nos.removedirs('dirname1')    è‹¥ç›®å½•ä¸ºç©ºï¼Œåˆ™åˆ é™¤ï¼Œå¹¶é€’å½’åˆ°ä¸Šä¸€çº§ç›®å½•ï¼Œå¦‚è‹¥ä¹Ÿä¸ºç©ºï¼Œåˆ™åˆ é™¤ï¼Œä¾æ­¤ç±»æ¨\n\nos.mkdir('dirname')    ç”Ÿæˆå•çº§ç›®å½•ï¼›ç›¸å½“äºshellä¸­mkdir dirname\n\nos.rmdir('dirname')    åˆ é™¤å•çº§ç©ºç›®å½•ï¼Œè‹¥ç›®å½•ä¸ä¸ºç©ºåˆ™æ— æ³•åˆ é™¤ï¼ŒæŠ¥é”™ï¼›ç›¸å½“äºshellä¸­rmdir dirname\n\nos.listdir('dirname')    åˆ—å‡ºæŒ‡å®šç›®å½•ä¸‹çš„æ‰€æœ‰æ–‡ä»¶å’Œå­ç›®å½•ï¼ŒåŒ…æ‹¬éšè—æ–‡ä»¶ï¼Œå¹¶ä»¥åˆ—è¡¨æ–¹å¼æ‰“å°\n\nos.remove()  åˆ é™¤ä¸€ä¸ªæ–‡ä»¶\n\nos.rename(\"oldname\",\"newname\")  é‡å‘½åæ–‡ä»¶/ç›®å½•\n\nos.stat('path/filename')  è·å–æ–‡ä»¶/ç›®å½•ä¿¡æ¯\n\nos.sep    è¾“å‡ºæ“ä½œç³»ç»Ÿç‰¹å®šçš„è·¯å¾„åˆ†éš”ç¬¦ï¼Œwinä¸‹ä¸º\"\\\\\",Linuxä¸‹ä¸º\"/\"\n\nos.linesep    è¾“å‡ºå½“å‰å¹³å°ä½¿ç”¨çš„è¡Œç»ˆæ­¢ç¬¦ï¼Œwinä¸‹ä¸º\"\\t\\n\",Linuxä¸‹ä¸º\"\\n\"\n\nos.pathsep    è¾“å‡ºç”¨äºåˆ†å‰²æ–‡ä»¶è·¯å¾„çš„å­—ç¬¦ä¸² winä¸‹ä¸º;,Linuxä¸‹ä¸º:\n\nos.name    è¾“å‡ºå­—ç¬¦ä¸²æŒ‡ç¤ºå½“å‰ä½¿ç”¨å¹³å°ã€‚win->'nt'; Linux->'posix'\n\nos.system(\"bash command\")  è¿è¡Œshellå‘½ä»¤ï¼Œç›´æ¥æ˜¾ç¤º\n\nos.environ  è·å–ç³»ç»Ÿç¯å¢ƒå˜é‡\n\nos.path.abspath(path)  è¿”å›pathè§„èŒƒåŒ–çš„ç»å¯¹è·¯å¾„\n\nos.path.split(path)  å°†pathåˆ†å‰²æˆç›®å½•å’Œæ–‡ä»¶åäºŒå…ƒç»„è¿”å›\n\nos.path.dirname(path)  è¿”å›pathçš„ç›®å½•ã€‚å…¶å®å°±æ˜¯os.path.split(path)çš„ç¬¬ä¸€ä¸ªå…ƒç´ \n\nos.path.basename(path)  è¿”å›pathæœ€åçš„æ–‡ä»¶åã€‚å¦‚ä½•pathä»¥ï¼æˆ–\\ç»“å°¾ï¼Œé‚£ä¹ˆå°±ä¼šè¿”å›ç©ºå€¼ã€‚å³os.path.split(path)çš„ç¬¬äºŒä¸ªå…ƒç´ \n\nos.path.exists(path)  å¦‚æœpathå­˜åœ¨ï¼Œè¿”å›Trueï¼›å¦‚æœpathä¸å­˜åœ¨ï¼Œè¿”å›False\n\nos.path.isabs(path)  å¦‚æœpathæ˜¯ç»å¯¹è·¯å¾„ï¼Œè¿”å›True\n\nos.path.isfile(path)  å¦‚æœpathæ˜¯ä¸€ä¸ªå­˜åœ¨çš„æ–‡ä»¶ï¼Œè¿”å›Trueã€‚å¦åˆ™è¿”å›False\n\nos.path.isdir(path)  å¦‚æœpathæ˜¯ä¸€ä¸ªå­˜åœ¨çš„ç›®å½•ï¼Œåˆ™è¿”å›Trueã€‚å¦åˆ™è¿”å›False\n\nos.path.join(path1[, path2[, ...]])  å°†å¤šä¸ªè·¯å¾„ç»„åˆåè¿”å›ï¼Œç¬¬ä¸€ä¸ªç»å¯¹è·¯å¾„ä¹‹å‰çš„å‚æ•°å°†è¢«å¿½ç•¥\n\nos.path.getatime(path)  è¿”å›pathæ‰€æŒ‡å‘çš„æ–‡ä»¶æˆ–è€…ç›®å½•çš„æœ€åå­˜å–æ—¶é—´\n\nos.path.getmtime(path)  è¿”å›pathæ‰€æŒ‡å‘çš„æ–‡ä»¶æˆ–è€…ç›®å½•çš„æœ€åä¿®æ”¹æ—¶é—´\n\nos.path.getsize(path) è¿”å›pathçš„å¤§å°\n\nos.path.normpath(os.path.join(os.path.abspath(__file__),'..','..','..'))è¡¨ç¤ºè¿”å›å½“å‰æ–‡ä»¶çš„ä¸Šä¸Šä¸Šå±‚ç›®å½•"
    },
    {
      "id": "/2020/3/27/dockerhub_2",
      "metadata": {
        "permalink": "/blog/2020/3/27/dockerhub_2",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-27-dockerhub_2.md",
        "source": "@site/blog/2020-3-27-dockerhub_2.md",
        "title": "ä»Dockerhubæ‹‰å–é•œåƒå¹¶ä¸”ä½¿ç”¨å‘½ä»¤è¿è¡Œ",
        "description": "step1: ç™»å½•è‡ªå·±çš„dockerhub,é€‰æ‹©éœ€è¦æ‹‰ä¸‹çš„é•œåƒ",
        "date": "2020-03-27T00:00:00.000Z",
        "formattedDate": "March 27, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 0.59,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dockerhub_2",
          "title": "ä»Dockerhubæ‹‰å–é•œåƒå¹¶ä¸”ä½¿ç”¨å‘½ä»¤è¿è¡Œ",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "pythonè„šæœ¬åŸºç¡€(1)-pythonä¸­osçš„å¸¸ç”¨æ–¹æ³•",
          "permalink": "/blog/2020/3/28/python"
        },
        "nextItem": {
          "title": "pushé•œåƒåˆ°è‡ªå·±çš„dockerhub",
          "permalink": "/blog/2020/3/26/dockerhub"
        }
      },
      "content": "<!--truncate-->\n## step1: ç™»å½•è‡ªå·±çš„dockerhub,é€‰æ‹©éœ€è¦æ‹‰ä¸‹çš„é•œåƒ\n\n![png](../img/dockerhub/6.png)\n\n## step2: ç‚¹å‡»é•œåƒ,ç‚¹å‡»public viewè·å–æ‹‰å–å‘½ä»¤\n\n![png](../img/dockerhub/7.png)\n\n## step3: å¤åˆ¶è·å–æ‹‰å–å‘½ä»¤\n\n![png](../img/dockerhub/8.png)\n\n## step4: åœ¨ç»ˆç«¯è¾“å…¥æ‹‰å–å‘½ä»¤\n1) æ‹‰å–é•œåƒ\n```python\ndocker pull é•œåƒåå­—\n```\n2)æŸ¥çœ‹é•œåƒ\n```python\ndocker images\n```\n![png](../img/dockerhub/9.png)\n\n## step4: è¿è¡Œé•œåƒ\n```python\ndocker run -p 127.0.0.1:80:5000/tcp flybirdgroup/classifier\n```\n![png](../img/dockerhub/10.png)\n\n## step5:æµè§ˆå™¨è¿è¡Œ\n```python\nåœ¨æµè§ˆå™¨è¾“å…¥: 127.0.0.1\n```\n![png](../img/dockerhub/11.png)\n\n## step6:å®Œç¾è¿è¡Œ\n\n![png](../img/dockerhub/12.png)"
    },
    {
      "id": "/2020/3/26/dockerhub",
      "metadata": {
        "permalink": "/blog/2020/3/26/dockerhub",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-26-dockerhub.md",
        "source": "@site/blog/2020-3-26-dockerhub.md",
        "title": "pushé•œåƒåˆ°è‡ªå·±çš„dockerhub",
        "description": "step1: ç™»å½•è‡ªå·±çš„dockerhub,ç‚¹å‡»create Repository",
        "date": "2020-03-26T00:00:00.000Z",
        "formattedDate": "March 26, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "docker",
            "permalink": "/blog/tags/docker"
          }
        ],
        "readingTime": 0.515,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "dockerhub",
          "title": "pushé•œåƒåˆ°è‡ªå·±çš„dockerhub",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "docker"
          ]
        },
        "prevItem": {
          "title": "ä»Dockerhubæ‹‰å–é•œåƒå¹¶ä¸”ä½¿ç”¨å‘½ä»¤è¿è¡Œ",
          "permalink": "/blog/2020/3/27/dockerhub_2"
        },
        "nextItem": {
          "title": "Create Virtual Linux by Google åˆ›å»ºlinuxè™šæ‹Ÿæœº",
          "permalink": "/blog/2020/3/21/createlinux"
        }
      },
      "content": "<!--truncate-->\n## step1: ç™»å½•è‡ªå·±çš„dockerhub,ç‚¹å‡»create Repository\n\n![png](../img/dockerhub/1.png)\n\n## step2: åˆ›å»ºä»“åº“repository\nå¤åˆ¶è¦ä¿å­˜çš„ä»“åº“åå­—å’Œæ¨é€å‘½ä»¤\n![png](../img/dockerhub/2.png)\n\n## step3: æŸ¥çœ‹æœ¬åœ°ä»“åº“çš„é•œåƒ\n```python\ndocker images\n```\n![png](../img/dockerhub/3.png)\n\n## step4: æŸ¥çœ‹æœ¬åœ°ä»“åº“çš„é•œåƒ\n```python\ndocker tag æœ¬åœ°é•œåƒåå­— dockerhubä»“åº“é•œåƒåå­—\ndocker tag quickstart-image flybirdgroup/helloworld:lastest\n```\n![png](../img/dockerhub/4.png)\n\n\n\n## step5: æ¨é€é•œåƒåˆ°è¿œç¨‹ä»“åº“\n```python\ndocker push flybirdgroup/helloworld:lastest\n```\n![png](../img/dockerhub/5.png)"
    },
    {
      "id": "/2020/3/21/createlinux",
      "metadata": {
        "permalink": "/blog/2020/3/21/createlinux",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-21-createlinux.md",
        "source": "@site/blog/2020-3-21-createlinux.md",
        "title": "Create Virtual Linux by Google åˆ›å»ºlinuxè™šæ‹Ÿæœº",
        "description": "Learn how to build linux system in Google Cloud Platform Docusaurus 2 alpha.",
        "date": "2020-03-21T00:00:00.000Z",
        "formattedDate": "March 21, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          },
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "linux",
            "permalink": "/blog/tags/linux"
          }
        ],
        "readingTime": 0.97,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "createlinux",
          "title": "Create Virtual Linux by Google åˆ›å»ºlinuxè™šæ‹Ÿæœº",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus",
            "google cloud",
            "linux"
          ]
        },
        "prevItem": {
          "title": "pushé•œåƒåˆ°è‡ªå·±çš„dockerhub",
          "permalink": "/blog/2020/3/26/dockerhub"
        },
        "nextItem": {
          "title": "åŒå‘æ³¨æ„åŠ›LSTMç¥ç»ç½‘ç»œ",
          "permalink": "/blog/2020/3/19/attention"
        }
      },
      "content": "Learn how to build linux system in Google Cloud Platform [**Docusaurus 2 alpha**](https://v2.docusaurus.io/).\n\n<!--truncate-->\n## step1: å»compute Engineåˆ›å»ºè™šæ‹Ÿæœºå®ä¾‹\n\n![png](../img/google/linuxs_object.png)\n\n## step2: åˆ›å»ºå®ä¾‹\n\n![png](../img/google/create_object.png)\n\n## step3: ç»™è™šæ‹Ÿæœºé…ç½®\n<img src=\"../img/google/create_object_1.png\" align=\"left\"/>\n\n## step4: \nåç§°,åŒºåŸŸ,æœºå™¨é…ç½®,ç±»å‹éƒ½æ˜¯æŒ‰éœ€è®¾ç½®, ç£ç›˜é€‰æ‹©Linux 9,é˜²ç«å¢™é€‰æ‹©httpæµé‡\n\n![png](../img/google/create_object_2.png)\n\n\n\n## step 5: \n\n### 1) æˆ‘ä»¬å¯ä»¥çœ‹åˆ°æœ‰å¤–éƒ¨ip,æˆ‘ä»¬è¦è®°ä½\n   \n### 2) æˆ‘ä»¬å¯ä»¥ç›´æ¥é€‰æ‹©åœ¨æµè§ˆå™¨çª—å£ä¸­æ‰“å¼€,æ¥è¿›å…¥è™šæ‹Ÿæœº\n   \n<img src=\"../img/google/create_object_3.png\" align=\"left\"/>\n\n![png](../img/google/virtual_linux.png)\n\n\n# ä½¿ç”¨ç»ˆç«¯è¿æ¥åˆ°è™šæ‹Ÿlinux\n## step 6: æ·»åŠ æœ¬åœ°å¯†é’¥åˆ°å…ƒæ•°æ®ä¸­\n\né¦–å…ˆå»å…ƒæ•°æ®, ç„¶åé€‰æ‹©SSHå¯†é’¥,ç‚¹å‡»ä¿®æ”¹æŒ‰é’®,æ·»åŠ æœ¬åœ°çš„SSHå¯†é’¥åˆ°æ¡†ä¸­\n![png](../img/google/ssh.png)\n\n## step 7: ä½¿ç”¨æœ¬åœ°ç»ˆç«¯è¿æ¥\n![png](../img/google/linxus1.png)"
    },
    {
      "id": "/2020/3/19/attention",
      "metadata": {
        "permalink": "/blog/2020/3/19/attention",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-19-attention.md",
        "source": "@site/blog/2020-3-19-attention.md",
        "title": "åŒå‘æ³¨æ„åŠ›LSTMç¥ç»ç½‘ç»œ",
        "description": "åŸç†è®²è§£",
        "date": "2020-03-19T00:00:00.000Z",
        "formattedDate": "March 19, 2020",
        "tags": [
          {
            "label": "CNN",
            "permalink": "/blog/tags/cnn"
          },
          {
            "label": "classifier",
            "permalink": "/blog/tags/classifier"
          },
          {
            "label": "textCNN",
            "permalink": "/blog/tags/text-cnn"
          }
        ],
        "readingTime": 9.09,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "Attention",
          "title": "åŒå‘æ³¨æ„åŠ›LSTMç¥ç»ç½‘ç»œ",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "CNN",
            "classifier",
            "textCNN"
          ]
        },
        "prevItem": {
          "title": "Create Virtual Linux by Google åˆ›å»ºlinuxè™šæ‹Ÿæœº",
          "permalink": "/blog/2020/3/21/createlinux"
        },
        "nextItem": {
          "title": "word2vecè¯¦è§£",
          "permalink": "/blog/2020/03/18/word2vec"
        }
      },
      "content": "## åŸç†è®²è§£\n\nTextAttBiRNNæ˜¯åœ¨åŒå‘LSTMæ–‡æœ¬åˆ†ç±»æ¨¡å‹çš„åŸºç¡€ä¸Šæ”¹è¿›çš„ï¼Œä¸»è¦æ˜¯å¼•å…¥äº†æ³¨æ„åŠ›æœºåˆ¶ï¼ˆAttentionï¼‰ã€‚å¯¹äºåŒå‘LSTMç¼–ç å¾—åˆ°çš„è¡¨å¾å‘é‡ï¼Œæ¨¡å‹èƒ½å¤Ÿé€šè¿‡æ³¨æ„åŠ›æœºåˆ¶ï¼Œå…³æ³¨ä¸å†³ç­–æœ€ç›¸å…³çš„ä¿¡æ¯ã€‚å…¶ä¸­æ³¨æ„åŠ›æœºåˆ¶æœ€å…ˆåœ¨è®ºæ–‡ [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/pdf/1409.0473.pdf) ä¸­è¢«æå‡ºï¼Œè€Œæ­¤å¤„å¯¹äºæ³¨æ„åŠ›æœºåˆ¶çš„å®ç°å‚ç…§äº†è®ºæ–‡ [Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems](https://arxiv.org/pdf/1512.08756.pdf)ã€‚\n<!--truncate-->\næ³¨æ„åŠ›æœºåˆ¶å‚è€ƒ\n- [æ·±åº¦å­¦ä¹ ä¸­çš„æ³¨æ„åŠ›æ¨¡å‹](https://zhuanlan.zhihu.com/p/37601161)\n- [æ·±åº¦å­¦ä¹ æ³¨æ„åŠ›æœºåˆ¶](https://zhuanlan.zhihu.com/p/53036028)\n\nè¯·æ³¨æ„,è¿™é‡Œçš„æ³¨æ„åŠ›æœºåˆ¶ä¸bertä¸­transformerçš„æ³¨æ„åŠ›æœºåˆ¶ä¸åŒ,transformerä¼šæ›´åŠ å¤æ‚,å¤§å®¶å¯ä»¥å‚è€ƒæˆ‘å…³äº[transformer](https://github.com/weijiang2009/URun.ResearchPrototype/tree/dev/People/Xiaoxian/NLP%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86%E6%95%B4%E7%90%86/Transformer%E7%AC%94%E8%AE%B0)\n\nIn the paper [Feed-Forward Networks with Attention Can Solve Some Long-Term Memory Problems](https://arxiv.org/pdf/1512.08756.pdf), the **feed forward attention** is simplified as follows,\n![png](../img/attention/FeedForwardAttention.png)\n\nFunction a, a learnable function, is recognized as a feed forward network. In this formulation, attention can be seen as producing a fixed-length embedding c of the input sequence by computing an adaptive weighted average of the state sequence h.\n\ncå°±æ˜¯æ³¨æ„åŠ›,alphaå°±æ˜¯æƒé‡,hå°±æ˜¯éšå«çŠ¶æ€,alphaé€šè¿‡softmaxè®¡ç®—,scoreå°±æ˜¯é€šè¿‡hè®¡ç®—çš„,hå°±æ˜¯å½“å‰çŠ¶æ€è¾“å…¥çš„è¯è¯­å’Œä¸Šä¸€éšå«çŠ¶æ€ht-1è®¡ç®—è€Œæ¥çš„\n\n\n![png](../img/attention/FeedForwardAttetion_fomular.png)\n\n## ç»†çœ‹ç»“æ„\nTextAttBiRNN çš„ç½‘ç»œç»“æ„\n![png](../img/attention/text-attn-birnn.png)\n\n### è¾“å…¥å±‚\nè¾“å…¥å±‚æˆ‘ä»¬å¯ä»¥å®šä¹‰ä¸ºå¥å­è¾“å…¥é•¿åº¦ï¼Œæ¯ä¸ªè¯ç»è¿‡ä¸€ä¸ªembedding_dim=50çš„embeddingçŸ©é˜µï¼Œæœ€ç»ˆè¾“å‡º400Ã—50çš„è¡¨ç¤ºçŸ©é˜µ.å‡è®¾ä¸€ä¸ªå¥å­æœ‰400ä¸ªè¯è¯­\n\n### Bi-LSTM\nBi-LSTMå±‚ä½œä¸ºä¸€ç§ç‰¹å¾ç¼–ç å±‚ï¼Œè¿™å±‚å¯ä»¥æå–æ¯ä¸ªè¯è¯­çš„ä¸Šä¸‹æ–‡ç‰¹å¾ï¼Œç„¶åå°†åŒå‘çš„ç‰¹å¾è¿›è¡Œæ‹¼æ¥ï¼Œç„¶åä¾æ—§å°†æ¯ä¸ªè¯è¯­çš„ç‰¹å¾è¿›è¡Œè¾“å‡ºï¼Œå› æ­¤è¾“å‡ºä¸º400Ã—256çš„ç‰¹å¾çŸ©é˜µ\n\nAttentionå±‚\nAttentionå±‚å¯¹è¿™ä¸ªç½‘ç»œä¸­å¯¹æ¯ä¸ªè¯è¯­è¿›è¡Œäº†åŠ æƒæ±‚å’Œï¼Œè¿™ä¸ªæƒé‡æ˜¯é€šè¿‡è®­ç»ƒä¸æ–­è®­ç»ƒå‡ºæ¥çš„ï¼Œè¿™å±‚æˆ‘ä»¬çš„è¾“å…¥xä¸º400Ã—256ï¼Œæˆ‘ä»¬åˆå§‹åŒ–æƒé‡çŸ©é˜µWä¸º256Ã—1ç»´ï¼Œç„¶åå¯¹xä¸Wè¿›è¡Œç‚¹ä¹˜ã€å½’ä¸€åŒ–ï¼ˆå…¬å¼çš„å‰ä¸¤ä¸ªï¼‰ï¼Œè¿™æ ·å°±å¯ä»¥å¾—åˆ°400Ã—1çš„çŸ©é˜µaï¼Œè¿™ä¸ªçŸ©é˜µä»£è¡¨çš„æ˜¯æ¯ä¸ªè¯å¯¹åº”çš„æƒé‡ï¼Œæƒé‡å¤§çš„è¯ä»£è¡¨æ³¨æ„åŠ›å¤§çš„ï¼Œè¿™ä¸ªè¯çš„è´¡çŒ®ç¨‹åº¦æ›´å¤§ï¼Œæœ€åå¯¹æ¯ä¸ªè¯è¯­è¿›è¡ŒåŠ æƒå¹³å‡ï¼ŒaTä¸xè¿›è¡Œç‚¹ä¹˜ï¼Œå¾—åˆ°1Ã—256ï¼Œè¿™æ˜¯æœ€ç»ˆåŠ æƒå¹³å‡åè¾“å‡ºçš„æ€»ç‰¹å¾å‘é‡ã€‚\n\nè¾“å‡ºå±‚\nä¸æˆ‘ä¹‹å‰textCNNåšä¸­æ–‡æ–°é—»åˆ†ç±»å®éªŒå·®ä¸å¤šï¼Œä½¿ç”¨å…¨è¿æ¥å±‚ï¼Œsoftmaxä½œä¸ºæ¿€æ´»å‡½æ•°è¿›è¡Œè¾“å‡ºã€‚\n\ndemoé¡¹ç›®: [æƒ…æ„Ÿåˆ†æ](https://github.com/flybirdgroup/sentiment_analysis)\n# å¯¼å…¥å·¥å…·åŒ…\n```python\nimport pandas as pd\nimport jieba_fast as jieba\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import initializers,regularizers,constraints\nfrom tensorflow.keras import Input,Model,models\nfrom tensorflow.keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\nfrom tensorflow.keras import Input,Model\nfrom tensorflow.keras.layers import Embedding,Dropout,Dense,Bidirectional,LSTM\nfrom tensorflow.keras.models import load_model\nfrom elmoformanylangs import Embedder\nimport numpy as np\nfrom tensorflow.keras.utils import plot_model\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom pandarallel import pandarallel\npandarallel.initialize()\nfrom tensorflow.keras.preprocessing.text import Tokenizer\n```\n\n# è¯»å–æ•°æ®\n\n```python\ndf = pd.read_csv('./data/sentiment_analysis_data.csv',sep='\t')\ndf\n```\n![png](../img/attention/1.png)\n\n## æ‰“ä¹±æ ·æœ¬\n```python\ndf = df.sample(frac=1).reset_index(drop=True)\n```\n\n# å»ºæ¨¡æ€è·¯\n\n## æŠ€æœ¯è·¯çº¿\nåˆ†ä¸¤ç§ç§æƒ…å†µ,å¥½è¯„,è´Ÿè¯„,ä¸­è¯„\nè®¡ç®—è·¯çº¿:\n1 ä½¿ç”¨TextCNNå¯¹æ¯ä¸ªå¥å­ç±»ä¼¼n-gramå¤„ç†\n\n2 ä½¿ç”¨RNN\n\n3 å¯ä»¥å°è¯•ä½¿ç”¨attentionæœºåˆ¶åšæƒ…æ„Ÿåˆ¤æ–­,å¯¹è¯è¿›è¡Œword2vec,æˆ–è€…elmo embedding,å¯æ·»åŠ bi-lstmè·å–ä¸Šä¸‹æ–‡ä¿¡æ¯\n\n[AttentionåŸç†è¯·å‚è€ƒ](https://www.xn--gmqr38alogxt2a.net/blog/Attention)\n\n\n## æŸ¥çœ‹æ˜¯å¦æœ‰ç¼ºå¤±å€¼\n\n```python\ndf.info()\n```\n\n## åˆ†ææ ‡ç­¾æ•°æ®æƒ…å†µ\n\n```python\nlabel_dict = {'-1':'è´Ÿè¯„','0':'ä¸­è¯„','1':'æ­£è¯„'}\n\ndf['label']=df['label'].apply(lambda x: label_dict[str(x)] )\n```\n\n```python\ndf.tail()\n```\n![png](../img/attention/2.png)\n\n### æŸ¥çœ‹æ¯ä¸ªæ–‡æœ¬çš„é•¿åº¦\n\n```python\ndf['txt_num'] = df['txt'].agg(lambda x: len(x))\n```\n\n```python\ndf.agg({'txt_num':'mean'})\n```\n## å¾—åˆ°å¥å­é•¿åº¦\n\næ‰€ä»¥æ ¹æ®æ•°æ®,å¾—å‡ºæˆ‘ä»¬ä¼šè®¾ç½®maxlen= 40å·¦å³\n\n## jiebaåˆ†è¯\n\n\n```python\nfrom pandarallel import pandarallel\npandarallel.initialize()\n```\n\n## è·å–åœç”¨è¯å’Œè®¾ç«‹åˆ†è¯å‡½æ•°\n\n\n```python\nstopwords = pd.read_csv('./data/stopwords.txt',sep='\\t',index_col=False,quoting=3,encoding='utf-8')\n```\n\n\n```python\ndef split_words(X):\n    result = [i for i in jieba.lcut(X) if i not in stopwords]\n    result = ' '.join(result)\n    return result\n```\n\n\n```python\ndf['txt']=df['txt'].parallel_apply(split_words)\n```\n\n## å»ºç«‹æ¨¡å‹\n\n### Attentionç½‘ç»œ\n```python\nclass Attention(Layer):\n    def __init__(self, step_dim,\n                 W_regularizer=None, b_regularizer=None,\n                 W_constraint=None, b_constraint=None,\n                 bias=True, **kwargs):\n        self.supports_masking = True\n        self.init = initializers.get('glorot_uniform')\n\n        self.W_regularizer = regularizers.get(W_regularizer)\n        self.b_regularizer = regularizers.get(b_regularizer)\n\n        self.W_constraint = constraints.get(W_constraint)\n        self.b_constraint = constraints.get(b_constraint)\n\n        self.bias = bias\n        self.step_dim = step_dim\n        self.features_dim = 0\n\n        super(Attention, self).__init__(**kwargs)\n\n    def build(self, input_shape):\n        assert len(input_shape) == 3\n\n        self.W = self.add_weight(shape=(input_shape[-1],),\n                                 initializer=self.init,\n                                 name='{}_W'.format(self.name),\n                                 regularizer=self.W_regularizer,\n                                 constraint=self.W_constraint)\n        self.features_dim = input_shape[-1]\n\n        if self.bias:\n            self.b = self.add_weight(shape=(input_shape[1],),\n                                     initializer='zero',\n                                     name='{}_b'.format(self.name),\n                                     regularizer=self.b_regularizer,\n                                     constraint=self.b_constraint)\n        else:\n            self.b = None\n\n        self.built = True\n    \n    def compute_mask(self,input,input_mask=None):\n        #do not pass the mask to the next layers\n        return None\n    \n    def call(self,x,mask=None):\n        features_dim = self.features_dim\n        step_dim = self.step_dim\n        \n        #K.reshape(x,(-1,features_dim))é‡Œé¢-1å¯ä»¥æƒ³è±¡æˆä¸€è¡Œ,features_dimå˜æˆä¸€è¡Œæœ‰features_dimç»´çŸ©é˜µ(1*dimç»´),K.reshape(self.W, (features_dim, 1)),å˜æˆçŸ©é˜µ(dimç»´*self.W)features_dimè¡Œå’Œ1ç»´\n        e = K.reshape(K.dot(K.reshape(x, (-1, features_dim)), K.reshape(self.W, (features_dim, 1))), (-1, step_dim))  \n        # è¿™é‡Œä¹Ÿå¯ä»¥ç”¨å¦å¤–ä¸€ç§è¡¨ç¤ºæ–¹å¼\n#         e = K.reshape(K.dot(K.reshape(x,(1,-1)),K.reshape(self.W,(-1,1))),(-1,1))\n        # å…¶å®å°±æ˜¯å…¨è¿æ¥çš„çŸ©é˜µç›¸ä¹˜ e = K.dot(x, self.W)\n        if self.bias:\n            e += self.b\n        e = K.tanh(e) # æ¿€æ´»å‡½æ•°\n        a = K.exp(e) # å»æŒ‡æ•°\n        # apply mask after the exp. will be re-normalized next\n        if mask is not None:\n            # cast the mask to floatX to avoid float64 upcasting in theano\n            a *= K.cast(mask, K.floatx()) # è½¬æ¢æˆfloatxç±»å‹\n        # in some cases especially in the early stages of training the sum may be almost zero\n        # and this results in NaN's. A workaround is to add a very small positive number Îµ to the sum.\n        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx()) # softmaxå‡½æ•°,å¾—åˆ°æƒé‡çŸ©é˜µ\n        a = K.expand_dims(a) # å˜æˆ(dim,1),è¿™æ ·å¯ä»¥ä¸xè¿›è¡ŒåŠ æƒå°±å’Œå¾—åˆ°context\n        \n        c = K.sum(a*x,axis=1) #æƒé‡ä¸hiddenä¿¡æ¯åŠ æƒå°±å’Œå¾—åˆ°context,ä¹Ÿå°±æ˜¯æˆ‘ä»¬çš„æ³¨æ„åŠ›\n        return c\n    def compute_output_shape(self, input_shape):\n        return input_shape[0], self.features_dim  \n    \n    def get_config(self):\n        config = {\n                \"step_dim\":self.step_dim,\n                 \"W_regularizer\":self.W_regularizer, \"b_regularizer\":self.b_regularizer,\n                 \"W_constraint\":self.W_constraint, \"b_constraint\":self.b_constraint,\n                 \"bias\":self.bias}\n        base_config = super(Attention, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n```\n\n### ç½‘ç»œç»“æ„\n\n### elmoå±‚\nå“ˆå·¥å¤§å¼€å‘çš„åŠ¨æ€è¯å‘é‡[elmo](https://github.com/HIT-SCIR/ELMoForManyLangs)\n\nelmoåŸç†å¯å‚è€ƒ[é“¾æ¥](https://www.jianshu.com/p/2fff53696fac)\n\n```python\ne = Embedder('./zhs.model/')\n```\n\n### åˆ›å»ºpaddingå‡½æ•°\nè¶…è¿‡å¥å­é•¿åº¦å°±æˆªå–,ä¸å¤Ÿå°±è¡¥ç©º\n\n```python\ndef pad_sent(x, max_len):\n    if len(x)>max_len:\n        return x[:max_len]\n    else:\n        return x+['']*(max_len-len(x))\n```\n### åˆ›å»ºæ‰¹é‡ç”Ÿæˆå™¨\n\n```python\ndef batch_generator(x, y, batch_size=64):\n    n_batches_per_epoch = len(x)//batch_size\n    for i in range(n_batches_per_epoch):\n        x_batch = np.array(e.sents2elmo([pad_sent(sent,40) for sent in x[batch_size*i:batch_size*(i+1)]]))\n        y_batch = y[batch_size*i:batch_size*(i+1),:]\n        yield x_batch, np.array(y_batch)\n```\n\n```python\ndef predict_generator(x, batch_size=1): #é¢„æµ‹\n    n_batches_per_epoch = len(x)//batch_size\n    for i in range(n_batches_per_epoch):\n        x_batch = np.array(e.sents2elmo([pad_sent(sent,40) for sent in x[batch_size*i:batch_size*(i+1)]]))\n        yield x_batch\n```\n\n### æ„å»ºELMOTextBiRNNç½‘ç»œç»“æ„\n\n\n```python\nclass ELMOTextBiRNN(object):\n    def __init__(self,maxlen,max_features,embedding_dims,class_num=3,last_activation='softmax'):\n        self.maxlen = maxlen\n        self.max_features = max_features\n        self.embedding_dims = embedding_dims\n        self.class_num = class_num\n        self.last_activation = last_activation\n#     def get_model(self):\n#         embedding = Input((self.maxlen, self.embedding_dims,)) # è¾“å…¥é¢„è®­ç»ƒçš„è¯å‘é‡\n#         convs = [] \n#         for kernel_size in [3,4,5]: #è®¾å®šfilterå¤§å°\n#             c = Conv1D(128,kernel_size,activation='relu')(embedding)\n#             c = GlobalMaxPooling1D()(c)\n#             convs.append(c)\n#         x = Concatenate()(convs)\n#         output = Dense(self.class_num,activation=self.last_activation)(x)\n#         model = Model(inputs=embedding,outputs=output)\n#         return model\n    \n    def get_model(self):\n        embedding = Input((self.maxlen,self.embedding_dims,))\n        x = Bidirectional(LSTM(128,return_sequences=True))(embedding)\n        x = Attention((self.maxlen))(x)\n        output = Dense(self.class_num,activation=self.last_activation)(x)\n        model = Model(embedding,output)\n        return model        \n```\n\n```python\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(df['txt'].values)\nvocab = tokenizer.word_index\nlen(vocab)+1\n```\n\n### è®¾ç½®æ¨¡å‹å‚æ•°\n\n\n```python\nmaxlen = 40\nbatch_size = 32\nmax_features = len(vocab)+1\nembedding_dims = 1024\nepochs = 9\n```\n### è·å–æ¨¡å‹\n```python\nmodel = ELMOTextBiRNN(maxlen,max_features,embedding_dims).get_model()\n```\n\n```python\nplot_model(model,show_shapes=True)\n```\n![png](../img/attention/output_47_0.png)\n\n## åˆ’åˆ†è®­ç»ƒé›†,æµ‹è¯•é›†\n\n\n```python\nx_train,x_test,y_train,y_test = train_test_split(df['txt'].values,df['label'])\n```\n\n## å»ºç«‹è¯å…¸,è¯è¯­idåŒ–,æ ‡ç­¾ç‹¬çƒ­ç¼–ç \n\n```python\ndef encode_category_one_hot(y_train,y_test): \n    from tensorflow.keras.utils import to_categorical\n    set(y_train)\n    categories = set(y_train)\n    categories\n    cat_to_id = dict(zip(categories, range(len(categories))))\n    y_train_id = [cat_to_id[i] for i in y_train]\n    y_test_id = [cat_to_id[i] for i in y_test]\n    cat_to_id\n    y_train_one_hot = to_categorical(y_train_id)\n    y_test_one_hot = to_categorical(y_test_id)\n    return y_train_one_hot,y_test_one_hot,cat_to_id\n```\n\n\n```python\ny_train_one_hot,y_test_one_hot,cat_to_id = encode_category_one_hot(y_train,y_test)\n```\n\n\n```python\nx_train = sentences_list(x_train)\nx_test = sentences_list(x_test)\n```\n\n## è®¾ç«‹æ—©åœ\n\n\n```python\nmy_callbacks = [ModelCheckpoint('.ELMO_birnn_model.h5'),\n                EarlyStopping(monitor='accuracy',patience=2,mode='max')]\n```\n\n\n```python\nmodel = ELMOTextBiRNN(40,max_features,1024).get_model()\nmodel.compile('adam','categorical_crossentropy',metrics=['accuracy'])\n```\n\n## æµ‹è¯•æ¨¡å‹\n\n\n```python\ntext = 'ä»Šå¤© å¤©æ°” å¾ˆ æ™´æœ— å¤„å¤„ æœ‰ é˜³å…‰ æœ‰ é˜³å…‰'\nsentence = [['%s'%text]]\n```\n\n\n```python\ncat_to_id\n```\n  {'è´Ÿè¯„': 0, 'æ­£è¯„': 1, 'ä¸­è¯„': 2}\n\n```python\nsentence\n```\n[['ä»Šå¤© å¤©æ°” å¾ˆ æ™´æœ— å¤„å¤„ æœ‰ é˜³å…‰ æœ‰ é˜³å…‰']]\n\n\n```python\nmodel.predict_generator(predict_generator(sentence, batch_size=1),steps=1)\n```\narray([[0.21561107, 0.600974  , 0.18341494]], dtype=float32)"
    },
    {
      "id": "/2020/03/18/word2vec",
      "metadata": {
        "permalink": "/blog/2020/03/18/word2vec",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-03-18-word2vec.md",
        "source": "@site/blog/2020-03-18-word2vec.md",
        "title": "word2vecè¯¦è§£",
        "description": "ä»€ä¹ˆæ˜¯Word2Vecå’ŒEmbeddingsï¼Ÿ",
        "date": "2020-03-18T00:00:00.000Z",
        "formattedDate": "March 18, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 31.345,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "elmo",
          "title": "word2vecè¯¦è§£",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "åŒå‘æ³¨æ„åŠ›LSTMç¥ç»ç½‘ç»œ",
          "permalink": "/blog/2020/3/19/attention"
        },
        "nextItem": {
          "title": "ä½¿ç”¨Google Cloud SDKæ¥é…ç½®Google App Engine",
          "permalink": "/blog/2020/3/18/google_cloud"
        }
      },
      "content": "## ä»€ä¹ˆæ˜¯Word2Vecå’ŒEmbeddingsï¼Ÿ\næˆ‘ä»¬å¯ä»¥ç®€å•è®¤ä¸ºWord2Vecå°±æ˜¯æŠŠè¯è¯­å‘é‡åŒ–ï¼Œä¹Ÿå°±æ˜¯æ¯ä¸ªæˆ‘ä»¬å¯¹äºä¸€ä¸ªè¯­æ–™åº“è¿›è¡Œå­¦ä¹ åï¼Œæ¯ä¸ªå•è¯éƒ½æœ‰å¯¹åº”çš„åæ ‡ä½ç½®ï¼Œè¿™æ—¶å€™ï¼Œé€šè¿‡æ¯ä¸ªå•è¯çš„åæ ‡ä½ç½®ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä½™å¼¦å®šç†æ¨å¯¼å‡ºä¸¤ä¸ªè¯è¯­ï¼ŒçŸ­è¯­æˆ–è€…å¥å­çš„ç›¸ä¼¼ç¨‹åº¦ã€‚è¿™é‡Œå¯ä»¥å‚è€ƒæˆ‘å‚ä¸çš„äº‘æ¶¦å¤§æ•°æ®èˆ†æƒ…ç³»ç»Ÿçš„è¯äº‘é¡¹ç›®ï¼Œ[å…³é”®è¯åŒ¹é…](https://github.com/weijiang2009/URun.ResearchPrototype/tree/dev/Projects/WordCloud/src/words_similarity_xiaoxian)\n![jpeg](../img/word2vec.jpeg)\n<!--truncate-->\né‚£ä¹ˆå®ƒæ˜¯å¦‚ä½•å¸®åŠ©æˆ‘ä»¬åšè‡ªç„¶è¯­è¨€å¤„ç†å‘¢ï¼ŸWord2Vecå…¶å®å°±æ˜¯é€šè¿‡å­¦ä¹ æ–‡æœ¬æ¥ç”¨è¯å‘é‡çš„æ–¹å¼è¡¨å¾è¯çš„è¯­ä¹‰ä¿¡æ¯ï¼Œå³é€šè¿‡ä¸€ä¸ªåµŒå…¥ç©ºé—´ä½¿å¾—è¯­ä¹‰ä¸Šç›¸ä¼¼çš„å•è¯åœ¨è¯¥ç©ºé—´å†…è·ç¦»å¾ˆè¿‘ã€‚\nEmbeddingå…¶å®å°±æ˜¯ä¸€ä¸ªæ˜ å°„ï¼Œå°†å•è¯ä»åŸå…ˆæ‰€å±çš„ç©ºé—´æ˜ å°„åˆ°æ–°çš„å¤šç»´ç©ºé—´ä¸­ï¼Œä¹Ÿå°±æ˜¯æŠŠåŸå…ˆè¯æ‰€åœ¨ç©ºé—´åµŒå…¥åˆ°ä¸€ä¸ªæ–°çš„ç©ºé—´ä¸­å»ã€‚\n\næˆ‘ä»¬ä»ç›´è§‚è§’åº¦ä¸Šæ¥ç†è§£ä¸€ä¸‹ï¼Œcatè¿™ä¸ªå•è¯å’Œkittenå±äºè¯­ä¹‰ä¸Šå¾ˆç›¸è¿‘çš„è¯ï¼Œè€Œdogå’Œkittenåˆ™ä¸æ˜¯é‚£ä¹ˆç›¸è¿‘ï¼Œiphoneè¿™ä¸ªå•è¯å’Œkittençš„è¯­ä¹‰å°±å·®çš„æ›´è¿œäº†ã€‚é€šè¿‡å¯¹è¯æ±‡è¡¨ä¸­å•è¯è¿›è¡Œè¿™ç§æ•°å€¼è¡¨ç¤ºæ–¹å¼çš„å­¦ä¹ ï¼ˆä¹Ÿå°±æ˜¯å°†å•è¯è½¬æ¢ä¸ºè¯å‘é‡ï¼‰ï¼Œèƒ½å¤Ÿè®©æˆ‘ä»¬åŸºäºè¿™æ ·çš„æ•°å€¼è¿›è¡Œå‘é‡åŒ–çš„æ“ä½œä»è€Œå¾—åˆ°ä¸€äº›æœ‰è¶£çš„ç»“è®ºã€‚æ¯”å¦‚è¯´ï¼Œå¦‚æœæˆ‘ä»¬å¯¹è¯å‘é‡kittenã€catä»¥åŠdogæ‰§è¡Œè¿™æ ·çš„æ“ä½œï¼škitten - cat + dogï¼Œé‚£ä¹ˆæœ€ç»ˆå¾—åˆ°çš„åµŒå…¥å‘é‡ï¼ˆembedded vectorï¼‰å°†ä¸puppyè¿™ä¸ªè¯å‘é‡ååˆ†ç›¸è¿‘ã€‚\n\n## æ¨¡å‹\n\nWord2Vecæ¨¡å‹ä¸­ï¼Œä¸»è¦æœ‰Skip-Gramå’ŒCBOWä¸¤ç§æ¨¡å‹ï¼Œä»ç›´è§‚ä¸Šç†è§£ï¼ŒSkip-Gramæ˜¯ç»™å®šinput wordæ¥é¢„æµ‹ä¸Šä¸‹æ–‡ã€‚è€ŒCBOWæ˜¯ç»™å®šä¸Šä¸‹æ–‡ï¼Œæ¥é¢„æµ‹input wordã€‚æœ¬ç¯‡æ–‡ç« ä»…è®²è§£Skip-Gramæ¨¡å‹ã€‚\n\nè¿™é‡Œå¯ä»¥æœ‰å‡ ç¯‡å¤§ç¥çš„æ–‡ç« å¯ä»¥å‚çœ‹:\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b306c8b3b1.png?imageMogr2/format/jpg/quality/90)\n\nSkip-Gramæ¨¡å‹çš„åŸºç¡€å½¢å¼éå¸¸ç®€å•ï¼Œä¸ºäº†æ›´æ¸…æ¥šåœ°è§£é‡Šæ¨¡å‹ï¼Œæˆ‘ä»¬å…ˆä»æœ€ä¸€èˆ¬çš„åŸºç¡€æ¨¡å‹æ¥çœ‹Word2Vecï¼ˆä¸‹æ–‡ä¸­æ‰€æœ‰çš„Word2Vecéƒ½æ˜¯æŒ‡Skip-Gramæ¨¡å‹ï¼‰ã€‚\n\nWord2Vecæ¨¡å‹å®é™…ä¸Šåˆ†ä¸ºäº†ä¸¤ä¸ªéƒ¨åˆ†ï¼Œ**ç¬¬ä¸€éƒ¨åˆ†ä¸ºå»ºç«‹æ¨¡å‹ï¼Œç¬¬äºŒéƒ¨åˆ†æ˜¯é€šè¿‡æ¨¡å‹è·å–åµŒå…¥è¯å‘é‡**ã€‚Word2Vecçš„æ•´ä¸ªå»ºæ¨¡è¿‡ç¨‹å®é™…ä¸Šä¸è‡ªç¼–ç å™¨ï¼ˆauto-encoderï¼‰çš„æ€æƒ³å¾ˆç›¸ä¼¼ï¼Œå³å…ˆåŸºäºè®­ç»ƒæ•°æ®æ„å»ºä¸€ä¸ªç¥ç»ç½‘ç»œï¼Œå½“è¿™ä¸ªæ¨¡å‹è®­ç»ƒå¥½ä»¥åï¼Œæˆ‘ä»¬å¹¶ä¸ä¼šç”¨è¿™ä¸ªè®­ç»ƒå¥½çš„æ¨¡å‹å¤„ç†æ–°çš„ä»»åŠ¡ï¼Œæˆ‘ä»¬çœŸæ­£éœ€è¦çš„æ˜¯è¿™ä¸ªæ¨¡å‹é€šè¿‡è®­ç»ƒæ•°æ®æ‰€å­¦å¾—çš„å‚æ•°ï¼Œä¾‹å¦‚éšå±‚çš„æƒé‡çŸ©é˜µâ€”â€”åé¢æˆ‘ä»¬å°†ä¼šçœ‹åˆ°è¿™äº›æƒé‡åœ¨Word2Vecä¸­å®é™…ä¸Šå°±æ˜¯æˆ‘ä»¬è¯•å›¾å»å­¦ä¹ çš„â€œword vectorsâ€ã€‚åŸºäºè®­ç»ƒæ•°æ®å»ºæ¨¡çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬ç»™å®ƒä¸€ä¸ªåå­—å«â€œFake Taskâ€ï¼Œæ„å‘³ç€å»ºæ¨¡å¹¶ä¸æ˜¯æˆ‘ä»¬æœ€ç»ˆçš„ç›®çš„ã€‚\n\n> ä¸Šé¢æåˆ°çš„è¿™ç§æ–¹æ³•å®é™…ä¸Šä¼šåœ¨æ— ç›‘ç£ç‰¹å¾å­¦ä¹ ï¼ˆunsupervised feature learningï¼‰ä¸­è§åˆ°ï¼Œæœ€å¸¸è§çš„å°±æ˜¯è‡ªç¼–ç å™¨ï¼ˆauto-encoderï¼‰ï¼šé€šè¿‡åœ¨éšå±‚å°†è¾“å…¥è¿›è¡Œç¼–ç å‹ç¼©ï¼Œç»§è€Œåœ¨è¾“å‡ºå±‚å°†æ•°æ®è§£ç æ¢å¤åˆå§‹çŠ¶æ€ï¼Œè®­ç»ƒå®Œæˆåï¼Œæˆ‘ä»¬ä¼šå°†è¾“å‡ºå±‚â€œç æ‰â€ï¼Œä»…ä¿ç•™éšå±‚ã€‚\n\n## The Fake Task\n\næˆ‘ä»¬åœ¨ä¸Šé¢æåˆ°ï¼Œè®­ç»ƒæ¨¡å‹çš„çœŸæ­£ç›®çš„æ˜¯è·å¾—æ¨¡å‹åŸºäºè®­ç»ƒæ•°æ®å­¦å¾—çš„éšå±‚æƒé‡ã€‚ä¸ºäº†å¾—åˆ°è¿™äº›æƒé‡ï¼Œæˆ‘ä»¬é¦–å…ˆè¦æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç¥ç»ç½‘ç»œä½œä¸ºæˆ‘ä»¬çš„â€œFake Taskâ€ï¼Œåé¢å†è¿”å›æ¥çœ‹é€šè¿‡â€œFake Taskâ€æˆ‘ä»¬å¦‚ä½•é—´æ¥åœ°å¾—åˆ°è¿™äº›è¯å‘é‡ã€‚\n\næ¥ä¸‹æ¥æˆ‘ä»¬æ¥çœ‹çœ‹å¦‚ä½•è®­ç»ƒæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œã€‚å‡å¦‚æˆ‘ä»¬æœ‰ä¸€ä¸ªå¥å­**â€œThe dog barked at the mailmanâ€**ã€‚\n\n- é¦–å…ˆæˆ‘ä»¬é€‰å¥å­ä¸­é—´çš„ä¸€ä¸ªè¯ä½œä¸ºæˆ‘ä»¬çš„è¾“å…¥è¯ï¼Œä¾‹å¦‚æˆ‘ä»¬é€‰å–â€œdogâ€ä½œä¸ºinput wordï¼›\n- æœ‰äº†input wordä»¥åï¼Œæˆ‘ä»¬å†å®šä¹‰ä¸€ä¸ªå«åšskip_windowçš„å‚æ•°ï¼Œå®ƒä»£è¡¨ç€æˆ‘ä»¬ä»å½“å‰input wordçš„ä¸€ä¾§ï¼ˆå·¦è¾¹æˆ–å³è¾¹ï¼‰é€‰å–è¯çš„æ•°é‡ã€‚å¦‚æœæˆ‘ä»¬è®¾ç½®skip_window=2ï¼Œé‚£ä¹ˆæˆ‘ä»¬æœ€ç»ˆè·å¾—çª—å£ä¸­çš„è¯ï¼ˆåŒ…æ‹¬input wordåœ¨å†…ï¼‰å°±æ˜¯**['The', 'dog'ï¼Œ'barked', 'at']**ã€‚skip_window=2ä»£è¡¨ç€é€‰å–å·¦input wordå·¦ä¾§2ä¸ªè¯å’Œå³ä¾§2ä¸ªè¯è¿›å…¥æˆ‘ä»¬çš„çª—å£ï¼Œæ‰€ä»¥æ•´ä¸ªçª—å£å¤§å°span=2x2=4ã€‚å¦ä¸€ä¸ªå‚æ•°å«num_skipsï¼Œå®ƒä»£è¡¨ç€æˆ‘ä»¬ä»æ•´ä¸ªçª—å£ä¸­é€‰å–å¤šå°‘ä¸ªä¸åŒçš„è¯ä½œä¸ºæˆ‘ä»¬çš„output wordï¼Œå½“skip_window=2ï¼Œnum_skips=2æ—¶ï¼Œæˆ‘ä»¬å°†ä¼šå¾—åˆ°ä¸¤ç»„ **(input word, output word)** å½¢å¼çš„è®­ç»ƒæ•°æ®ï¼Œå³ **('dog', 'barked')**ï¼Œ**('dog', 'the')**ã€‚\n- ç¥ç»ç½‘ç»œåŸºäºè¿™äº›è®­ç»ƒæ•°æ®å°†ä¼šè¾“å‡ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼Œè¿™ä¸ªæ¦‚ç‡ä»£è¡¨ç€æˆ‘ä»¬çš„è¯å…¸ä¸­çš„æ¯ä¸ªè¯æ˜¯output wordçš„å¯èƒ½æ€§ã€‚è¿™å¥è¯æœ‰ç‚¹ç»•ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸ªæ —å­ã€‚ç¬¬äºŒæ­¥ä¸­æˆ‘ä»¬åœ¨è®¾ç½®skip_windowå’Œnum_skips=2çš„æƒ…å†µä¸‹è·å¾—äº†ä¸¤ç»„è®­ç»ƒæ•°æ®ã€‚å‡å¦‚æˆ‘ä»¬å…ˆæ‹¿ä¸€ç»„æ•°æ® **('dog', 'barked')** æ¥è®­ç»ƒç¥ç»ç½‘ç»œï¼Œé‚£ä¹ˆæ¨¡å‹é€šè¿‡å­¦ä¹ è¿™ä¸ªè®­ç»ƒæ ·æœ¬ï¼Œä¼šå‘Šè¯‰æˆ‘ä»¬è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯æ˜¯â€œbarkedâ€çš„æ¦‚ç‡å¤§å°ã€‚\n\næ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ä»£è¡¨ç€åˆ°æˆ‘ä»¬è¯å…¸ä¸­æ¯ä¸ªè¯æœ‰å¤šå¤§å¯èƒ½æ€§è·Ÿinput wordåŒæ—¶å‡ºç°ã€‚ä¸¾ä¸ªæ —å­ï¼Œå¦‚æœæˆ‘ä»¬å‘ç¥ç»ç½‘ç»œæ¨¡å‹ä¸­è¾“å…¥ä¸€ä¸ªå•è¯â€œSovietâ€œï¼Œé‚£ä¹ˆæœ€ç»ˆæ¨¡å‹çš„è¾“å‡ºæ¦‚ç‡ä¸­ï¼Œåƒâ€œUnionâ€ï¼Œ â€Russiaâ€œè¿™ç§ç›¸å…³è¯çš„æ¦‚ç‡å°†è¿œé«˜äºåƒâ€watermelonâ€œï¼Œâ€kangarooâ€œéç›¸å…³è¯çš„æ¦‚ç‡ã€‚å› ä¸ºâ€Unionâ€œï¼Œâ€Russiaâ€œåœ¨æ–‡æœ¬ä¸­æ›´å¤§å¯èƒ½åœ¨â€Sovietâ€œçš„çª—å£ä¸­å‡ºç°ã€‚æˆ‘ä»¬å°†é€šè¿‡ç»™ç¥ç»ç½‘ç»œè¾“å…¥æ–‡æœ¬ä¸­æˆå¯¹çš„å•è¯æ¥è®­ç»ƒå®ƒå®Œæˆä¸Šé¢æ‰€è¯´çš„æ¦‚ç‡è®¡ç®—ã€‚ä¸‹é¢çš„å›¾ä¸­ç»™å‡ºäº†ä¸€äº›æˆ‘ä»¬çš„è®­ç»ƒæ ·æœ¬çš„ä¾‹å­ã€‚æˆ‘ä»¬é€‰å®šå¥å­**â€œThe quick brown fox jumps over lazy dogâ€**ï¼Œè®¾å®šæˆ‘ä»¬çš„çª—å£å¤§å°ä¸º2ï¼ˆwindow_size=2ï¼‰ï¼Œä¹Ÿå°±æ˜¯è¯´æˆ‘ä»¬ä»…é€‰è¾“å…¥è¯å‰åå„ä¸¤ä¸ªè¯å’Œè¾“å…¥è¯è¿›è¡Œç»„åˆã€‚ä¸‹å›¾ä¸­ï¼Œè“è‰²ä»£è¡¨input wordï¼Œæ–¹æ¡†å†…ä»£è¡¨ä½äºçª—å£å†…çš„å•è¯ã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b319eb5f1f.png?imageMogr2/format/jpg/quality/90)\n\næˆ‘ä»¬çš„æ¨¡å‹å°†ä¼šä»æ¯å¯¹å•è¯å‡ºç°çš„æ¬¡æ•°ä¸­ä¹ å¾—ç»Ÿè®¡ç»“æœã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œå¯èƒ½ä¼šå¾—åˆ°æ›´å¤šç±»ä¼¼ï¼ˆâ€œSovietâ€œï¼Œâ€Unionâ€œï¼‰è¿™æ ·çš„è®­ç»ƒæ ·æœ¬å¯¹ï¼Œè€Œå¯¹äºï¼ˆâ€Sovietâ€œï¼Œâ€Sasquatchâ€œï¼‰è¿™æ ·çš„ç»„åˆå´çœ‹åˆ°çš„å¾ˆå°‘ã€‚å› æ­¤ï¼Œå½“æˆ‘ä»¬çš„æ¨¡å‹å®Œæˆè®­ç»ƒåï¼Œç»™å®šä¸€ä¸ªå•è¯â€Sovietâ€œä½œä¸ºè¾“å…¥ï¼Œè¾“å‡ºçš„ç»“æœä¸­â€Unionâ€œæˆ–è€…â€Russiaâ€œè¦æ¯”â€Sasquatchâ€œè¢«èµ‹äºˆæ›´é«˜çš„æ¦‚ç‡ã€‚\n\n## æ¨¡å‹ç»†èŠ‚\n\næˆ‘ä»¬å¦‚ä½•æ¥è¡¨ç¤ºè¿™äº›å•è¯å‘¢ï¼Ÿé¦–å…ˆï¼Œæˆ‘ä»¬éƒ½çŸ¥é“ç¥ç»ç½‘ç»œåªèƒ½æ¥å—æ•°å€¼è¾“å…¥ï¼Œæˆ‘ä»¬ä¸å¯èƒ½æŠŠä¸€ä¸ªå•è¯å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥ï¼Œå› æ­¤æˆ‘ä»¬å¾—æƒ³ä¸ªåŠæ³•æ¥è¡¨ç¤ºè¿™äº›å•è¯ã€‚æœ€å¸¸ç”¨çš„åŠæ³•å°±æ˜¯åŸºäºè®­ç»ƒæ–‡æ¡£æ¥æ„å»ºæˆ‘ä»¬è‡ªå·±çš„è¯æ±‡è¡¨ï¼ˆvocabularyï¼‰å†å¯¹å•è¯è¿›è¡Œone-hotç¼–ç ã€‚\n\nå‡è®¾ä»æˆ‘ä»¬çš„è®­ç»ƒæ–‡æ¡£ä¸­æŠ½å–å‡º10000ä¸ªå”¯ä¸€ä¸é‡å¤çš„å•è¯ç»„æˆè¯æ±‡è¡¨ã€‚æˆ‘ä»¬å¯¹è¿™10000ä¸ªå•è¯è¿›è¡Œone-hotç¼–ç ï¼Œå¾—åˆ°çš„æ¯ä¸ªå•è¯éƒ½æ˜¯ä¸€ä¸ª10000ç»´çš„å‘é‡ï¼Œå‘é‡æ¯ä¸ªç»´åº¦çš„å€¼åªæœ‰0æˆ–è€…1ï¼Œå‡å¦‚å•è¯antsåœ¨è¯æ±‡è¡¨ä¸­çš„å‡ºç°ä½ç½®ä¸ºç¬¬3ä¸ªï¼Œé‚£ä¹ˆantsçš„å‘é‡å°±æ˜¯ä¸€ä¸ªç¬¬ä¸‰ç»´åº¦å–å€¼ä¸º1ï¼Œå…¶ä»–ç»´éƒ½ä¸º0çš„10000ç»´çš„å‘é‡ï¼ˆants=[0, 0, 1, 0, ..., 0]ï¼‰ã€‚\n\nè¿˜æ˜¯ä¸Šé¢çš„ä¾‹å­ï¼Œâ€œThe dog barked at the mailmanâ€ï¼Œé‚£ä¹ˆæˆ‘ä»¬åŸºäºè¿™ä¸ªå¥å­ï¼Œå¯ä»¥æ„å»ºä¸€ä¸ªå¤§å°ä¸º5çš„è¯æ±‡è¡¨ï¼ˆå¿½ç•¥å¤§å°å†™å’Œæ ‡ç‚¹ç¬¦å·ï¼‰ï¼š(\"the\", \"dog\", \"barked\", \"at\", \"mailman\")ï¼Œæˆ‘ä»¬å¯¹è¿™ä¸ªè¯æ±‡è¡¨çš„å•è¯è¿›è¡Œç¼–å·0-4ã€‚é‚£ä¹ˆâ€dogâ€œå°±å¯ä»¥è¢«è¡¨ç¤ºä¸ºä¸€ä¸ª5ç»´å‘é‡[0, 1, 0, 0, 0]ã€‚\n\næ¨¡å‹çš„è¾“å…¥å¦‚æœä¸ºä¸€ä¸ª10000ç»´çš„å‘é‡ï¼Œé‚£ä¹ˆè¾“å‡ºä¹Ÿæ˜¯ä¸€ä¸ª10000ç»´åº¦ï¼ˆè¯æ±‡è¡¨çš„å¤§å°ï¼‰çš„å‘é‡ï¼Œå®ƒåŒ…å«äº†10000ä¸ªæ¦‚ç‡ï¼Œæ¯ä¸€ä¸ªæ¦‚ç‡ä»£è¡¨ç€å½“å‰è¯æ˜¯è¾“å…¥æ ·æœ¬ä¸­output wordçš„æ¦‚ç‡å¤§å°ã€‚\n\nä¸‹å›¾æ˜¯æˆ‘ä»¬ç¥ç»ç½‘ç»œçš„ç»“æ„ï¼š\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b31d0920ef.png?imageMogr2/format/jpg/quality/90)\n\néšå±‚æ²¡æœ‰ä½¿ç”¨ä»»ä½•æ¿€æ´»å‡½æ•°ï¼Œä½†æ˜¯è¾“å‡ºå±‚ä½¿ç”¨äº†sotfmaxã€‚\n\næˆ‘ä»¬åŸºäºæˆå¯¹çš„å•è¯æ¥å¯¹ç¥ç»ç½‘ç»œè¿›è¡Œè®­ç»ƒï¼Œè®­ç»ƒæ ·æœ¬æ˜¯ ( input word, output word ) è¿™æ ·çš„å•è¯å¯¹ï¼Œinput wordå’Œoutput wordéƒ½æ˜¯one-hotç¼–ç çš„å‘é‡ã€‚æœ€ç»ˆæ¨¡å‹çš„è¾“å‡ºæ˜¯ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒã€‚\n\n## éšå±‚\n\nè¯´å®Œå•è¯çš„ç¼–ç å’Œè®­ç»ƒæ ·æœ¬çš„é€‰å–ï¼Œæˆ‘ä»¬æ¥çœ‹ä¸‹æˆ‘ä»¬çš„éšå±‚ã€‚å¦‚æœæˆ‘ä»¬ç°åœ¨æƒ³ç”¨300ä¸ªç‰¹å¾æ¥è¡¨ç¤ºä¸€ä¸ªå•è¯ï¼ˆå³æ¯ä¸ªè¯å¯ä»¥è¢«è¡¨ç¤ºä¸º300ç»´çš„å‘é‡ï¼‰ã€‚é‚£ä¹ˆéšå±‚çš„æƒé‡çŸ©é˜µåº”è¯¥ä¸º10000è¡Œï¼Œ300åˆ—ï¼ˆéšå±‚æœ‰300ä¸ªç»“ç‚¹ï¼‰ã€‚\n\nGoogleåœ¨æœ€æ–°å‘å¸ƒçš„åŸºäºGoogle newsæ•°æ®é›†è®­ç»ƒçš„æ¨¡å‹ä¸­ä½¿ç”¨çš„å°±æ˜¯300ä¸ªç‰¹å¾çš„è¯å‘é‡ã€‚è¯å‘é‡çš„ç»´åº¦æ˜¯ä¸€ä¸ªå¯ä»¥è°ƒèŠ‚çš„è¶…å‚æ•°ï¼ˆåœ¨Pythonçš„gensimåŒ…ä¸­å°è£…çš„Word2Vecæ¥å£é»˜è®¤çš„è¯å‘é‡å¤§å°ä¸º100ï¼Œ window_sizeä¸º5ï¼‰ã€‚\n\nçœ‹ä¸‹é¢çš„å›¾ç‰‡ï¼Œå·¦å³ä¸¤å¼ å›¾åˆ†åˆ«ä»ä¸åŒè§’åº¦ä»£è¡¨äº†è¾“å…¥å±‚-éšå±‚çš„æƒé‡çŸ©é˜µã€‚å·¦å›¾ä¸­æ¯ä¸€åˆ—ä»£è¡¨ä¸€ä¸ª10000ç»´çš„è¯å‘é‡å’Œéšå±‚å•ä¸ªç¥ç»å…ƒè¿æ¥çš„æƒé‡å‘é‡ã€‚ä»å³è¾¹çš„å›¾æ¥çœ‹ï¼Œæ¯ä¸€è¡Œå®é™…ä¸Šä»£è¡¨äº†æ¯ä¸ªå•è¯çš„è¯å‘é‡ã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b320f8ed60.png?imageMogr2/format/jpg/quality/90)\n\næ‰€ä»¥æˆ‘ä»¬æœ€ç»ˆçš„ç›®æ ‡å°±æ˜¯å­¦ä¹ è¿™ä¸ªéšå±‚çš„æƒé‡çŸ©é˜µã€‚\n\næˆ‘ä»¬ç°åœ¨å›æ¥æ¥ç€é€šè¿‡æ¨¡å‹çš„å®šä¹‰æ¥è®­ç»ƒæˆ‘ä»¬çš„è¿™ä¸ªæ¨¡å‹ã€‚\n\nä¸Šé¢æˆ‘ä»¬æåˆ°ï¼Œinput wordå’Œoutput wordéƒ½ä¼šè¢«æˆ‘ä»¬è¿›è¡Œone-hotç¼–ç ã€‚ä»”ç»†æƒ³ä¸€ä¸‹ï¼Œæˆ‘ä»¬çš„è¾“å…¥è¢«one-hotç¼–ç ä»¥åå¤§å¤šæ•°ç»´åº¦ä¸Šéƒ½æ˜¯0ï¼ˆå®é™…ä¸Šä»…æœ‰ä¸€ä¸ªä½ç½®ä¸º1ï¼‰ï¼Œæ‰€ä»¥è¿™ä¸ªå‘é‡ç›¸å½“ç¨€ç–ï¼Œé‚£ä¹ˆä¼šé€ æˆä»€ä¹ˆç»“æœå‘¢ã€‚å¦‚æœæˆ‘ä»¬å°†ä¸€ä¸ª1 x 10000çš„å‘é‡å’Œ10000 x 300çš„çŸ©é˜µç›¸ä¹˜ï¼Œå®ƒä¼šæ¶ˆè€—ç›¸å½“å¤§çš„è®¡ç®—èµ„æºï¼Œä¸ºäº†é«˜æ•ˆè®¡ç®—ï¼Œå®ƒä»…ä»…ä¼šé€‰æ‹©çŸ©é˜µä¸­å¯¹åº”çš„å‘é‡ä¸­ç»´åº¦å€¼ä¸º1çš„ç´¢å¼•è¡Œï¼ˆè¿™å¥è¯å¾ˆç»•ï¼‰ï¼Œçœ‹å›¾å°±æ˜ç™½ã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b322ae0c72.png?imageMogr2/format/jpg/quality/90)\n\næˆ‘ä»¬æ¥çœ‹ä¸€ä¸‹ä¸Šå›¾ä¸­çš„çŸ©é˜µè¿ç®—ï¼Œå·¦è¾¹åˆ†åˆ«æ˜¯1 x 5å’Œ5 x 3çš„çŸ©é˜µï¼Œç»“æœåº”è¯¥æ˜¯1 x 3çš„çŸ©é˜µï¼ŒæŒ‰ç…§çŸ©é˜µä¹˜æ³•çš„è§„åˆ™ï¼Œç»“æœçš„ç¬¬ä¸€è¡Œç¬¬ä¸€åˆ—å…ƒç´ ä¸º0 x 17 + 0 x 23 + 0 x 4 + 1 x 10 + 0 x 11 = 10ï¼ŒåŒç†å¯å¾—å…¶ä½™ä¸¤ä¸ªå…ƒç´ ä¸º12ï¼Œ19ã€‚å¦‚æœ10000ä¸ªç»´åº¦çš„çŸ©é˜µé‡‡ç”¨è¿™æ ·çš„è®¡ç®—æ–¹å¼æ˜¯ååˆ†ä½æ•ˆçš„ã€‚\n\nä¸ºäº†æœ‰æ•ˆåœ°è¿›è¡Œè®¡ç®—ï¼Œè¿™ç§ç¨€ç–çŠ¶æ€ä¸‹ä¸ä¼šè¿›è¡ŒçŸ©é˜µä¹˜æ³•è®¡ç®—ï¼Œå¯ä»¥çœ‹åˆ°çŸ©é˜µçš„è®¡ç®—çš„ç»“æœå®é™…ä¸Šæ˜¯çŸ©é˜µå¯¹åº”çš„å‘é‡ä¸­å€¼ä¸º1çš„ç´¢å¼•ï¼Œä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå·¦è¾¹å‘é‡ä¸­å–å€¼ä¸º1çš„å¯¹åº”ç»´åº¦ä¸º3ï¼ˆä¸‹æ ‡ä»0å¼€å§‹ï¼‰ï¼Œé‚£ä¹ˆè®¡ç®—ç»“æœå°±æ˜¯çŸ©é˜µçš„ç¬¬3è¡Œï¼ˆä¸‹æ ‡ä»0å¼€å§‹ï¼‰â€”â€” [10, 12, 19]ï¼Œè¿™æ ·æ¨¡å‹ä¸­çš„éšå±‚æƒé‡çŸ©é˜µä¾¿æˆäº†ä¸€ä¸ªâ€æŸ¥æ‰¾è¡¨â€œï¼ˆlookup tableï¼‰ï¼Œè¿›è¡ŒçŸ©é˜µè®¡ç®—æ—¶ï¼Œç›´æ¥å»æŸ¥è¾“å…¥å‘é‡ä¸­å–å€¼ä¸º1çš„ç»´åº¦ä¸‹å¯¹åº”çš„é‚£äº›æƒé‡å€¼ã€‚éšå±‚çš„è¾“å‡ºå°±æ˜¯æ¯ä¸ªè¾“å…¥å•è¯çš„â€œåµŒå…¥è¯å‘é‡â€ã€‚\n\n## è¾“å‡ºå±‚\n\nç»è¿‡ç¥ç»ç½‘ç»œéšå±‚çš„è®¡ç®—ï¼Œantsè¿™ä¸ªè¯ä¼šä»ä¸€ä¸ª1 x 10000çš„å‘é‡å˜æˆ1 x 300çš„å‘é‡ï¼Œå†è¢«è¾“å…¥åˆ°è¾“å‡ºå±‚ã€‚è¾“å‡ºå±‚æ˜¯ä¸€ä¸ªsoftmaxå›å½’åˆ†ç±»å™¨ï¼Œå®ƒçš„æ¯ä¸ªç»“ç‚¹å°†ä¼šè¾“å‡ºä¸€ä¸ª0-1ä¹‹é—´çš„å€¼ï¼ˆæ¦‚ç‡ï¼‰ï¼Œè¿™äº›æ‰€æœ‰è¾“å‡ºå±‚ç¥ç»å…ƒç»“ç‚¹çš„æ¦‚ç‡ä¹‹å’Œä¸º1ã€‚\n\nä¸‹é¢æ˜¯ä¸€ä¸ªä¾‹å­ï¼Œè®­ç»ƒæ ·æœ¬ä¸º (input word: â€œantsâ€ï¼Œ output word: â€œcarâ€) çš„è®¡ç®—ç¤ºæ„å›¾ã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆç»“æ„ç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b3267c64f4.png?imageMogr2/format/jpg/quality/90)\n\n## ç›´è§‰ä¸Šçš„ç†è§£\n\nä¸‹é¢æˆ‘ä»¬å°†é€šè¿‡ç›´è§‰æ¥è¿›è¡Œä¸€äº›æ€è€ƒã€‚\n\nå¦‚æœä¸¤ä¸ªä¸åŒçš„å•è¯æœ‰ç€éå¸¸ç›¸ä¼¼çš„â€œä¸Šä¸‹æ–‡â€ï¼ˆä¹Ÿå°±æ˜¯çª—å£å•è¯å¾ˆç›¸ä¼¼ï¼Œæ¯”å¦‚â€œKitty climbed the treeâ€å’Œâ€œCat climbed the treeâ€ï¼‰ï¼Œé‚£ä¹ˆé€šè¿‡æˆ‘ä»¬çš„æ¨¡å‹è®­ç»ƒï¼Œè¿™ä¸¤ä¸ªå•è¯çš„åµŒå…¥å‘é‡å°†éå¸¸ç›¸ä¼¼ã€‚\n\né‚£ä¹ˆä¸¤ä¸ªå•è¯æ‹¥æœ‰ç›¸ä¼¼çš„â€œä¸Šä¸‹æ–‡â€åˆ°åº•æ˜¯ä»€ä¹ˆå«ä¹‰å‘¢ï¼Ÿæ¯”å¦‚å¯¹äºåŒä¹‰è¯â€œintelligentâ€å’Œâ€œsmartâ€ï¼Œæˆ‘ä»¬è§‰å¾—è¿™ä¸¤ä¸ªå•è¯åº”è¯¥æ‹¥æœ‰ç›¸åŒçš„â€œä¸Šä¸‹æ–‡â€ã€‚è€Œä¾‹å¦‚â€engineâ€œå’Œâ€transmissionâ€œè¿™æ ·ç›¸å…³çš„è¯è¯­ï¼Œå¯èƒ½ä¹Ÿæ‹¥æœ‰ç€ç›¸ä¼¼çš„ä¸Šä¸‹æ–‡ã€‚\n\nå®é™…ä¸Šï¼Œè¿™ç§æ–¹æ³•å®é™…ä¸Šä¹Ÿå¯ä»¥å¸®åŠ©ä½ è¿›è¡Œè¯å¹²åŒ–ï¼ˆstemmingï¼‰ï¼Œä¾‹å¦‚ï¼Œç¥ç»ç½‘ç»œå¯¹â€antâ€œå’Œâ€antsâ€ä¸¤ä¸ªå•è¯ä¼šä¹ å¾—ç›¸ä¼¼çš„è¯å‘é‡ã€‚\n\n> è¯å¹²åŒ–ï¼ˆstemmingï¼‰å°±æ˜¯å»é™¤è¯ç¼€å¾—åˆ°è¯æ ¹çš„è¿‡ç¨‹ã€‚\n\n\n\nåœ¨ç¬¬ä¸€éƒ¨åˆ†è®²è§£å®Œæˆåï¼Œæˆ‘ä»¬ä¼šå‘ç°Word2Vecæ¨¡å‹æ˜¯ä¸€ä¸ªè¶…çº§å¤§çš„ç¥ç»ç½‘ç»œï¼ˆæƒé‡çŸ©é˜µè§„æ¨¡éå¸¸å¤§ï¼‰ã€‚\n\nä¸¾ä¸ªæ —å­ï¼Œæˆ‘ä»¬æ‹¥æœ‰10000ä¸ªå•è¯çš„è¯æ±‡è¡¨ï¼Œæˆ‘ä»¬å¦‚æœæƒ³åµŒå…¥300ç»´çš„è¯å‘é‡ï¼Œé‚£ä¹ˆæˆ‘ä»¬çš„**è¾“å…¥-éšå±‚æƒé‡çŸ©é˜µ**å’Œ**éšå±‚-è¾“å‡ºå±‚çš„æƒé‡çŸ©é˜µ**éƒ½ä¼šæœ‰ 10000 x 300 = 300ä¸‡ä¸ªæƒé‡ï¼Œåœ¨å¦‚æ­¤åºå¤§çš„ç¥ç»ç½‘ç»œä¸­è¿›è¡Œæ¢¯åº¦ä¸‹é™æ˜¯ç›¸å½“æ…¢çš„ã€‚æ›´ç³Ÿç³•çš„æ˜¯ï¼Œä½ éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®æ¥è°ƒæ•´è¿™äº›æƒé‡å¹¶ä¸”é¿å…è¿‡æ‹Ÿåˆã€‚ç™¾ä¸‡æ•°é‡çº§çš„æƒé‡çŸ©é˜µå’Œäº¿ä¸‡æ•°é‡çº§çš„è®­ç»ƒæ ·æœ¬æ„å‘³ç€è®­ç»ƒè¿™ä¸ªæ¨¡å‹å°†ä¼šæ˜¯ä¸ªç¾éš¾ï¼ˆå¤ªå‡¶æ®‹äº†ï¼‰ã€‚\n\nWord2Vec çš„ä½œè€…åœ¨å®ƒçš„ç¬¬äºŒç¯‡è®ºæ–‡ä¸­å¼ºè°ƒäº†è¿™äº›é—®é¢˜ï¼Œä¸‹é¢æ˜¯ä½œè€…åœ¨ç¬¬äºŒç¯‡è®ºæ–‡ä¸­çš„ä¸‰ä¸ªåˆ›æ–°ï¼š\n\n> 1.å°†å¸¸è§çš„å•è¯ç»„åˆï¼ˆword pairsï¼‰æˆ–è€…è¯ç»„ä½œä¸ºå•ä¸ªâ€œwordsâ€æ¥å¤„ç†ã€‚\n>\n> 2.å¯¹é«˜é¢‘æ¬¡å•è¯è¿›è¡ŒæŠ½æ ·æ¥å‡å°‘è®­ç»ƒæ ·æœ¬çš„ä¸ªæ•°ã€‚\n>\n> 3.å¯¹ä¼˜åŒ–ç›®æ ‡é‡‡ç”¨â€œnegative samplingâ€æ–¹æ³•ï¼Œè¿™æ ·æ¯ä¸ªè®­ç»ƒæ ·æœ¬çš„è®­ç»ƒåªä¼šæ›´æ–°ä¸€å°éƒ¨åˆ†çš„æ¨¡å‹æƒé‡ï¼Œä»è€Œé™ä½è®¡ç®—è´Ÿæ‹…ã€‚\n\näº‹å®è¯æ˜ï¼Œå¯¹å¸¸ç”¨è¯æŠ½æ ·å¹¶ä¸”å¯¹ä¼˜åŒ–ç›®æ ‡é‡‡ç”¨â€œnegative samplingâ€ä¸ä»…é™ä½äº†è®­ç»ƒè¿‡ç¨‹ä¸­çš„è®¡ç®—è´Ÿæ‹…ï¼Œè¿˜æé«˜äº†è®­ç»ƒçš„è¯å‘é‡çš„è´¨é‡ã€‚\n\n## Word pairs and \"phases\"\n\nè®ºæ–‡çš„ä½œè€…æŒ‡å‡ºï¼Œä¸€äº›å•è¯ç»„åˆï¼ˆæˆ–è€…è¯ç»„ï¼‰çš„å«ä¹‰å’Œæ‹†å¼€ä»¥åå…·æœ‰å®Œå…¨ä¸åŒçš„æ„ä¹‰ã€‚æ¯”å¦‚â€œBoston Globeâ€æ˜¯ä¸€ç§æŠ¥åˆŠçš„åå­—ï¼Œè€Œå•ç‹¬çš„â€œBostonâ€å’Œâ€œGlobeâ€è¿™æ ·å•ä¸ªçš„å•è¯å´è¡¨è¾¾ä¸å‡ºè¿™æ ·çš„å«ä¹‰ã€‚å› æ­¤ï¼Œåœ¨æ–‡ç« ä¸­åªè¦å‡ºç°â€œBoston Globeâ€ï¼Œæˆ‘ä»¬å°±åº”è¯¥æŠŠå®ƒä½œä¸ºä¸€ä¸ªå•ç‹¬çš„è¯æ¥ç”Ÿæˆå…¶è¯å‘é‡ï¼Œè€Œä¸æ˜¯å°†å…¶æ‹†å¼€ã€‚åŒæ ·çš„ä¾‹å­è¿˜æœ‰â€œNew Yorkâ€ï¼Œâ€œUnited Statedâ€ç­‰ã€‚\n\nåœ¨Googleå‘å¸ƒçš„æ¨¡å‹ä¸­ï¼Œå®ƒæœ¬èº«çš„è®­ç»ƒæ ·æœ¬ä¸­æœ‰æ¥è‡ªGoogle Newsæ•°æ®é›†ä¸­çš„1000äº¿çš„å•è¯ï¼Œä½†æ˜¯é™¤äº†å•ä¸ªå•è¯ä»¥å¤–ï¼Œå•è¯ç»„åˆï¼ˆæˆ–è¯ç»„ï¼‰åˆæœ‰3ç™¾ä¸‡ä¹‹å¤šã€‚\n\nå¦‚æœä½ å¯¹æ¨¡å‹çš„è¯æ±‡è¡¨æ„Ÿå…´è¶£ï¼Œå¯ä»¥ç‚¹å‡»ï¼š\n\n<http://t.cn/RoVde3h>\n\nä½ è¿˜å¯ä»¥ç›´æ¥æµè§ˆè¿™ä¸ªè¯æ±‡è¡¨ï¼š\n\n<http://t.cn/RoVdsZr>\n\nå¦‚æœæƒ³äº†è§£è¿™ä¸ªæ¨¡å‹å¦‚ä½•è¿›è¡Œæ–‡æ¡£ä¸­çš„è¯ç»„æŠ½å–ï¼Œå¯ä»¥çœ‹è®ºæ–‡ä¸­â€œLearning Phrasesâ€è¿™ä¸€ç« ï¼Œå¯¹åº”çš„ä»£ç åœ¨ word2phrase.c ï¼Œç›¸å…³é“¾æ¥å¦‚ä¸‹ã€‚\n\n> è®ºæ–‡é“¾æ¥ï¼š\n>\n> <http://t.cn/RMct1c7>\n\n> ä»£ç é“¾æ¥ï¼š\n>\n> [http://t.cn/R5auFLz](http://t.cn/RMct1c7)\n\n## å¯¹é«˜é¢‘è¯æŠ½æ ·\n\nåœ¨ç¬¬ä¸€éƒ¨åˆ†çš„è®²è§£ä¸­ï¼Œæˆ‘ä»¬å±•ç¤ºäº†è®­ç»ƒæ ·æœ¬æ˜¯å¦‚ä½•ä»åŸå§‹æ–‡æ¡£ä¸­ç”Ÿæˆå‡ºæ¥çš„ï¼Œè¿™é‡Œæˆ‘å†é‡å¤ä¸€æ¬¡ã€‚æˆ‘ä»¬çš„åŸå§‹æ–‡æœ¬ä¸ºâ€œThe quick brown fox jumps over the laze dogâ€ï¼Œå¦‚æœæˆ‘ä½¿ç”¨å¤§å°ä¸º2çš„çª—å£ï¼Œé‚£ä¹ˆæˆ‘ä»¬å¯ä»¥å¾—åˆ°å›¾ä¸­å±•ç¤ºçš„é‚£äº›è®­ç»ƒæ ·æœ¬ã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆè®­ç»ƒç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b387f8455d.png?imageMogr2/format/jpg/quality/90)\n\nä½†æ˜¯å¯¹äºâ€œtheâ€è¿™ç§å¸¸ç”¨é«˜é¢‘å•è¯ï¼Œè¿™æ ·çš„å¤„ç†æ–¹å¼ä¼šå­˜åœ¨ä¸‹é¢ä¸¤ä¸ªé—®é¢˜ï¼š\n\n> 1. å½“æˆ‘ä»¬å¾—åˆ°æˆå¯¹çš„å•è¯è®­ç»ƒæ ·æœ¬æ—¶ï¼Œ(\"fox\", \"the\") è¿™æ ·çš„è®­ç»ƒæ ·æœ¬å¹¶ä¸ä¼šç»™æˆ‘ä»¬æä¾›å…³äºâ€œfoxâ€æ›´å¤šçš„è¯­ä¹‰ä¿¡æ¯ï¼Œå› ä¸ºâ€œtheâ€åœ¨æ¯ä¸ªå•è¯çš„ä¸Šä¸‹æ–‡ä¸­å‡ ä¹éƒ½ä¼šå‡ºç°ã€‚\n> 2. ç”±äºåœ¨æ–‡æœ¬ä¸­â€œtheâ€è¿™æ ·çš„å¸¸ç”¨è¯å‡ºç°æ¦‚ç‡å¾ˆå¤§ï¼Œå› æ­¤æˆ‘ä»¬å°†ä¼šæœ‰å¤§é‡çš„ï¼ˆâ€theâ€œï¼Œ...ï¼‰è¿™æ ·çš„è®­ç»ƒæ ·æœ¬ï¼Œè€Œè¿™äº›æ ·æœ¬æ•°é‡è¿œè¿œè¶…è¿‡äº†æˆ‘ä»¬å­¦ä¹ â€œtheâ€è¿™ä¸ªè¯å‘é‡æ‰€éœ€çš„è®­ç»ƒæ ·æœ¬æ•°ã€‚\n\nWord2Vecé€šè¿‡â€œæŠ½æ ·â€æ¨¡å¼æ¥è§£å†³è¿™ç§é«˜é¢‘è¯é—®é¢˜ã€‚å®ƒçš„åŸºæœ¬æ€æƒ³å¦‚ä¸‹ï¼šå¯¹äºæˆ‘ä»¬åœ¨è®­ç»ƒåŸå§‹æ–‡æœ¬ä¸­é‡åˆ°çš„æ¯ä¸€ä¸ªå•è¯ï¼Œå®ƒä»¬éƒ½æœ‰ä¸€å®šæ¦‚ç‡è¢«æˆ‘ä»¬ä»æ–‡æœ¬ä¸­åˆ æ‰ï¼Œè€Œè¿™ä¸ªè¢«åˆ é™¤çš„æ¦‚ç‡ä¸å•è¯çš„é¢‘ç‡æœ‰å…³ã€‚\nå¦‚æœæˆ‘ä»¬è®¾ç½®çª—å£å¤§å°ï¼ˆå³ï¼‰ï¼Œå¹¶ä¸”ä»æˆ‘ä»¬çš„æ–‡æœ¬ä¸­åˆ é™¤æ‰€æœ‰çš„â€œtheâ€ï¼Œé‚£ä¹ˆä¼šæœ‰ä¸‹é¢çš„ç»“æœï¼š\n\n- ç”±äºæˆ‘ä»¬åˆ é™¤äº†æ–‡æœ¬ä¸­æ‰€æœ‰çš„â€œtheâ€ï¼Œé‚£ä¹ˆåœ¨æˆ‘ä»¬çš„è®­ç»ƒæ ·æœ¬ä¸­ï¼Œâ€œtheâ€è¿™ä¸ªè¯æ°¸è¿œä¹Ÿä¸ä¼šå‡ºç°åœ¨æˆ‘ä»¬çš„ä¸Šä¸‹æ–‡çª—å£ä¸­ã€‚\n\n- å½“â€œtheâ€ä½œä¸ºinput wordæ—¶ï¼Œæˆ‘ä»¬çš„è®­ç»ƒæ ·æœ¬æ•°è‡³å°‘ä¼šå‡å°‘10ä¸ªã€‚\n\n> è¿™å¥è¯åº”è¯¥è¿™ä¹ˆç†è§£ï¼Œå‡å¦‚æˆ‘ä»¬çš„æ–‡æœ¬ä¸­ä»…å‡ºç°äº†ä¸€ä¸ªâ€œtheâ€ï¼Œé‚£ä¹ˆå½“è¿™ä¸ªâ€œtheâ€ä½œä¸ºinput wordæ—¶ï¼Œæˆ‘ä»¬è®¾ç½®span=10ï¼Œæ­¤æ—¶ä¼šå¾—åˆ°10ä¸ªè®­ç»ƒæ ·æœ¬ (\"the\", ...) ï¼Œå¦‚æœåˆ æ‰è¿™ä¸ªâ€œtheâ€ï¼Œæˆ‘ä»¬å°±ä¼šå‡å°‘10ä¸ªè®­ç»ƒæ ·æœ¬ã€‚å®é™…ä¸­æˆ‘ä»¬çš„æ–‡æœ¬ä¸­ä¸æ­¢ä¸€ä¸ªâ€œtheâ€ï¼Œå› æ­¤å½“â€œtheâ€ä½œä¸ºinput wordçš„æ—¶å€™ï¼Œè‡³å°‘ä¼šå‡å°‘10ä¸ªè®­ç»ƒæ ·æœ¬ã€‚\n\nä¸Šé¢æåˆ°çš„è¿™ä¸¤ä¸ªå½±å“ç»“æœå®é™…ä¸Šå°±å¸®åŠ©æˆ‘ä»¬è§£å†³äº†é«˜é¢‘è¯å¸¦æ¥çš„é—®é¢˜ã€‚\n\n## æŠ½æ ·ç‡\n\nword2vecçš„Cè¯­è¨€ä»£ç å®ç°äº†ä¸€ä¸ªè®¡ç®—åœ¨è¯æ±‡è¡¨ä¸­ä¿ç•™æŸä¸ªè¯æ¦‚ç‡çš„å…¬å¼ã€‚\n\nÏ‰i æ˜¯ä¸€ä¸ªå•è¯ï¼ŒZ(Ï‰i) æ˜¯ Ï‰i è¿™ä¸ªå•è¯åœ¨æ‰€æœ‰è¯­æ–™ä¸­å‡ºç°çš„é¢‘æ¬¡ã€‚ä¸¾ä¸ªæ —å­ï¼Œå¦‚æœå•è¯â€œpeanutâ€åœ¨10äº¿è§„æ¨¡å¤§å°çš„è¯­æ–™ä¸­å‡ºç°äº†1000æ¬¡ï¼Œé‚£ä¹ˆ Z(peanut) = 1000/1000000000 = 1e - 6ã€‚\n\nåœ¨ä»£ç ä¸­è¿˜æœ‰ä¸€ä¸ªå‚æ•°å«â€œsampleâ€ï¼Œè¿™ä¸ªå‚æ•°ä»£è¡¨ä¸€ä¸ªé˜ˆå€¼ï¼Œé»˜è®¤å€¼ä¸º0.001**ï¼ˆåœ¨gensimåŒ…ä¸­çš„Word2Vecç±»è¯´æ˜ä¸­ï¼Œè¿™ä¸ªå‚æ•°é»˜è®¤ä¸º0.001ï¼Œæ–‡æ¡£ä¸­å¯¹è¿™ä¸ªå‚æ•°çš„è§£é‡Šä¸ºâ€œ threshold for configuring which higher-frequency words are randomly downsampledâ€ï¼‰**ã€‚è¿™ä¸ªå€¼è¶Šå°æ„å‘³ç€è¿™ä¸ªå•è¯è¢«ä¿ç•™ä¸‹æ¥çš„æ¦‚ç‡è¶Šå°ï¼ˆå³æœ‰è¶Šå¤§çš„æ¦‚ç‡è¢«æˆ‘ä»¬åˆ é™¤ï¼‰ã€‚\n\nP(Ï‰i) ä»£è¡¨ç€ä¿ç•™æŸä¸ªå•è¯çš„æ¦‚ç‡ï¼š\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆè®­ç»ƒç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b3a020bdea.png?imageMogr2/format/jpg/quality/90)\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆè®­ç»ƒç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b3a191fdcd.png?imageMogr2/format/jpg/quality/90)\n\nå›¾ä¸­xè½´ä»£è¡¨ç€ Z(Ï‰i) ï¼Œå³å•è¯ Ï‰i åœ¨è¯­æ–™ä¸­å‡ºç°é¢‘ç‡ï¼Œyè½´ä»£è¡¨æŸä¸ªå•è¯è¢«ä¿ç•™çš„æ¦‚ç‡ã€‚å¯¹äºä¸€ä¸ªåºå¤§çš„è¯­æ–™æ¥è¯´ï¼Œå•ä¸ªå•è¯çš„å‡ºç°é¢‘ç‡ä¸ä¼šå¾ˆå¤§ï¼Œå³ä½¿æ˜¯å¸¸ç”¨è¯ï¼Œä¹Ÿä¸å¯èƒ½ç‰¹åˆ«å¤§ã€‚\n\nä»è¿™ä¸ªå›¾ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥çœ‹åˆ°ï¼Œéšç€å•è¯å‡ºç°é¢‘ç‡çš„å¢é«˜ï¼Œå®ƒè¢«é‡‡æ ·ä¿ç•™çš„æ¦‚ç‡è¶Šæ¥è¶Šå°ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥çœ‹åˆ°ä¸€äº›æœ‰è¶£çš„ç»“è®ºï¼š\n\n- å½“ Z(Ï‰i) <= 0.0026 æ—¶ï¼ŒP(Ï‰i) = 1.0 ã€‚å½“å•è¯åœ¨è¯­æ–™ä¸­å‡ºç°çš„é¢‘ç‡å°äº 0.0026 æ—¶ï¼Œå®ƒæ˜¯ 100% è¢«ä¿ç•™çš„ï¼Œè¿™æ„å‘³ç€åªæœ‰é‚£äº›åœ¨è¯­æ–™ä¸­å‡ºç°é¢‘ç‡è¶…è¿‡ 0.26% çš„å•è¯æ‰ä¼šè¢«é‡‡æ ·ã€‚\n\n- å½“æ—¶ Z(Ï‰i) = 0.00746 æ—¶ï¼ŒP(Ï‰i) = 0.5ï¼Œæ„å‘³ç€è¿™ä¸€éƒ¨åˆ†çš„å•è¯æœ‰ 50% çš„æ¦‚ç‡è¢«ä¿ç•™ã€‚\n\n- å½“ Z(Ï‰i) = 1.0 æ—¶ï¼ŒP(Ï‰i) = 0.033ï¼Œæ„å‘³ç€è¿™éƒ¨åˆ†å•è¯ä»¥ 3.3% çš„æ¦‚ç‡è¢«ä¿ç•™ã€‚\n\n> å¦‚æœä½ å»çœ‹é‚£ç¯‡è®ºæ–‡çš„è¯ï¼Œä½ ä¼šå‘ç°ä½œè€…åœ¨è®ºæ–‡ä¸­å¯¹å‡½æ•°å…¬å¼çš„å®šä¹‰å’Œåœ¨Cè¯­è¨€ä»£ç çš„å®ç°ä¸Šæœ‰ä¸€äº›å·®åˆ«ï¼Œä½†æˆ‘è®¤ä¸ºCè¯­è¨€ä»£ç çš„å…¬å¼å®ç°æ˜¯æ›´æƒå¨çš„ä¸€ä¸ªç‰ˆæœ¬ã€‚\n\n## è´Ÿé‡‡æ ·ï¼ˆnegative samplingï¼‰\n\nè®­ç»ƒä¸€ä¸ªç¥ç»ç½‘ç»œæ„å‘³ç€è¦è¾“å…¥è®­ç»ƒæ ·æœ¬å¹¶ä¸”ä¸æ–­è°ƒæ•´ç¥ç»å…ƒçš„æƒé‡ï¼Œä»è€Œä¸æ–­æé«˜å¯¹ç›®æ ‡çš„å‡†ç¡®é¢„æµ‹ã€‚æ¯å½“ç¥ç»ç½‘ç»œç»è¿‡ä¸€ä¸ªè®­ç»ƒæ ·æœ¬çš„è®­ç»ƒï¼Œå®ƒçš„æƒé‡å°±ä¼šè¿›è¡Œä¸€æ¬¡è°ƒæ•´ã€‚\næ­£å¦‚æˆ‘ä»¬ä¸Šé¢æ‰€è®¨è®ºçš„ï¼Œvocabularyçš„å¤§å°å†³å®šäº†æˆ‘ä»¬çš„Skip-Gramç¥ç»ç½‘ç»œå°†ä¼šæ‹¥æœ‰å¤§è§„æ¨¡çš„æƒé‡çŸ©é˜µï¼Œæ‰€æœ‰çš„è¿™äº›æƒé‡éœ€è¦é€šè¿‡æˆ‘ä»¬æ•°ä»¥äº¿è®¡çš„è®­ç»ƒæ ·æœ¬æ¥è¿›è¡Œè°ƒæ•´ï¼Œè¿™æ˜¯éå¸¸æ¶ˆè€—è®¡ç®—èµ„æºçš„ï¼Œå¹¶ä¸”å®é™…ä¸­è®­ç»ƒèµ·æ¥ä¼šéå¸¸æ…¢ã€‚\n**è´Ÿé‡‡æ ·ï¼ˆnegative samplingï¼‰**è§£å†³äº†è¿™ä¸ªé—®é¢˜ï¼Œå®ƒæ˜¯ç”¨æ¥æé«˜è®­ç»ƒé€Ÿåº¦å¹¶ä¸”æ”¹å–„æ‰€å¾—åˆ°è¯å‘é‡çš„è´¨é‡çš„ä¸€ç§æ–¹æ³•ã€‚ä¸åŒäºåŸæœ¬æ¯ä¸ªè®­ç»ƒæ ·æœ¬æ›´æ–°æ‰€æœ‰çš„æƒé‡ï¼Œè´Ÿé‡‡æ ·æ¯æ¬¡è®©ä¸€ä¸ªè®­ç»ƒæ ·æœ¬ä»…ä»…æ›´æ–°ä¸€å°éƒ¨åˆ†çš„æƒé‡ï¼Œè¿™æ ·å°±ä¼šé™ä½æ¢¯åº¦ä¸‹é™è¿‡ç¨‹ä¸­çš„è®¡ç®—é‡ã€‚\nå½“æˆ‘ä»¬ç”¨è®­ç»ƒæ ·æœ¬ ( input word: \"fox\"ï¼Œoutput word: \"quick\") æ¥è®­ç»ƒæˆ‘ä»¬çš„ç¥ç»ç½‘ç»œæ—¶ï¼Œâ€œ foxâ€å’Œâ€œquickâ€éƒ½æ˜¯ç»è¿‡one-hotç¼–ç çš„ã€‚å¦‚æœæˆ‘ä»¬çš„vocabularyå¤§å°ä¸º10000æ—¶ï¼Œåœ¨è¾“å‡ºå±‚ï¼Œæˆ‘ä»¬æœŸæœ›å¯¹åº”â€œquickâ€å•è¯çš„é‚£ä¸ªç¥ç»å…ƒç»“ç‚¹è¾“å‡º1ï¼Œå…¶ä½™9999ä¸ªéƒ½åº”è¯¥è¾“å‡º0ã€‚åœ¨è¿™é‡Œï¼Œè¿™9999ä¸ªæˆ‘ä»¬æœŸæœ›è¾“å‡ºä¸º0çš„ç¥ç»å…ƒç»“ç‚¹æ‰€å¯¹åº”çš„å•è¯æˆ‘ä»¬ç§°ä¸ºâ€œnegativeâ€ wordã€‚\nå½“ä½¿ç”¨è´Ÿé‡‡æ ·æ—¶ï¼Œæˆ‘ä»¬å°†éšæœºé€‰æ‹©ä¸€å°éƒ¨åˆ†çš„negative wordsï¼ˆæ¯”å¦‚é€‰5ä¸ªnegative wordsï¼‰æ¥æ›´æ–°å¯¹åº”çš„æƒé‡ã€‚æˆ‘ä»¬ä¹Ÿä¼šå¯¹æˆ‘ä»¬çš„â€œpositiveâ€ wordè¿›è¡Œæƒé‡æ›´æ–°ï¼ˆåœ¨æˆ‘ä»¬ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œè¿™ä¸ªå•è¯æŒ‡çš„æ˜¯â€quickâ€œï¼‰ã€‚\n\n> åœ¨è®ºæ–‡ä¸­ï¼Œä½œè€…æŒ‡å‡ºæŒ‡å‡ºå¯¹äºå°è§„æ¨¡æ•°æ®é›†ï¼Œé€‰æ‹©5-20ä¸ªnegative wordsä¼šæ¯”è¾ƒå¥½ï¼Œå¯¹äºå¤§è§„æ¨¡æ•°æ®é›†å¯ä»¥ä»…é€‰æ‹©2-5ä¸ªnegative wordsã€‚\n\nå›å¿†ä¸€ä¸‹æˆ‘ä»¬çš„éšå±‚-è¾“å‡ºå±‚æ‹¥æœ‰300 x 10000çš„æƒé‡çŸ©é˜µã€‚å¦‚æœä½¿ç”¨äº†è´Ÿé‡‡æ ·çš„æ–¹æ³•æˆ‘ä»¬ä»…ä»…å»æ›´æ–°æˆ‘ä»¬çš„positive word-â€œquickâ€çš„å’Œæˆ‘ä»¬é€‰æ‹©çš„å…¶ä»–5ä¸ªnegative wordsçš„ç»“ç‚¹å¯¹åº”çš„æƒé‡ï¼Œå…±è®¡6ä¸ªè¾“å‡ºç¥ç»å…ƒï¼Œç›¸å½“äºæ¯æ¬¡åªæ›´æ–° 300 x 6 = 1800 ä¸ªæƒé‡ã€‚å¯¹äº3ç™¾ä¸‡çš„æƒé‡æ¥è¯´ï¼Œç›¸å½“äºåªè®¡ç®—äº†0.06%çš„æƒé‡ï¼Œè¿™æ ·è®¡ç®—æ•ˆç‡å°±å¤§å¹…åº¦æé«˜ã€‚\n\n## å¦‚ä½•é€‰æ‹©negative words\n\næˆ‘ä»¬ä½¿ç”¨â€œä¸€å…ƒæ¨¡å‹åˆ†å¸ƒï¼ˆunigram distributionï¼‰â€æ¥é€‰æ‹©â€œnegative wordsâ€ã€‚\nè¦æ³¨æ„çš„ä¸€ç‚¹æ˜¯ï¼Œä¸€ä¸ªå•è¯è¢«é€‰ä½œnegative sampleçš„æ¦‚ç‡è·Ÿå®ƒå‡ºç°çš„é¢‘æ¬¡æœ‰å…³ï¼Œå‡ºç°é¢‘æ¬¡è¶Šé«˜çš„å•è¯è¶Šå®¹æ˜“è¢«é€‰ä½œnegative wordsã€‚\nåœ¨word2vecçš„Cè¯­è¨€å®ç°ä¸­ï¼Œä½ å¯ä»¥çœ‹åˆ°å¯¹äºè¿™ä¸ªæ¦‚ç‡çš„å®ç°å…¬å¼ã€‚æ¯ä¸ªå•è¯è¢«é€‰ä¸ºâ€œnegative wordsâ€çš„æ¦‚ç‡è®¡ç®—å…¬å¼ä¸å…¶å‡ºç°çš„é¢‘æ¬¡æœ‰å…³ã€‚\nä»£ç ä¸­çš„å…¬å¼å®ç°å¦‚ä¸‹ï¼š\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆè®­ç»ƒç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b3b5516125.png?imageMogr2/format/jpg/quality/90)\n\næ¯ä¸ªå•è¯è¢«èµ‹äºˆä¸€ä¸ªæƒé‡ï¼Œå³ f(Ï‰i)ï¼Œ å®ƒä»£è¡¨ç€å•è¯å‡ºç°çš„é¢‘æ¬¡ã€‚\n\nå…¬å¼ä¸­å¼€3/4çš„æ ¹å·å®Œå…¨æ˜¯åŸºäºç»éªŒçš„ï¼Œè®ºæ–‡ä¸­æåˆ°è¿™ä¸ªå…¬å¼çš„æ•ˆæœè¦æ¯”å…¶å®ƒå…¬å¼æ›´åŠ å‡ºè‰²ã€‚ä½ å¯ä»¥åœ¨googleçš„æœç´¢æ ä¸­è¾“å…¥â€œplot y = x^(3/4) and y = xâ€ï¼Œç„¶åçœ‹åˆ°è¿™ä¸¤å¹…å›¾ï¼ˆå¦‚ä¸‹å›¾ï¼‰ï¼Œä»”ç»†è§‚å¯Ÿxåœ¨[0,1]åŒºé—´å†…æ—¶yçš„å–å€¼ï¼Œx^(3/4) æœ‰ä¸€å°æ®µå¼§å½¢ï¼Œå–å€¼åœ¨ y = x å‡½æ•°ä¹‹ä¸Šã€‚\n\n![ä¸€æ–‡è¯¦è§£ Word2vec ä¹‹ Skip-Gram æ¨¡å‹ï¼ˆè®­ç»ƒç¯‡ï¼‰](https://static.leiphone.com/uploads/new/article/740_740/201706/594b3bb3458fc.png?imageMogr2/format/jpg/quality/90)\n\nè´Ÿé‡‡æ ·çš„Cè¯­è¨€å®ç°éå¸¸çš„æœ‰è¶£ã€‚unigram tableæœ‰ä¸€ä¸ªåŒ…å«äº†ä¸€äº¿ä¸ªå…ƒç´ çš„æ•°ç»„ï¼Œè¿™ä¸ªæ•°ç»„æ˜¯ç”±è¯æ±‡è¡¨ä¸­æ¯ä¸ªå•è¯çš„ç´¢å¼•å·å¡«å……çš„ï¼Œå¹¶ä¸”è¿™ä¸ªæ•°ç»„ä¸­æœ‰é‡å¤ï¼Œä¹Ÿå°±æ˜¯è¯´æœ‰äº›å•è¯ä¼šå‡ºç°å¤šæ¬¡ã€‚é‚£ä¹ˆæ¯ä¸ªå•è¯çš„ç´¢å¼•åœ¨è¿™ä¸ªæ•°ç»„ä¸­å‡ºç°çš„æ¬¡æ•°è¯¥å¦‚ä½•å†³å®šå‘¢ï¼Œæœ‰å…¬å¼ï¼Œä¹Ÿå°±æ˜¯è¯´è®¡ç®—å‡ºçš„**è´Ÿé‡‡æ ·æ¦‚ç‡\\*1äº¿=å•è¯åœ¨è¡¨ä¸­å‡ºç°çš„æ¬¡æ•°**ã€‚\n\næœ‰äº†è¿™å¼ è¡¨ä»¥åï¼Œæ¯æ¬¡å»æˆ‘ä»¬è¿›è¡Œè´Ÿé‡‡æ ·æ—¶ï¼Œåªéœ€è¦åœ¨0-1äº¿èŒƒå›´å†…ç”Ÿæˆä¸€ä¸ªéšæœºæ•°ï¼Œç„¶åé€‰æ‹©è¡¨ä¸­ç´¢å¼•å·ä¸ºè¿™ä¸ªéšæœºæ•°çš„é‚£ä¸ªå•è¯ä½œä¸ºæˆ‘ä»¬çš„negative wordå³å¯ã€‚ä¸€ä¸ªå•è¯çš„è´Ÿé‡‡æ ·æ¦‚ç‡è¶Šå¤§ï¼Œé‚£ä¹ˆå®ƒåœ¨è¿™ä¸ªè¡¨ä¸­å‡ºç°çš„æ¬¡æ•°å°±è¶Šå¤šï¼Œå®ƒè¢«é€‰ä¸­çš„æ¦‚ç‡å°±è¶Šå¤§ã€‚\n\nåˆ°ç›®å‰ä¸ºæ­¢ï¼ŒWord2Vecä¸­çš„Skip-Gramæ¨¡å‹å°±è®²å®Œäº†ï¼Œå¯¹äºé‡Œé¢å…·ä½“çš„æ•°å­¦å…¬å¼æ¨å¯¼ç»†èŠ‚è¿™é‡Œå¹¶æ²¡æœ‰æ·±å…¥ã€‚è¿™ç¯‡æ–‡ç« åªæ˜¯å¯¹äºå®ç°ç»†èŠ‚ä¸Šçš„ä¸€äº›æ€æƒ³è¿›è¡Œäº†é˜è¿°ã€‚\n\n\n\n\n\n```"
    },
    {
      "id": "/2020/3/18/google_cloud",
      "metadata": {
        "permalink": "/blog/2020/3/18/google_cloud",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-18-google_cloud.md",
        "source": "@site/blog/2020-3-18-google_cloud.md",
        "title": "ä½¿ç”¨Google Cloud SDKæ¥é…ç½®Google App Engine",
        "description": "Learn how to build deep learning in Google Cloud Platform Docusaurus 2 alpha.",
        "date": "2020-03-18T00:00:00.000Z",
        "formattedDate": "March 18, 2020",
        "tags": [
          {
            "label": "google cloud",
            "permalink": "/blog/tags/google-cloud"
          },
          {
            "label": "SDK",
            "permalink": "/blog/tags/sdk"
          },
          {
            "label": "socket",
            "permalink": "/blog/tags/socket"
          },
          {
            "label": "google cloud init",
            "permalink": "/blog/tags/google-cloud-init"
          }
        ],
        "readingTime": 1.145,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI engine @ Facebook",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "google cloud",
          "title": "ä½¿ç”¨Google Cloud SDKæ¥é…ç½®Google App Engine",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI engine @ Facebook",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "google cloud",
            "SDK",
            "socket",
            "google cloud init"
          ]
        },
        "prevItem": {
          "title": "word2vecè¯¦è§£",
          "permalink": "/blog/2020/03/18/word2vec"
        },
        "nextItem": {
          "title": "textCNNå·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»",
          "permalink": "/blog/2020/3/18/textCNN"
        }
      },
      "content": "Learn how to build deep learning in Google Cloud Platform [**Docusaurus 2 alpha**](https://v2.docusaurus.io/).\n\n<!--truncate-->\n\nä½¿ç”¨Google Cloud SDKæ¥é…ç½®Google App Engine\n\nGoogle App Engine æ˜¯ä¸€ä¸ªè„±ç¦»äº†åŸºç¡€æ¶æ„æŸç¼šçš„å…¨é¢æ‰˜ç®¡å‹å¹³å°ï¼ŒåŠŸèƒ½ååˆ†å¼ºå¤§ï¼Œå½“ä»Šæœ€æˆåŠŸçš„ä¸€äº›å…¬å¸éƒ½çº·çº·åœ¨ App Engine ä¸Šè¿è¡Œä»–ä»¬çš„åº”ç”¨ã€‚\n\nã€€ã€€ä¹‹å‰æˆ‘æ›¾ç»ä»‹ç»è¿‡ä½¿ç”¨Google App Engine SDKæ¥æ›´æ–°Google App Engineçš„å·¥ç¨‹ï¼Œç›®å‰Google App Engineæœ‰äº†ä¸€ä¸ªæ–°çš„SDKï¼šGoogle Cloud SDKï¼Œä½¿ç”¨è¿™ä¸ªSDKèƒ½æ›´å¿«æ›´é«˜æ•ˆåœ°è¿›è¡Œç»´æŠ¤å’Œæ›´æ–°ã€‚ä¸‹é¢æˆ‘å°±ä»‹ç»ä¸€ä¸‹Google Cloud SDKçš„ç®€å•ä½¿ç”¨æ–¹æ³•ã€‚\n\nã€€ã€€å…ˆä»è¿™ä¸ªåœ°å€æ¥ä¸‹è½½å®‰è£…SDKç¯å¢ƒï¼ŒåŒ…æ‹¬ä¸‹è½½å¹¶å®‰è£… Python 2.7ï¼Œ ä¸‹è½½å¹¶å®‰è£… Google Cloud SDKã€‚\n\nã€€ã€€ä½¿ç”¨ gcloud init --skip-diagnostics æ¥åˆå§‹åŒ–å¹¶ç™»é™†Googleè´¦æˆ·ï¼Œé€‰æ‹©ä¸€ä¸ªå·¥ç¨‹ã€‚æ”¯æŒsocks5ä»£ç†ï¼Œç”¨æˆ·å¯ä»¥åœ¨åˆå§‹åŒ–çš„æ—¶å€™æŠŠä»£ç†è®¾ç½®ä¸Šã€‚\n\n![png](../img/SDK/1.png)\n\n![png](../img/SDK/2.png)"
    },
    {
      "id": "/2020/3/18/textCNN",
      "metadata": {
        "permalink": "/blog/2020/3/18/textCNN",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-3-18-textCNN.md",
        "source": "@site/blog/2020-3-18-textCNN.md",
        "title": "textCNNå·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»",
        "description": "äº‘æ¶¦äººå·¥æ™ºèƒ½éƒ¨é—¨ã€ŠNLPé›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ã€‹è¯¾ç¨‹èµ„æ–™ by ç®—æ³•å·¥ç¨‹å¸ˆ:æ‹›æ™“è´¤",
        "date": "2020-03-18T00:00:00.000Z",
        "formattedDate": "March 18, 2020",
        "tags": [
          {
            "label": "facebook",
            "permalink": "/blog/tags/facebook"
          },
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 4.69,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "æ‹›æ™“è´¤",
            "title": "AI Engineer",
            "url": "https://github.com/flybirdgroup",
            "imageURL": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"
          }
        ],
        "frontMatter": {
          "id": "welcome",
          "title": "textCNNå·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»",
          "author": "æ‹›æ™“è´¤",
          "author_title": "AI Engineer",
          "author_url": "https://github.com/flybirdgroup",
          "author_image_url": "https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",
          "tags": [
            "facebook",
            "hello",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "ä½¿ç”¨Google Cloud SDKæ¥é…ç½®Google App Engine",
          "permalink": "/blog/2020/3/18/google_cloud"
        },
        "nextItem": {
          "title": "Long Blog Post",
          "permalink": "/blog/long-blog-post"
        }
      },
      "content": "**[äº‘æ¶¦äººå·¥æ™ºèƒ½éƒ¨é—¨](https://my-website-six.now.sh/)ã€ŠNLPé›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ã€‹è¯¾ç¨‹èµ„æ–™ by [ç®—æ³•å·¥ç¨‹å¸ˆ:æ‹›æ™“è´¤](https://github.com/flybirdgroup)**\n<!--truncate-->\n# èœé¸Ÿä¹Ÿèƒ½ç©è½¬NLP-å·ç§¯ç¥ç»ç½‘ç»œæ–‡æœ¬åˆ†ç±»\n**[äº‘æ¶¦äººå·¥æ™ºèƒ½éƒ¨é—¨](https://my-website-six.now.sh/)ã€ŠNLPé›¶åŸºç¡€å¿«é€Ÿä¸Šæ‰‹æ•™ç¨‹ã€‹è¯¾ç¨‹èµ„æ–™ by [ç®—æ³•å·¥ç¨‹å¸ˆ:æ‹›æ™“è´¤](https://github.com/flybirdgroup)**\n\n## åŸç†è®²è§£\nTextCNNå‡ºå¤„ï¼šè®ºæ–‡[Convolutional Neural Networks for Sentence Classification](http://www.aclweb.org/anthology/D14-1181)\n\n### è®ºæ–‡æ ¸å¿ƒç‚¹\n\n![png](../img/CNN/TextCNN.png)\n\n1. Represent sentence with **static and non-static channels**.\n2. **Convolve** with multiple filter widths and feature maps.\n3. Use **max-over-time pooling**.\n4. Use **fully connected layer** with **dropout** and **softmax** ouput.\n\n### TextCNNåŸºç¡€çŸ¥è¯†\n#### è¯å‘é‡\n1. éšæœºåˆå§‹åŒ–\n2. é¢„è®­ç»ƒè¯å‘é‡è¿›è¡Œåˆå§‹åŒ–,åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å›ºå®š(CNN-static),æ³¨æ„ä¸å›¾åƒCNNçš„ä¸åŒ\n3. é¢„è®­ç»ƒè¯å‘é‡è¿›è¡Œåˆå§‹åŒ–,åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å¾®è°ƒ(CNN-non-static)\n4. å¤šé€šé“(CNN-multichannel):å°†å›ºå®šçš„é¢„è®­ç»ƒè¯å‘é‡å’Œå¾®è°ƒçš„è¯å‘é‡åˆ†åˆ«ä½œä¸ºä¸€ä¸ªé€šé“(channel),å·ç§¯æ“ä½œåŒæ—¶åœ¨ä¸¤ä¸ªé€šé“ä¸Šè¿›è¡Œ,å¯ä»¥ç±»æ¯”å›¾åƒRGBä¸‰é€šé“\n\n#### è¯¦ç»†è¯´æ˜\n1. ä¸Šå›¾çš„å›¾ç‰‡ä¸ºä¾‹,å¥å­é•¿åº¦ä¸ºn=9,è¯å‘é‡ç»´åº¦kä¸º6,filteræœ‰ä¸¤ç§çª—å£å¤§å°,æ¯ç§æœ‰2ä¸ª,æ‰€ä»¥filteræœ‰4ä¸ª.\n2. çº¢è‰²æ¡†çš„ä¸ºh=2,å·ç§¯åçš„å‘é‡ç»´åº¦ä¸ºn-h+1=9-2+1=8\n3. é»„è‰²æ¡†h=3,å·ç§¯åçš„å‘é‡ç»´åº¦æ˜¯n-h+1=9-3+1=7 (è®ºæ–‡åŸå›¾å°‘ç”»äº†ä¸€ä¸ªç»´åº¦)\n\n### é¡¹ç›®å®ç°\n\nTextCNN çš„ç½‘ç»œç»“æ„ï¼š\n\n\n![png](../img/CNN/TextCNN_network_structure.png)\n\n\n\n## æ¨¡å‹æ„å»ºä¸è®­ç»ƒ\n\n### 1.å®šä¹‰ç½‘ç»œç»“æ„\n\n\n```python\nfrom tensorflow.keras import Input, Model\nfrom tensorflow.keras.layers import Embedding, Dense, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout\n\n#é‡è¦å‚æ•°è§£é‡Š\n#maxlen:å¥å­æœ€å¤§é•¿åº¦\n#max_features:è¯å…¸æœ€å¤§æ•°é‡\n# embeding_dims:è¯å‘é‡ç»´åº¦æ•°\n#class_num: åˆ†ç±»æ•°\n#last_activation:æ¿€æ´»å‡½æ•°\n\nclass TextCNN(object):\n    def __init__(self, maxlen, max_features, embedding_dims,\n                 class_num=5,\n                 last_activation='softmax'):\n        self.maxlen = maxlen\n        self.max_features = max_features\n        self.embedding_dims = embedding_dims\n        self.class_num = class_num\n        self.last_activation = last_activation\n\n    def get_model(self):\n        input = Input((self.maxlen,))\n        embedding = Embedding(self.max_features, self.embedding_dims, input_length=self.maxlen)(input)\n        convs = []\n        for kernel_size in [3, 4, 5]:\n            c = Conv1D(128, kernel_size, activation='relu')(embedding)\n            c = GlobalMaxPooling1D()(c)\n            convs.append(c)\n        x = Concatenate()(convs)\n\n        output = Dense(self.class_num, activation=self.last_activation)(x)\n        model = Model(inputs=input, outputs=output)\n        return model\n```\n\n### 2.æ•°æ®å¤„ç†ä¸è®­ç»ƒ\n\n\n```python\nfrom tensorflow.keras.preprocessing import sequence\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.utils import to_categorical\nfrom utils import *\n\n# è·¯å¾„ç­‰é…ç½®\ndata_dir = \"./processed_data\"\nvocab_file = \"./vocab/vocab.txt\"\nvocab_size = 40000\n\n# ç¥ç»ç½‘ç»œé…ç½®\nmax_features = 40001\nmaxlen = 100\nbatch_size = 64\nembedding_dims = 50\nepochs = 8\n\nprint('æ•°æ®é¢„å¤„ç†ä¸åŠ è½½æ•°æ®...')\n# å¦‚æœä¸å­˜åœ¨è¯æ±‡è¡¨ï¼Œé‡å»º\nif not os.path.exists(vocab_file):  \n    build_vocab(data_dir, vocab_file, vocab_size)\n# è·å¾— è¯æ±‡/ç±»åˆ« ä¸idæ˜ å°„å­—å…¸\ncategories, cat_to_id = read_category()\nwords, word_to_id = read_vocab(vocab_file)\n\n# å…¨éƒ¨æ•°æ®\nx, y = read_files(data_dir)\ndata = list(zip(x,y))\ndel x,y\n# ä¹±åº\nrandom.shuffle(data)\n# åˆ‡åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†\ntrain_data, test_data = train_test_split(data)\n# å¯¹æ–‡æœ¬çš„è¯idå’Œç±»åˆ«idè¿›è¡Œç¼–ç \nx_train = encode_sentences([content[0] for content in train_data], word_to_id)\ny_train = to_categorical(encode_cate([content[1] for content in train_data], cat_to_id))\nx_test = encode_sentences([content[0] for content in test_data], word_to_id)\ny_test = to_categorical(encode_cate([content[1] for content in test_data], cat_to_id))\n\nprint('å¯¹åºåˆ—åšpaddingï¼Œä¿è¯æ˜¯ samples*timestep çš„ç»´åº¦')\nx_train = sequence.pad_sequences(x_train, maxlen=maxlen)\nx_test = sequence.pad_sequences(x_test, maxlen=maxlen)\nprint('x_train shape:', x_train.shape)\nprint('x_test shape:', x_test.shape)\n\nprint('æ„å»ºæ¨¡å‹...')\nmodel = TextCNN(maxlen, max_features, embedding_dims).get_model()\nmodel.compile('adam', 'categorical_crossentropy', metrics=['accuracy'])\n\nprint('è®­ç»ƒ...')\n# è®¾å®šcallbackså›è°ƒå‡½æ•°\nmy_callbacks = [\n    ModelCheckpoint('./cnn_model.h5', verbose=1),\n    EarlyStopping(monitor='val_accuracy', patience=2, mode='max')\n]\n\n# fitæ‹Ÿåˆæ•°æ®\nhistory = model.fit(x_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          callbacks=my_callbacks,\n          validation_data=(x_test, y_test))\n\n#print('å¯¹æµ‹è¯•é›†é¢„æµ‹...')\n#result = model.predict(x_test)\n```\n\n\n### 3.è®­ç»ƒä¸­é—´ä¿¡æ¯è¾“å‡º\n\n\n```python\nimport matplotlib.pyplot as plt\nplt.switch_backend('agg')\n%matplotlib inline\n\nfig1 = plt.figure()\nplt.plot(history.history['loss'],'r',linewidth=3.0)\nplt.plot(history.history['val_loss'],'b',linewidth=3.0)\nplt.legend(['Training loss', 'Validation Loss'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Loss',fontsize=16)\nplt.title('Loss Curves :CNN',fontsize=16)\nfig1.savefig('loss_cnn.png')\nplt.show()\n```\n![png](../img/CNN/output_8_0.png)\n\n```python\nfig2=plt.figure()\nplt.plot(history.history['acc'],'r',linewidth=3.0)\nplt.plot(history.history['val_acc'],'b',linewidth=3.0)\nplt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\nplt.xlabel('Epochs ',fontsize=16)\nplt.ylabel('Accuracy',fontsize=16)\nplt.title('Accuracy Curves : CNN',fontsize=16)\nfig2.savefig('accuracy_cnn.png')\nplt.show()\n```\n\n![png](../img/CNN/output_9_0.png)\n\n\n### 4.æ¨¡å‹ç»“æ„æ‰“å°\n\n\n```python\nfrom tensorflow.keras.utils import plot_model\nplot_model(model, show_shapes=True, show_layer_names=True)\n```\n![png](../img/CNN/CNN_structure.png)\n\n\n\n### 5.æ¨¡å‹å¯¼å‡º\n```python\nimport tensorflow as tf\nimport shutil \nmodel = tf.keras.models.load_model('./cnn_model.h5')\n```\n\n### 6.é¢„æµ‹æ¨¡å‹\n```python\nimport jieba\ntext = \"æ¨å¹‚å¥½æ¼‚äº®,å‘ç”ŸåŸå­å¼¹\"\nprint(jieba.lcut(text))\ntext_seg = encode_sentences([jieba.lcut(text)], word_to_id)\ntext_input = sequence.pad_sequences(text_seg, maxlen=maxlen)\nprint(model.predict(text_input))\n```\n\n###   7.å‰åç«¯ç»“åˆ+dockeréƒ¨ç½²\né¡¹ç›®demoï¼šdockeréƒ¨ç½²é“¾æ¥:[ä¸­æ–‡æ–°é—»å¤šåˆ†ç±»demo](https://hub.docker.com/repository/docker/flybirdgroup/classifier)\n\n`dockerå¯åŠ¨å‘½ä»¤`\n```python\ndocker run -p 127.0.0.1:80:5000/tcp flybirdgroup/classifier\n```\n![png](../img/CNN/docker1.png)\n\n![png](../img/CNN/docker2.png)"
    },
    {
      "id": "long-blog-post",
      "metadata": {
        "permalink": "/blog/long-blog-post",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-29-long-blog-post.md",
        "source": "@site/blog/2019-05-29-long-blog-post.md",
        "title": "Long Blog Post",
        "description": "This is the summary of a very long blog post,",
        "date": "2019-05-29T00:00:00.000Z",
        "formattedDate": "May 29, 2019",
        "tags": [
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 2.05,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "Endilie Yacop Sucipto",
            "title": "Maintainer of Docusaurus",
            "url": "https://github.com/endiliey",
            "imageURL": "https://github.com/endiliey.png",
            "key": "endi"
          }
        ],
        "frontMatter": {
          "slug": "long-blog-post",
          "title": "Long Blog Post",
          "authors": "endi",
          "tags": [
            "hello",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "textCNNå·ç§¯ç¥ç»ç½‘ç»œåˆ†ç±»",
          "permalink": "/blog/2020/3/18/textCNN"
        },
        "nextItem": {
          "title": "Long Blog Post",
          "permalink": "/blog/long-blog-post"
        }
      },
      "content": "This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!--truncate-->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"
    },
    {
      "id": "long-blog-post",
      "metadata": {
        "permalink": "/blog/long-blog-post",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-29-long-blog-postçš„å‰¯æœ¬.md",
        "source": "@site/blog/2019-05-29-long-blog-postçš„å‰¯æœ¬.md",
        "title": "Long Blog Post",
        "description": "This is the summary of a very long blog post,",
        "date": "2019-05-29T00:00:00.000Z",
        "formattedDate": "May 29, 2019",
        "tags": [
          {
            "label": "hello",
            "permalink": "/blog/tags/hello"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 2.05,
        "hasTruncateMarker": true,
        "authors": [
          {
            "name": "Endilie Yacop Sucipto",
            "title": "Maintainer of Docusaurus",
            "url": "https://github.com/endiliey",
            "imageURL": "https://github.com/endiliey.png",
            "key": "endi"
          }
        ],
        "frontMatter": {
          "slug": "long-blog-post",
          "title": "Long Blog Post",
          "authors": "endi",
          "tags": [
            "hello",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "Long Blog Post",
          "permalink": "/blog/long-blog-post"
        },
        "nextItem": {
          "title": "First Blog Post",
          "permalink": "/blog/first-blog-post"
        }
      },
      "content": "This is the summary of a very long blog post,\n\nUse a `<!--` `truncate` `-->` comment to limit blog post size in the list view.\n\n<!--truncate-->\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet\n\nLorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"
    },
    {
      "id": "first-blog-post",
      "metadata": {
        "permalink": "/blog/first-blog-post",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-28-first-blog-post.md",
        "source": "@site/blog/2019-05-28-first-blog-post.md",
        "title": "First Blog Post",
        "description": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet",
        "date": "2019-05-28T00:00:00.000Z",
        "formattedDate": "May 28, 2019",
        "tags": [
          {
            "label": "hola",
            "permalink": "/blog/tags/hola"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 0.12,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Gao Wei",
            "title": "Docusaurus Core Team",
            "url": "https://github.com/wgao19",
            "image_url": "https://github.com/wgao19.png",
            "imageURL": "https://github.com/wgao19.png"
          }
        ],
        "frontMatter": {
          "slug": "first-blog-post",
          "title": "First Blog Post",
          "authors": {
            "name": "Gao Wei",
            "title": "Docusaurus Core Team",
            "url": "https://github.com/wgao19",
            "image_url": "https://github.com/wgao19.png",
            "imageURL": "https://github.com/wgao19.png"
          },
          "tags": [
            "hola",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "Long Blog Post",
          "permalink": "/blog/long-blog-post"
        },
        "nextItem": {
          "title": "First Blog Post",
          "permalink": "/blog/first-blog-post"
        }
      },
      "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"
    },
    {
      "id": "first-blog-post",
      "metadata": {
        "permalink": "/blog/first-blog-post",
        "editUrl": "https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2019-05-28-first-blog-postçš„å‰¯æœ¬.md",
        "source": "@site/blog/2019-05-28-first-blog-postçš„å‰¯æœ¬.md",
        "title": "First Blog Post",
        "description": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet",
        "date": "2019-05-28T00:00:00.000Z",
        "formattedDate": "May 28, 2019",
        "tags": [
          {
            "label": "hola",
            "permalink": "/blog/tags/hola"
          },
          {
            "label": "docusaurus",
            "permalink": "/blog/tags/docusaurus"
          }
        ],
        "readingTime": 0.12,
        "hasTruncateMarker": false,
        "authors": [
          {
            "name": "Gao Wei",
            "title": "Docusaurus Core Team",
            "url": "https://github.com/wgao19",
            "image_url": "https://github.com/wgao19.png",
            "imageURL": "https://github.com/wgao19.png"
          }
        ],
        "frontMatter": {
          "slug": "first-blog-post",
          "title": "First Blog Post",
          "authors": {
            "name": "Gao Wei",
            "title": "Docusaurus Core Team",
            "url": "https://github.com/wgao19",
            "image_url": "https://github.com/wgao19.png",
            "imageURL": "https://github.com/wgao19.png"
          },
          "tags": [
            "hola",
            "docusaurus"
          ]
        },
        "prevItem": {
          "title": "First Blog Post",
          "permalink": "/blog/first-blog-post"
        }
      },
      "content": "Lorem ipsum dolor sit amet, consectetur adipiscing elit. Pellentesque elementum dignissim ultricies. Fusce rhoncus ipsum tempor eros aliquam consequat. Lorem ipsum dolor sit amet"
    }
  ]
}