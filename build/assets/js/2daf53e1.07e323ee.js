"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[5073],{3905:(e,n,t)=>{t.d(n,{Zo:()=>u,kt:()=>d});var o=t(67294);function a(e,n,t){return n in e?Object.defineProperty(e,n,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[n]=t,e}function r(e,n){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);n&&(o=o.filter((function(n){return Object.getOwnPropertyDescriptor(e,n).enumerable}))),t.push.apply(t,o)}return t}function i(e){for(var n=1;n<arguments.length;n++){var t=null!=arguments[n]?arguments[n]:{};n%2?r(Object(t),!0).forEach((function(n){a(e,n,t[n])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):r(Object(t)).forEach((function(n){Object.defineProperty(e,n,Object.getOwnPropertyDescriptor(t,n))}))}return e}function l(e,n){if(null==e)return{};var t,o,a=function(e,n){if(null==e)return{};var t,o,a={},r=Object.keys(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||(a[t]=e[t]);return a}(e,n);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(o=0;o<r.length;o++)t=r[o],n.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(a[t]=e[t])}return a}var s=o.createContext({}),p=function(e){var n=o.useContext(s),t=n;return e&&(t="function"==typeof e?e(n):i(i({},n),e)),t},u=function(e){var n=p(e.components);return o.createElement(s.Provider,{value:n},e.children)},m={inlineCode:"code",wrapper:function(e){var n=e.children;return o.createElement(o.Fragment,{},n)}},c=o.forwardRef((function(e,n){var t=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),c=p(t),d=a,b=c["".concat(s,".").concat(d)]||c[d]||m[d]||r;return t?o.createElement(b,i(i({ref:n},u),{},{components:t})):o.createElement(b,i({ref:n},u))}));function d(e,n){var t=arguments,a=n&&n.mdxType;if("string"==typeof e||a){var r=t.length,i=new Array(r);i[0]=c;var l={};for(var s in n)hasOwnProperty.call(n,s)&&(l[s]=n[s]);l.originalType=e,l.mdxType="string"==typeof e?e:a,i[1]=l;for(var p=2;p<r;p++)i[p]=t[p];return o.createElement.apply(null,i)}return o.createElement.apply(null,t)}c.displayName="MDXCreateElement"},38950:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>r,metadata:()=>l,toc:()=>p});var o=t(87462),a=(t(67294),t(3905));const r={id:"dataflow2",title:"dataflow\u7b80\u5355\u5165\u95e8-\u4f7f\u7528apache_beam\u521b\u5efa,\u8fd0\u884c\u4f5c\u4e1a",author:"\u62db\u6653\u8d24",author_title:"AI Engineer",author_url:"https://github.com/flybirdgroup",author_image_url:"https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",tags:["dataflow","bigquery","subpub","steaming"]},i="\u521b\u5efadataflow\u4f5c\u4e1a\u7684\u601d\u8def",l={unversionedId:"Big_Data/dataflow2",id:"Big_Data/dataflow2",title:"dataflow\u7b80\u5355\u5165\u95e8-\u4f7f\u7528apache_beam\u521b\u5efa,\u8fd0\u884c\u4f5c\u4e1a",description:"1. \u5728\u672c\u5730\u521b\u5efa\u6765\u6d4b\u8bd5\u8fd0\u884c",source:"@site/docs/Big_Data/2020-4-11-dataflow\u521b\u5efa\u4f5c\u4e1a.md",sourceDirName:"Big_Data",slug:"/Big_Data/dataflow2",permalink:"/docs/Big_Data/dataflow2",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Big_Data/2020-4-11-dataflow\u521b\u5efa\u4f5c\u4e1a.md",tags:[{label:"dataflow",permalink:"/docs/tags/dataflow"},{label:"bigquery",permalink:"/docs/tags/bigquery"},{label:"subpub",permalink:"/docs/tags/subpub"},{label:"steaming",permalink:"/docs/tags/steaming"}],version:"current",frontMatter:{id:"dataflow2",title:"dataflow\u7b80\u5355\u5165\u95e8-\u4f7f\u7528apache_beam\u521b\u5efa,\u8fd0\u884c\u4f5c\u4e1a",author:"\u62db\u6653\u8d24",author_title:"AI Engineer",author_url:"https://github.com/flybirdgroup",author_image_url:"https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",tags:["dataflow","bigquery","subpub","steaming"]},sidebar:"tutorialSidebar",previous:{title:"dataflow\u7b80\u5355\u5165\u95e8-apache beam \u57fa\u672c\u6982\u5ff5",permalink:"/docs/Big_Data/dataflow4"},next:{title:"dataflow\u7b80\u5355\u5165\u95e8-\u6d41\u6570\u636e\u8f93\u5165\u5230bigquery",permalink:"/docs/Big_Data/dataflow1"}},s={},p=[{value:"\u672c\u5730\u521b\u5efajob",id:"\u672c\u5730\u521b\u5efajob",level:2}],u={toc:p};function m(e){let{components:n,...t}=e;return(0,a.kt)("wrapper",(0,o.Z)({},u,t,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h1",{id:"\u521b\u5efadataflow\u4f5c\u4e1a\u7684\u601d\u8def"},"\u521b\u5efadataflow\u4f5c\u4e1a\u7684\u601d\u8def"),(0,a.kt)("ol",null,(0,a.kt)("li",{parentName:"ol"},"\u5728\u672c\u5730\u521b\u5efa\u6765\u6d4b\u8bd5\u8fd0\u884c"),(0,a.kt)("li",{parentName:"ol"},"\u653e\u5230dataflow\u4e0a\u8fd0\u884c")),(0,a.kt)("h2",{id:"\u672c\u5730\u521b\u5efajob"},"\u672c\u5730\u521b\u5efajob"),(0,a.kt)("p",null,"1 \u9996\u5148\u662f\u5b89\u88c5\u6211\u4eec\u9700\u8981\u6253\u5de5\u5177\u5305,\u56e0\u4e3a\u6211\u662f\u5c06\u6765\u662f\u8981\u8fd0\u884c\u5230GCP\u4e0a\u7684,\u6240\u4ee5\u6211\u4eec\u5b89\u88c5\u7684\u662f"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"pip install apache_beam[gcp]\n")),(0,a.kt)("p",null,"2 \u5bfc\u5165\u5404\u79cd\u5305"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"from apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import GoogleCloudOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nfrom apache_beam.io.textio import ReadFromText, WriteToText #\u7528\u6765\u8bfb\u5199\u6587\u4ef6\n")),(0,a.kt)("p",null,"3 \u8bbe\u7f6e\u914d\u7f6e"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'# \u8f93\u5165\u8f93\u51fa\u8def\u5f84\ninput_filename = "./input.txt"\noutput_filename = "./output.txt"\n\n#\u6307\u5b9a\u6267\u884c\u9009\u9879,\u4ee5\u544a\u8bc9Pipeline\u8fd0\u884c\u4f4d\u7f6e\u548c\u8fd0\u884c\u65b9\u5f0f\noptions = PipelineOptions()\noptions.view_as(StandardOptions).runner = "direct" #\u8868\u793a\u672c\u5730\u8fd0\u884c\n\n# \u5199\u529f\u80fd\u7c7b\n#DoFn\u5c31\u662f\u628a\u7c7b,\u8f6c\u6362,callable\u7684\u529f\u80fd\u96c6\u5408\u5728\u4e00\u8d77,\u6211\u4eec\u53ef\u4ee5\u76f4\u63a5\u7ee7\u627f,\u65b9\u4fbf\u540e\u9762\u7ba1\u9053\u4f7f\u7528\n#\u6240\u6709ParDo\u7684\u64cd\u4f5c\u90fd\u5fc5\u987b\u8981\u8ddfDoFn\u7c7b\u7684\u51fd\u6570,\u6bd4\u5982ParDo(DoFn())\n\n\nclass Split(beam.DoFn):\n    def process(self, element):\n        """\n        Splits each row on commas and returns a dictionary representing the row\n        \u6211\u4eec\u8fd9\u91cc\u505a\u7684\u4e8b\u60c5\u5c31\u662f\u7c7b\u4f3cmapper, \u5c06\u6240\u6709\u5143\u7d20\u53d8\u6210\u5b57\u5178\n        """\n        country,duration,user = element.split(",")\n        print(len(element))# element\u5c31\u662f\u6bcf\u884c\u7684\u6570\u636e,\u8ddfhdfs\u4e00\u6837,\u89c6\u529b\u6709\u95ee\u9898\n        return [\n            {\n                \'country\':country,\n                \'duration\':duration,\n                \'user\':user\n            }\n        ]\n    \nclass CollectTimings(beam.DoFn):\n    def process(self,element):\n        result = [element(\'country\'),element(\'duration\')]\n        return result\n\nclass CollectUsers(beam.DoFn):\n    def process(self,element):\n        """\n        Returns a list of tuples containing country and user name\n        """\n        return [element(\'country\'),element(\'user\')]\n\nclass WriteToCSV(beam.DoFn):\n    def process(self,element):\n        """\n        Prepares each row to be written in the csv\n        """\n        result = ["%s,%s,%s"%(element[0],element[1][\'user\'][0],element[1][\'timings\'][0])]\n        return result\n\n#\u521b\u5efa\u7ba1\u9053\u5bf9\u8c61, \u521b\u5efa\u53d8\u91cf\u63a5\u6536Pcollection, \u4e00\u5b9a\u8981\u52a0\u4e0a(),\u9632\u6b62\u6b67\u4e49,\u5982\u679c\u53d8\u6210 rows = P \u7136\u540e \u518d\u7ba1 | ReadFromText(input_filename), \u5f88\u5bb9\u6613\u62a5\u9519\nwith beam.Pipeline(options=options) as p:\n    rows = (\n        P | ReadFromText(input_filename) | beam.ParDo(SPlit())\n    )\n    timings = (\n        rows |\n        beam.ParDo(CollectTimings()) |\n        "Grouping timings" >> beam.GroupByKey() | \n        "Calculating average" >> beam.CombineValues(\n            beam.combiners.MeanCombineFn()\n        )\n    )\n    users = (\n        rows |\n        beam.ParDo(CollectUsers()) |\n        "Grouping users" >> beam.GroupByKey() |\n        "Counting users" >> beam.CombineValues(\n            beam.combiners.CountCombineFn()\n        )\n    )\n    to_be_joined = (\n        {\n            \'timings\': timings,\n            \'users\': users\n        } |\n        beam.CoGroupByKey() |\n        beam.ParDo(WriteToCSV()) |\n        WriteToText(output_filename)\n    )\n\n\n#\u8fd9\u91cc\u7684\u683c\u5f0f\u4e3apvalue | "label" >> transform\n\u4e3a\u4ec0\u4e48\u8981\u4e3a\u4ec0\u4e48\u8981\u7528"label" >>,\u5176\u5b9e\u5982\u679c\u4efb\u52a1\u4e0d\u91cd\u590d\u7684\u65f6\u5019,\u662f\u53ef\u4ee5\u4e0d\u7528\u7684,\u4f46\u662f\u6bd4\u5982\u8fd9\u91cc\u8026\u5408\u51fd\u6570groupbykey\u51fa\u73b0\u5df2\u7ecf\u5728pipeline\u4e86,\u5982\u679c\u6ca1\u6709label\u5c31\u4f1a\u62a5\u9519,\u6267\u884cusers\u65f6\u5019\u5c31\u4f1a\u62a5\u9519\n\nGroupByKey\u662f\u628akey\u76f8\u540c\u7684\u62fc\u4e3a\u4e3a\u4e00\u7ec4,CombineValues\u662f\u628a\u503c\u7d2f\u79ef\u76f8\u52a0\nCoGroupByKey\u662f\u6839\u636ekey\u62fc\u63a5\u4e00\u8d77\n')),(0,a.kt)("h1",{id:"\u597d\u7684\u672c\u5730\u6d4b\u8bd5\u597d\u540e-\u6211\u4eec\u8981\u653e\u5230dataflow\u4e0a\u8dd1\u4e86"},"\u597d\u7684,\u672c\u5730\u6d4b\u8bd5\u597d\u540e, \u6211\u4eec\u8981\u653e\u5230dataflow\u4e0a\u8dd1\u4e86"),(0,a.kt)("p",null,"1 \u6211\u4eec\u9700\u8981\u6539\u7684\u5c31\u662f input,ouput \u8def\u5f84,\u8bb0\u4f4fstorage bucket\u7684\u6743\u9650"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'input_filename = "gs://dataflow_s/input.txt"\noutput_filename = "gs://dataflow_s/output.txt"\n')),(0,a.kt)("p",null,"2 options"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"dataflow_options = ['--project=query-11','--job_name=test-job','--temp_location=gs://dataflow_s/tmp','--region=us-central1']\ndataflow_options.append('--staging_location=gs://dataflow_s/stage')\noptions = PipelineOptions(dataflow_options)\ngcloud_options = options.view_as(GoogleCloudOptions)\noptions.view_as(StandardOptions).runner = \"dataflow\" # \u6307\u5b9a\u540e\u7aef\u8dd1\u5728dataflow\n")),(0,a.kt)("p",null,"\u8fd9\u91cc\u6709\u4e2a\u5751,\u5982\u679c\u4f60\u7684apache beam\u662f2.15\u7248\u672c\u4ee5\u4e0a\u7684\u8bdd,\u662f\u9700\u8981\u5199region\u8fd9\u4e2a\u53c2\u6570\u7684\n\u7136\u540e\u5176\u4ed6\u7684\u90fd\u5f88\u672c\u5730\u4e00\u6837,\u6574\u4f53\u4ee3\u7801\u5982\u4e0b:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'import logging\nimport apache_beam as beam\nfrom apache_beam.options.pipeline_options import PipelineOptions\nfrom apache_beam.options.pipeline_options import SetupOptions\nfrom apache_beam.options.pipeline_options import GoogleCloudOptions\nfrom apache_beam.options.pipeline_options import StandardOptions\nfrom apache_beam.io.textio import ReadFromText, WriteToText\n\n\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\n\ninput_filename = "gs://dataflow_s/input.txt"\noutput_filename = "gs://dataflow_s/output.txt"\n\n\ndataflow_options = [\'--project=query-11\',\'--job_name=test-job\',\'--temp_location=gs://dataflow_s/tmp\']\ndataflow_options.append(\'--staging_location=gs://dataflow_s/stage\')\noptions = PipelineOptions(dataflow_options)\ngcloud_options = options.view_as(GoogleCloudOptions)\n\n# gcloud_options.job_name = "test-job"\n\n\noptions.view_as(StandardOptions).runner = "dataflow"\n\n\nclass Split(beam.DoFn):\n\n    def process(self, element):\n        """\n        Splits each row on commas and returns a dictionary representing the\n        row\n        """\n        country, duration, user = element.split(",")\n\n        return [{\n            \'country\': country,\n            \'duration\': float(duration),\n            \'user\': user\n        }]\n\n\nclass CollectTimings(beam.DoFn):\n\n    def process(self, element):\n        """\n        Returns a list of tuples containing country and duration\n        """\n\n        result = [\n            (element[\'country\'], element[\'duration\'])\n        ]\n        return result\n\n\nclass CollectUsers(beam.DoFn):\n\n    def process(self, element):\n        """\n        Returns a list of tuples containing country and user name\n        """\n        result = [\n            (element[\'country\'], element[\'user\'])\n        ]\n        return result\n\n\nclass WriteToCSV(beam.DoFn):\n\n    def process(self, element):\n        """\n        Prepares each row to be written in the csv\n        """\n        result = [\n            "{},{},{}".format(\n                element[0],\n                element[1][\'users\'][0],\n                element[1][\'timings\'][0]\n            )\n        ]\n        return result\n\n\n\n\nwith beam.Pipeline(options=options) as p:\n    rows = (\n        p |\n        ReadFromText(input_filename) |\n        beam.ParDo(Split())\n    )\n\n    timings = (\n        rows |\n        beam.ParDo(CollectTimings()) |\n        "Grouping timings" >> beam.GroupByKey() |\n        "Calculating average" >> beam.CombineValues(\n            beam.combiners.MeanCombineFn()\n        )\n    )\n\n    users = (\n        rows |\n        beam.ParDo(CollectUsers()) |\n        "Grouping users" >> beam.GroupByKey() |\n        "Counting users" >> beam.CombineValues(\n            beam.combiners.CountCombineFn()\n        )\n    )\n\n    to_be_joined = (\n        {\n            \'timings\': timings,\n            \'users\': users\n        } |\n        beam.CoGroupByKey() |\n        beam.ParDo(WriteToCSV()) |\n        WriteToText(output_filename)\n    )\n')),(0,a.kt)("h1",{id:"\u7136\u540e\u628a\u8fd9\u6bb5\u4ee3\u7801\u653e\u5230gcloud\u4e0a"},"\u7136\u540e\u628a\u8fd9\u6bb5\u4ee3\u7801\u653e\u5230gcloud\u4e0a"),(0,a.kt)("p",null,"\u4f7f\u7528\u547d\u4ee4\u542f\u52a8,\u5177\u4f53\u662f\u5b89\u88c5\u865a\u62df\u73af\u5883,\u8fdb\u5165\u865a\u62df\u73af\u5883,\u5b89\u88c5apache beam\u5305,\u8fd0\u884cpython\u6587\u4ef6"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"pip3 install --upgrade virtualenv --user\npython3 -m virtualenv env\nsource env/bin/activate\npip3 install --quiet apache-beam[gcp]\npython dataflow.py\n")),(0,a.kt)("h1",{id:"\u7136\u540e\u6211\u4eec\u5c31\u53ef\u4ee5\u53bbjob\u4e0a\u770b\u5230\u8fd0\u884c\u60c5\u51b5"},"\u7136\u540e\u6211\u4eec\u5c31\u53ef\u4ee5\u53bbjob\u4e0a\u770b\u5230\u8fd0\u884c\u60c5\u51b5"))}m.isMDXComponent=!0}}]);