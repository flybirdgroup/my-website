"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[4758],{3905:(e,r,t)=>{t.d(r,{Zo:()=>c,kt:()=>d});var a=t(67294);function o(e,r,t){return r in e?Object.defineProperty(e,r,{value:t,enumerable:!0,configurable:!0,writable:!0}):e[r]=t,e}function n(e,r){var t=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);r&&(a=a.filter((function(r){return Object.getOwnPropertyDescriptor(e,r).enumerable}))),t.push.apply(t,a)}return t}function p(e){for(var r=1;r<arguments.length;r++){var t=null!=arguments[r]?arguments[r]:{};r%2?n(Object(t),!0).forEach((function(r){o(e,r,t[r])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(t)):n(Object(t)).forEach((function(r){Object.defineProperty(e,r,Object.getOwnPropertyDescriptor(t,r))}))}return e}function l(e,r){if(null==e)return{};var t,a,o=function(e,r){if(null==e)return{};var t,a,o={},n=Object.keys(e);for(a=0;a<n.length;a++)t=n[a],r.indexOf(t)>=0||(o[t]=e[t]);return o}(e,r);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);for(a=0;a<n.length;a++)t=n[a],r.indexOf(t)>=0||Object.prototype.propertyIsEnumerable.call(e,t)&&(o[t]=e[t])}return o}var s=a.createContext({}),i=function(e){var r=a.useContext(s),t=r;return e&&(t="function"==typeof e?e(r):p(p({},r),e)),t},c=function(e){var r=i(e.components);return a.createElement(s.Provider,{value:r},e.children)},u={inlineCode:"code",wrapper:function(e){var r=e.children;return a.createElement(a.Fragment,{},r)}},b=a.forwardRef((function(e,r){var t=e.components,o=e.mdxType,n=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),b=i(t),d=o,g=b["".concat(s,".").concat(d)]||b[d]||u[d]||n;return t?a.createElement(g,p(p({ref:r},c),{},{components:t})):a.createElement(g,p({ref:r},c))}));function d(e,r){var t=arguments,o=r&&r.mdxType;if("string"==typeof e||o){var n=t.length,p=new Array(n);p[0]=b;var l={};for(var s in r)hasOwnProperty.call(r,s)&&(l[s]=r[s]);l.originalType=e,l.mdxType="string"==typeof e?e:o,p[1]=l;for(var i=2;i<n;i++)p[i]=t[i];return a.createElement.apply(null,p)}return a.createElement.apply(null,t)}b.displayName="MDXCreateElement"},35436:(e,r,t)=>{t.r(r),t.d(r,{assets:()=>s,contentTitle:()=>p,default:()=>u,frontMatter:()=>n,metadata:()=>l,toc:()=>i});var a=t(87462),o=(t(67294),t(3905));const n={id:"dataproc3",title:"dataproc--\u8dd1pyspark(\u4ecebig query\u83b7\u53d6\u6570\u636e)",author:"\u62db\u6653\u8d24",author_title:"AI Engineer",author_url:"https://github.com/flybirdgroup",author_image_url:"https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",tags:["dataproc","GCP","Spark","Hadoop"]},p="\u4eca\u5929\u6709\u610f\u601d\u5566 !! big query + pyspark + Dataproc",l={permalink:"/blog/2020/4/17/dataproc\u8dd1pyspark",editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/blog/2020-4-17-dataproc\u8dd1pyspark.md",source:"@site/blog/2020-4-17-dataproc\u8dd1pyspark.md",title:"dataproc--\u8dd1pyspark(\u4ecebig query\u83b7\u53d6\u6570\u636e)",description:"\u6d41\u7a0b\u5f88\u7b80\u5355",date:"2020-04-17T00:00:00.000Z",formattedDate:"April 17, 2020",tags:[{label:"dataproc",permalink:"/blog/tags/dataproc"},{label:"GCP",permalink:"/blog/tags/gcp"},{label:"Spark",permalink:"/blog/tags/spark"},{label:"Hadoop",permalink:"/blog/tags/hadoop"}],readingTime:1.83,hasTruncateMarker:!1,authors:[{name:"\u62db\u6653\u8d24",title:"AI Engineer",url:"https://github.com/flybirdgroup",imageURL:"https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg"}],frontMatter:{id:"dataproc3",title:"dataproc--\u8dd1pyspark(\u4ecebig query\u83b7\u53d6\u6570\u636e)",author:"\u62db\u6653\u8d24",author_title:"AI Engineer",author_url:"https://github.com/flybirdgroup",author_image_url:"https://ss3.bdstatic.com/70cFv8Sh_Q1YnxGkpoWK1HF6hhy/it/u=1615738601,1434436036&fm=26&gp=0.jpg",tags:["dataproc","GCP","Spark","Hadoop"]},prevItem:{title:"dataproc\u81ea\u52a8\u4f38\u7f29\u548c\u8fd0\u884cspark job",permalink:"/blog/2020/4/17/dataproc\u81ea\u52a8\u4f38\u7f29\u548c\u8fd0\u884csparkjob"},nextItem:{title:"5\u5206\u949f\u5728\u8c37\u6b4c\u4e91\u4e0a\u4f7f\u7528Dataproc\u8fd0\u884cApache Spark\u96c6\u7fa4",permalink:"/blog/2020/4/17/dataproc\u8fd0\u884cApache Spark\u96c6\u7fa4"}},s={authorsImageUrls:[void 0]},i=[{value:"\u6d41\u7a0b\u5f88\u7b80\u5355",id:"\u6d41\u7a0b\u5f88\u7b80\u5355",level:2},{value:"1. spark \u521d\u59cb\u5316,\u56e0\u4e3a\u8981\u8bfb\u53d6\u6210dataframe\u6216\u8005sql\u5f62\u5f0f,\u5bfc\u5165SparkSession",id:"1-spark-\u521d\u59cb\u5316\u56e0\u4e3a\u8981\u8bfb\u53d6\u6210dataframe\u6216\u8005sql\u5f62\u5f0f\u5bfc\u5165sparksession",level:3},{value:"2. \u521b\u5efaspark\u5bf9\u8c61",id:"2-\u521b\u5efaspark\u5bf9\u8c61",level:3},{value:"3 \u6211\u4eec\u901a\u8fc7connector\u8fde\u63a5\u4e00\u4e2agoogle storage bucket \u7ed9Bigquery\u8f93\u51fa\u6570\u636e\u4e34\u65f6\u7528",id:"3-\u6211\u4eec\u901a\u8fc7connector\u8fde\u63a5\u4e00\u4e2agoogle-storage-bucket-\u7ed9bigquery\u8f93\u51fa\u6570\u636e\u4e34\u65f6\u7528",level:3},{value:"4 \u914d\u7f6e\u597dtmp bucket,\u6211\u4eec\u53ef\u4ee5\u5f00\u59cb\u8bfb\u53d6\u6570\u636e,\u5e76\u4e14\u628a\u6570\u636e\u6846\u6ce8\u518c\u4e3a\u89c6\u56fe",id:"4-\u914d\u7f6e\u597dtmp-bucket\u6211\u4eec\u53ef\u4ee5\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\u5e76\u4e14\u628a\u6570\u636e\u6846\u6ce8\u518c\u4e3a\u89c6\u56fe",level:3},{value:"5 \u5f00\u59cb\u4f7f\u7528sql\u8bed\u53e5",id:"5-\u5f00\u59cb\u4f7f\u7528sql\u8bed\u53e5",level:3},{value:"6 \u5904\u7406\u597d\u7684dataframe\u5bf9\u8c61\u5199\u5165bigquery (\u6ce8\u610f,\u7528sql\u5904\u7406\u8fc7\u540e\u7684\u8fd8\u662fdataframe\u5bf9\u8c61)",id:"6-\u5904\u7406\u597d\u7684dataframe\u5bf9\u8c61\u5199\u5165bigquery-\u6ce8\u610f\u7528sql\u5904\u7406\u8fc7\u540e\u7684\u8fd8\u662fdataframe\u5bf9\u8c61",level:3},{value:"7 \u53bb\u5230\u7ec8\u7aef\u8f93\u5165\u547d\u4ee4,\u63d0\u4ea4spark job",id:"7-\u53bb\u5230\u7ec8\u7aef\u8f93\u5165\u547d\u4ee4\u63d0\u4ea4spark-job",level:3}],c={toc:i};function u(e){let{components:r,...t}=e;return(0,o.kt)("wrapper",(0,a.Z)({},c,t,{components:r,mdxType:"MDXLayout"}),(0,o.kt)("h2",{id:"\u6d41\u7a0b\u5f88\u7b80\u5355"},"\u6d41\u7a0b\u5f88\u7b80\u5355"),(0,o.kt)("p",null,"\u6211\u4eec\u8981\u7528spark\u8bfb\u53d6\u4ecebigquery\u8bfb\u53d6table,\u7136\u540e\u6211\u4eec\u5bf9\u8fd9\u4e2atable\u505a\u4e00\u4e2a\u7b80\u5355\u7684\u5904\u7406,\u518d\u5206\u6210\u4e24dataframe\u5bf9\u8c61,\u7136\u540e\u628a\u4e24\u4e2a\u5bf9\u8c61\u5199\u5165bigquery"),(0,o.kt)("h3",{id:"1-spark-\u521d\u59cb\u5316\u56e0\u4e3a\u8981\u8bfb\u53d6\u6210dataframe\u6216\u8005sql\u5f62\u5f0f\u5bfc\u5165sparksession"},"1. spark \u521d\u59cb\u5316,\u56e0\u4e3a\u8981\u8bfb\u53d6\u6210dataframe\u6216\u8005sql\u5f62\u5f0f,\u5bfc\u5165SparkSession"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"#!/usr/bin/python\nfrom pyspark.sql import SparkSession\n")),(0,o.kt)("h3",{id:"2-\u521b\u5efaspark\u5bf9\u8c61"},"2. \u521b\u5efaspark\u5bf9\u8c61"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"spark = SparkSession.builder.master('yarn').appName('your app name').getOrCreate()\n")),(0,o.kt)("h3",{id:"3-\u6211\u4eec\u901a\u8fc7connector\u8fde\u63a5\u4e00\u4e2agoogle-storage-bucket-\u7ed9bigquery\u8f93\u51fa\u6570\u636e\u4e34\u65f6\u7528"},"3 \u6211\u4eec\u901a\u8fc7connector\u8fde\u63a5\u4e00\u4e2agoogle storage bucket \u7ed9Bigquery\u8f93\u51fa\u6570\u636e\u4e34\u65f6\u7528"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"bucket = \"haha_mm_bucket\"\nspark.conf.set('temporaryGcsBucket',bucket)\n")),(0,o.kt)("h3",{id:"4-\u914d\u7f6e\u597dtmp-bucket\u6211\u4eec\u53ef\u4ee5\u5f00\u59cb\u8bfb\u53d6\u6570\u636e\u5e76\u4e14\u628a\u6570\u636e\u6846\u6ce8\u518c\u4e3a\u89c6\u56fe"},"4 \u914d\u7f6e\u597dtmp bucket,\u6211\u4eec\u53ef\u4ee5\u5f00\u59cb\u8bfb\u53d6\u6570\u636e,\u5e76\u4e14\u628a\u6570\u636e\u6846\u6ce8\u518c\u4e3a\u89c6\u56fe"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"df = spark.read.format('bigquery').option('table','datasetid:tableid').load()\ndf.createTempView(\"temp table name(\u6bd4\u5982words)\")\n\u4e5f\u53ef\u4ee5\u662fdf.createOrReplaceTempView('words') \u8fd9\u6837\u5c31\u53ef\u4ee5\u8986\u76d6\u539f\u6765\u540c\u6837\u540d\u5b57\u7684\u4e34\u65f6\u89c6\u56fe\n")),(0,o.kt)("h3",{id:"5-\u5f00\u59cb\u4f7f\u7528sql\u8bed\u53e5"},"5 \u5f00\u59cb\u4f7f\u7528sql\u8bed\u53e5"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'lefttable = spark.sql("SELECT ACNO, FIELD_1, FIELD_2 FROM words")\nrighttable = spark.sql("SELECT ACNO, FIELD_3, FIELD_4 FROM words")\nlefttable.show()\nlefttable.printSchema()\nrighttable.show()\nrighttable.printSchema()\n')),(0,o.kt)("h3",{id:"6-\u5904\u7406\u597d\u7684dataframe\u5bf9\u8c61\u5199\u5165bigquery-\u6ce8\u610f\u7528sql\u5904\u7406\u8fc7\u540e\u7684\u8fd8\u662fdataframe\u5bf9\u8c61"},"6 \u5904\u7406\u597d\u7684dataframe\u5bf9\u8c61\u5199\u5165bigquery (\u6ce8\u610f,\u7528sql\u5904\u7406\u8fc7\u540e\u7684\u8fd8\u662fdataframe\u5bf9\u8c61)"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"lefttable.write.format('bigquery').option('table','query-11:newdata.lefttable').save()\nrighttable.write.format('bigquery').option('table','query-11:newdata.righttable').save()\n")),(0,o.kt)("h3",{id:"7-\u53bb\u5230\u7ec8\u7aef\u8f93\u5165\u547d\u4ee4\u63d0\u4ea4spark-job"},"7 \u53bb\u5230\u7ec8\u7aef\u8f93\u5165\u547d\u4ee4,\u63d0\u4ea4spark job"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},'gcloud dataproc jobs submit pyspark wordcount.py \\\n    --cluster cluster-name \\\n    --region cluster-region (example: "us-central1") \\\n    --jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar\n')),(0,o.kt)("p",null,"\u4e3b\u8981\u683c\u5f0f: gcloud dataproc jobs submit pyspark python.py(python\u6587\u4ef6) \\\n--cluster cluster-name \\\n--region cluster-region(\u6bd4\u5982:us-central1,\u4e00\u5b9a\u8981\u5bf9\u5e94dataproc\u96c6\u7fa4\u7684region)\n--jars \u4e0ebiguqery\u8fde\u63a5\u7684\u5305\n\u6ce8\u610f\u8fd9\u91cc\u7684jars:\nIf you are using Dataproc image 1.5, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest_2.12.jar\nIf you are using Dataproc image 1.4 or below, add the following parameter:\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar"),(0,o.kt)("pre",null,(0,o.kt)("code",{parentName:"pre"},"gcloud config set dataproc/region us-central1\nBUCKET_NAME=haha_mm_bucket\ninput=new.avro\ngcloud dataproc jobs submit pyspark wordcount3.py \\\n--cluster cluster-662b \\\n-- gs://${BUCKET_NAME}/${input} \\\n--jars=gs://spark-lib/bigquery/spark-bigquery-latest.jar \\\n--packages com.databricks:spark-avro_2.11:4.0.0\n")))}u.isMDXComponent=!0}}]);