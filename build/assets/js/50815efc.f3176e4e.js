"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[1520],{3905:(e,t,n)=>{n.d(t,{Zo:()=>c,kt:()=>d});var r=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);t&&(r=r.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,r)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,r,a=function(e,t){if(null==e)return{};var n,r,a={},i=Object.keys(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(r=0;r<i.length;r++)n=i[r],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var l=r.createContext({}),p=function(e){var t=r.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},c=function(e){var t=p(e.components);return r.createElement(l.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return r.createElement(r.Fragment,{},t)}},u=r.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,l=e.parentName,c=s(e,["components","mdxType","originalType","parentName"]),u=p(n),d=a,f=u["".concat(l,".").concat(d)]||u[d]||m[d]||i;return n?r.createElement(f,o(o({ref:t},c),{},{components:n})):r.createElement(f,o({ref:t},c))}));function d(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=u;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:a,o[1]=s;for(var p=2;p<i;p++)o[p]=n[p];return r.createElement.apply(null,o)}return r.createElement.apply(null,n)}u.displayName="MDXCreateElement"},89570:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>m,frontMatter:()=>i,metadata:()=>s,toc:()=>p});var r=n(87462),a=(n(67294),n(3905));const i={id:"ML4",title:"\u673a\u5668\u5b66\u4e60-- 4 TF\u57fa\u672c\u6b65\u9aa4"},o=void 0,s={unversionedId:"Machine_Learning/ML4",id:"Machine_Learning/ML4",title:"\u673a\u5668\u5b66\u4e60-- 4 TF\u57fa\u672c\u6b65\u9aa4",description:"\u5b98\u65b9\u6587\u6863\u4fe1\u606f",source:"@site/docs/Machine_Learning/ML_TF\u57fa\u672c\u6b65\u9aa4.md",sourceDirName:"Machine_Learning",slug:"/Machine_Learning/ML4",permalink:"/docs/Machine_Learning/ML4",draft:!1,editUrl:"https://github.com/facebook/docusaurus/tree/main/packages/create-docusaurus/templates/shared/docs/Machine_Learning/ML_TF\u57fa\u672c\u6b65\u9aa4.md",tags:[],version:"current",frontMatter:{id:"ML4",title:"\u673a\u5668\u5b66\u4e60-- 4 TF\u57fa\u672c\u6b65\u9aa4"},sidebar:"tutorialSidebar",previous:{title:"tf_serving\u90e8\u7f72+\u9047\u5230\u7684\u95ee\u9898",permalink:"/docs/Machine_Learning/tf_serving"},next:{title:"\u673a\u5668\u5b66\u4e60-- 3 \u68af\u5ea6\u4e0b\u964d\u6cd5",permalink:"/docs/Machine_Learning/ML3"}},l={},p=[],c={toc:p};function m(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,r.Z)({},c,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://developers.google.com/machine-learning/crash-course/first-steps-with-tensorflow/toolkit"},"\u5b98\u65b9\u6587\u6863\u4fe1\u606f")),(0,a.kt)("p",null,(0,a.kt)("img",{parentName:"p",src:"https://developers.google.com/machine-learning/crash-course/images/TFHierarchy.svg",alt:"img"})),(0,a.kt)("p",null,"\u603b\u7ed3\u4e0d\u540c\u5c42\u7684\u7528\u9014:\nEstimator (tf.estimator)\t\u9ad8\u7ea7 OOP API\u3002\ntf.layers/tf.losses/tf.metrics\t\u7528\u4e8e\u5e38\u89c1\u6a21\u578b\u7ec4\u4ef6\u7684\u5e93\u3002\nTensorFlow\t\u4f4e\u7ea7 API"),(0,a.kt)("p",null,"\u60a8\u5e94\u8be5\u4f7f\u7528\u54ea\u4e2a API\uff1f\u60a8\u5e94\u8be5\u4f7f\u7528\u80fd\u591f\u89e3\u51b3\u95ee\u9898\u7684\u6700\u9ad8\u7ea7\u62bd\u8c61\u5c42\u3002\u8f83\u9ad8\u7ea7\u522b\u7684\u62bd\u8c61\u5c42\u66f4\u6613\u4e8e\u4f7f\u7528\uff0c\u4f46\uff08\u8bbe\u8ba1\u65b9\u9762\uff09\u4e0d\u591f\u7075\u6d3b\u3002\u6211\u4eec\u5efa\u8bae\u60a8\u5148\u4ece\u6700\u9ad8\u7ea7 API \u5165\u624b\uff0c\u8ba9\u6240\u6709\u7ec4\u4ef6\u6b63\u5e38\u8fd0\u4f5c\u8d77\u6765\u3002\u5982\u679c\u60a8\u5e0c\u671b\u5728\u67d0\u4e9b\u7279\u6b8a\u5efa\u6a21\u65b9\u9762\u80fd\u591f\u66f4\u52a0\u7075\u6d3b\u4e00\u4e9b\uff0c\u5219\u53ef\u4ee5\u964d\u4f4e\u4e00\u4e2a\u7ea7\u522b\u3002\u8bf7\u6ce8\u610f\uff0c\u6bcf\u4e2a\u7ea7\u522b\u90fd\u662f\u4f7f\u7528\u4f4e\u7ea7 API \u6784\u5efa\u7684\uff0c\u56e0\u6b64\u964d\u4f4e\u5c42\u6b21\u7ed3\u6784\u7ea7\u522b\u5e94\u8be5\u6bd4\u8f83\u76f4\u89c2\u3002"),(0,a.kt)("h1",{id:"\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u7a0b\u5e8f"},"\u7b80\u5355\u7684\u7ebf\u6027\u56de\u5f52\u7a0b\u5e8f"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"import tensorflow as tf\n# set up a linear classifier\nclassifer = tf.estimator.linearClassifier()\n# train the model on some example data\nclassifer.train(input_fn=train_input_fn,steps=2000)\n# use the model to predict\npredictions = classifer.predict(input_fn=predict_input_fn)\n")),(0,a.kt)("p",null,"\u673a\u5668\u5b66\u4e60\u901f\u6210\u8bfe\u7a0b\u7ec3\u4e60\u4e2d\u7684\u5e38\u7528\u8d85\u53c2\u6570\n\u5f88\u591a\u7f16\u7801\u7ec3\u4e60\u90fd\u5305\u542b\u4ee5\u4e0b\u8d85\u53c2\u6570\uff1a"),(0,a.kt)("p",null,"steps\uff1a\u8bad\u7ec3\u8fed\u4ee3\u7684\u603b\u6b21\u6570\u3002\u4e00\u6b65\u8ba1\u7b97\u4e00\u6279\u6837\u672c\u4ea7\u751f\u7684\u635f\u5931\uff0c\u7136\u540e\u4f7f\u7528\u8be5\u503c\u4fee\u6539\u4e00\u6b21\u6a21\u578b\u7684\u6743\u91cd\u3002\nbatch size\uff1a\u5355\u6b65\u7684\u6837\u672c\u6570\u91cf\uff08\u968f\u673a\u9009\u62e9\uff09\u3002\u4f8b\u5982\uff0cSGD \u7684\u6279\u6b21\u5927\u5c0f\u4e3a 1\u3002"),(0,a.kt)("p",null,"total number of trained examples = batch sizes * steps"),(0,a.kt)("p",null,"\u673a\u5668\u5b66\u4e60\u901f\u6210\u8bfe\u7a0b\u7ec3\u4e60\u4e2d\u7684\u65b9\u4fbf\u53d8\u91cf\n\u6709\u4e9b\u7ec3\u4e60\u4e2d\u4f1a\u51fa\u73b0\u4ee5\u4e0b\u65b9\u4fbf\u53d8\u91cf\uff1a"),(0,a.kt)("p",null,"periods\uff1a\u63a7\u5236\u62a5\u544a\u7684\u7c92\u5ea6\u3002\u4f8b\u5982\uff0c\u5982\u679c periods \u8bbe\u4e3a 7 \u4e14 steps \u8bbe\u4e3a 70\uff0c\u5219\u8bad\u7ec3\u5c06\u6bcf 10 \u6b65\u8f93\u51fa\u4e00\u6b21\u635f\u5931\u503c\uff08\u5373 7 \u6b21\uff09\u3002\u4e0e\u8d85\u53c2\u6570\u4e0d\u540c\uff0c\u6211\u4eec\u4e0d\u5e0c\u671b\u60a8\u4fee\u6539 periods \u7684\u503c\u3002\u8bf7\u6ce8\u610f\uff0c\u4fee\u6539 periods \u4e0d\u4f1a\u66f4\u6539\u6a21\u578b\u6240\u5b66\u4e60\u7684\u89c4\u5f8b\u3002"),(0,a.kt)("h1",{id:"\u7f16\u7a0b\u7ec3\u4e60"},"\u7f16\u7a0b\u7ec3\u4e60"),(0,a.kt)("p",null,(0,a.kt)("a",{parentName:"p",href:"https://colab.research.google.com/notebooks/mlcc/first_steps_with_tensor_flow.ipynb?utm_source=mlcc&utm_campaign=colab-external&utm_medium=referral&utm_content=firststeps-colab&hl=zh-cn#scrollTo=UzoZUSdLIolF"},"colab\u7ec3\u4e601")),(0,a.kt)("h1",{id:"\u6b65\u9aa41-\u8bfb\u5165csv\u6587\u4ef6\u8bbe\u7f6e\u53c2\u6570"},"\u6b65\u9aa41 \u8bfb\u5165csv\u6587\u4ef6,\u8bbe\u7f6e\u53c2\u6570:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'from __future__ import print_function\n\nimport math\n\nfrom IPython import display\nfrom matplotlib import cm\nfrom matplotlib import gridspec\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport sklearn.metrics as metrics\n%tensorflow_version 1.x\nimport tensorflow as tf\nfrom tensorflow.python.data import Dataset\n\ntf.logging.set_verbosity(tf.logging.ERROR)\npd.options.display.max_rows = 10\npd.options.display.float_format = \'{:.1f}\'.format #\u8bbe\u7f6edataframe\u5c0f\u6570\u70b9\n\ncalifornia_housing_dataframe = pd.read_csv("https://download.mlcc.google.cn/mledu-datasets/california_housing_train.csv", sep=",")\n\ncalifornia_housing_dataframe = california_housing_dataframe.reindex(\n    np.random.permutation(california_housing_dataframe.index))\ncalifornia_housing_dataframe["median_house_value"] /= 1000.0\ncalifornia_housing_dataframe\n')),(0,a.kt)("h1",{id:"\u6b65\u9aa42-\u8bbe\u7f6e\u8f93\u5165\u51fd\u6570\u5e76\u9488\u5bf9\u6a21\u578b\u8bad\u7ec3\u6765\u5b9a\u4e49\u51fd\u6570"},"\u6b65\u9aa42 \u8bbe\u7f6e\u8f93\u5165\u51fd\u6570,\u5e76\u9488\u5bf9\u6a21\u578b\u8bad\u7ec3\u6765\u5b9a\u4e49\u51fd\u6570"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'def my_input_fn(features, targets, batch_size=1, shuffle=True, num_epochs=None):\n"""Trains a linear regression model of one feature.\n\nArgs:\n    features: pandas DataFrame of features,\u7279\u5f81\n    targets: pandas DataFrame of targets,\u76ee\u6807\u503c\n    batch_size: Size of batches to be passed to the model,\u6279\u91cf\u7684\u5927\u5c0f\n    shuffle: True or False. Whether to shuffle the data.\n    num_epochs: Number of epochs for which data should be repeated. None = repeat indefinitely\nReturns:\n    Tuple of (features, labels) for next data batch\n"""\n# Convert pandas data into a dict of np arrays.\nfeatures = {key:np.array(value) for key,value in dict(features).items()}   \n\n# Construct a dataset, and configure batching/repeating.\n# \u521b\u5efaDataset,\u8bbe\u7f6e\u6279\u6b21\u548c\u91cd\u590d\u6b21\u6570\nds = Dataset.from_tensor_slices((features,targets)) # warning: 2GB limit\nds = ds.batch(batch_size).repeat(num_epochs)\n\n# Shuffle the data, if specified.\nif shuffle:\n    ds = ds.shuffle(buffer_size=10000)\n\n# Return the next batch of data.\nfeatures, labels = ds.make_one_shot_iterator().get_next()\nreturn features, labels\n')),(0,a.kt)("p",null,"\u6b65\u9aa43: \u8bad\u7ec3\u6a21\u578b"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'def train_model(learning_rate, steps, batch_size, input_feature):\n  """Trains a linear regression model.\n  \n  Args:\n    learning_rate: A `float`, the learning rate.\n    steps: A non-zero `int`, the total number of training steps. A training step\n      consists of a forward and backward pass using a single batch.\n    batch_size: A non-zero `int`, the batch size.\n    input_feature: A `string` specifying a column from `california_housing_dataframe`\n      to use as input feature.\n      \n  Returns:\n    A Pandas `DataFrame` containing targets and the corresponding predictions done\n    after training the model.\n  """\n    periods = 10\n    steps_per_period = steps / periods\n    my_feature = input_feature\n    my_feature_data = california_housing_dataframe[[my_feature]].astype(\'float32\')\n    my_label = "median_house_value"\n    targets = california_housing_dataframe[my_label].astype(\'float32\')\n\n    # Create input functions.\n    training_input_fn = lambda: my_input_fn(my_feature_data, targets, batch_size=batch_size)\n    predict_training_input_fn = lambda: my_input_fn(my_feature_data, targets, num_epochs=1, shuffle=False)\n\n    # Create feature columns.\n    feature_columns = [tf.feature_column.numeric_column(my_feature)]\n\n    # Create a linear regressor object.\n    my_optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)\n    my_optimizer = tf.contrib.estimator.clip_gradients_by_norm(my_optimizer, 5.0)\n    linear_regressor = tf.estimator.LinearRegressor(\n        feature_columns=feature_columns,\n        optimizer=my_optimizer\n    )\n\n    # Set up to plot the state of our model\'s line each period.\n    plt.figure(figsize=(15, 6))\n    plt.subplot(1, 2, 1)\n    plt.title("Learned Line by Period")\n    plt.ylabel(my_label)\n    plt.xlabel(my_feature)\n    sample = california_housing_dataframe.sample(n=300)\n    plt.scatter(sample[my_feature], sample[my_label])\n    colors = [cm.coolwarm(x) for x in np.linspace(-1, 1, periods)]\n\n    # Train the model, but do so inside a loop so that we can periodically assess\n    # loss metrics.\n    print("Training model...")\n    print("RMSE (on training data):")\n    root_mean_squared_errors = []\n    for period in range (0, periods):\n        # Train the model, starting from the prior state.\n        linear_regressor.train(\n            input_fn=training_input_fn,\n            steps=steps_per_period,\n        )\n        # Take a break and compute predictions.\n        predictions = linear_regressor.predict(input_fn=predict_training_input_fn)\n        predictions = np.array([item[\'predictions\'][0] for item in predictions])\n    \n    # Compute loss.\n    root_mean_squared_error = math.sqrt(\n    metrics.mean_squared_error(predictions, targets))\n\n    # Occasionally print the current loss.\n    print("  period %02d : %0.2f" % (period, root_mean_squared_error))\n    # Add the loss metrics from this period to our list.\n    root_mean_squared_errors.append(root_mean_squared_error)\n    # Finally, track the weights and biases over time.\n    # Apply some math to ensure that the data and line are plotted neatly.\n    y_extents = np.array([0, sample[my_label].max()])\n\n    weight = linear_regressor.get_variable_value(\'linear/linear_model/%s/weights\' % input_feature)[0]\n    bias = linear_regressor.get_variable_value(\'linear/linear_model/bias_weights\')\n\n    x_extents = (y_extents - bias) / weight\n    x_extents = np.maximum(np.minimum(x_extents,\n                                      sample[my_feature].max()),\n                           sample[my_feature].min())\n    y_extents = weight * x_extents + bias\n    plt.plot(x_extents, y_extents, color=colors[period]) \n  print("Model training finished.")\n\n  # Output a graph of loss metrics over periods.\n  plt.subplot(1, 2, 2)\n  plt.ylabel(\'RMSE\')\n  plt.xlabel(\'Periods\')\n  plt.title("Root Mean Squared Error vs. Periods")\n  plt.tight_layout()\n  plt.plot(root_mean_squared_errors)\n  \n  # Create a table with calibration data.\n  calibration_data = pd.DataFrame()\n  calibration_data["predictions"] = pd.Series(predictions)\n  calibration_data["targets"] = pd.Series(targets)\n  display.display(calibration_data.describe())\n\n  print("Final RMSE (on training data): %0.2f" % root_mean_squared_error)\n  \n  return calibration_data\n')))}m.isMDXComponent=!0}}]);